{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LLM evaluation 의 중요성\n",
    "* 서비스를 안정적으로 운영하기 위해\n",
    "* 사용자가 정확한 정보를 받을 수 있는지 ? -> 환각 현상\n",
    "\n",
    "### Langsmith\n",
    "* 답변의 도움 정도, 실제 답변과 얼마나 유사한지 등의 llm 의 성능 평가 기능을 제공함\n",
    "\n",
    "* Dataset 구성\n",
    "    * 도메인 전문가가 작성한 정답지를 포함하는 데이터\n",
    "    * 특정 질문이 들어올 때 기대되는 답변을 포함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langsmith import Client\n",
    "\n",
    "client = Client()\n",
    "\n",
    "# Define dataset: these are your test cases\n",
    "dataset_name = \"income_tax_dataset\"\n",
    "dataset = client.create_dataset(dataset_name)\n",
    "client.create_examples(\n",
    "    inputs=[\n",
    "        {\"input_question\": \"제1조에 따른 소득세법의 목적은 무엇인가요?\"},\n",
    "        {\"input_question\": \"'거주자'는 소득세법에서 어떻게 정의되나요?\"},\n",
    "        {\"input_question\": \"'비거주자'는 소득세법에 따라 어떻게 정의되나요?\"},\n",
    "        {\"input_question\": \"소득세법에 따른 '내국법인'은 누구를 의미하나요?\"},\n",
    "        {\"input_question\": \"소득세법에 따라 소득세를 납부할 의무가 있는 사람은 누구인가요?\"},\n",
    "        {\"input_question\": \"거주자의 과세 범위는 무엇인가요?\"},\n",
    "        {\"input_question\": \"소득세법에 따라 소득은 어떻게 분류되나요?\"},\n",
    "        {\"input_question\": \"종합소득이란 무엇인가요?\"},\n",
    "        {\"input_question\": \"세금이 면제되는 소득의 종류는 무엇인가요?\"},\n",
    "        {\"input_question\": \"소득세의 과세기간은 어떻게 되나요?\"},\n",
    "        {\"input_question\": \"거주자의 소득세 납세지는 어디인가요?\"},\n",
    "        {\"input_question\": \"비거주자의 소득세 납세지는 어디인가요?\"},\n",
    "        {\"input_question\": \"납세지가 불분명한 경우 어떻게 되나요?\"},\n",
    "        {\"input_question\": \"원천징수세액의 납세지는 어떻게 결정되나요?\"},\n",
    "        {\"input_question\": \"납세자의 사망 시 납세지는 어떻게 되나요?\"},\n",
    "        {\"input_question\": \"신탁 소득에 대한 납세의 범위는 무엇인가요?\"},\n",
    "        {\"input_question\": \"원천징수 대상 소득은 무엇인가요?\"},\n",
    "        {\"input_question\": \"공동 소유 자산의 양도소득은 어떻게 과세되나요?\"},\n",
    "        {\"input_question\": \"이자 소득의 출처는 무엇인가요?\"},\n",
    "        {\"input_question\": \"소득세법에서 배당소득은 어떻게 정의되나요?\"}\n",
    "    ],\n",
    "    outputs=[\n",
    "        {\"output_answer\": \"소득세법의 목적은 소득의 성격과 납세자의 부담능력에 따라 적정하게 과세함으로써 조세부담의 형평을 도모하고 재정수입의 원활한 조달에 이바지하는 것입니다.\"},\n",
    "        {\"output_answer\": \"'거주자'는 한국에 주소를 두거나 183일 이상 거소를 둔 개인을 의미합니다.\"},\n",
    "        {\"output_answer\": \"'비거주자'는 거주자가 아닌 개인을 의미합니다.\"},\n",
    "        {\"output_answer\": \"'내국법인'은 법인세법 제2조 제1호에 따른 내국법인을 의미합니다.\"},\n",
    "        {\"output_answer\": \"거주자 및 국내원천소득이 있는 비거주자는 소득세를 납부할 의무가 있습니다.\"},\n",
    "        {\"output_answer\": \"거주자는 법에서 규정한 모든 소득에 대해 과세되며, 비거주자는 국내원천소득에 대해서만 과세됩니다.\"},\n",
    "        {\"output_answer\": \"소득은 종합소득, 퇴직소득, 양도소득으로 분류됩니다.\"},\n",
    "        {\"output_answer\": \"종합소득은 이자소득, 배당소득, 사업소득, 근로소득, 연금소득 및 기타소득을 포함합니다.\"},\n",
    "        {\"output_answer\": \"비과세 소득에는 공익신탁의 이익, 특정 사업소득 및 기타 법에서 정한 특정 소득이 포함됩니다.\"},\n",
    "        {\"output_answer\": \"소득세의 과세기간은 매년 1월 1일부터 12월 31일까지입니다.\"},\n",
    "        {\"output_answer\": \"거주자의 소득세 납세지는 주소지이며, 주소지가 없으면 거소지입니다.\"},\n",
    "        {\"output_answer\": \"비거주자의 소득세 납세지는 국내사업장의 소재지입니다. 국내사업장이 여러 곳인 경우 주된 사업장의 소재지가 납세지가 됩니다.\"},\n",
    "        {\"output_answer\": \"납세지가 불분명한 경우 대통령령으로 정합니다.\"},\n",
    "        {\"output_answer\": \"원천징수세액의 납세지는 원천징수자의 종류와 위치에 따라 결정됩니다.\"},\n",
    "        {\"output_answer\": \"납세자의 사망 시 상속인 또는 납세관리인의 주소지나 거소지가 납세지가 됩니다.\"},\n",
    "        {\"output_answer\": \"신탁 소득에 대한 납세의 범위는 신탁의 수익자가 해당 소득에 대해 납세의무를 집니다.\"},\n",
    "        {\"output_answer\": \"이자소득, 배당소득 및 기타 법에서 정한 소득은 원천징수 대상입니다.\"},\n",
    "        {\"output_answer\": \"공동 소유 자산의 양도소득은 각 거주자 소유 지분에 따라 과세됩니다.\"},\n",
    "        {\"output_answer\": \"이자 소득의 출처는 정부 및 지방자치단체가 발행한 채권, 법인이 발행한 채권, 국내외 은행 예금 등입니다.\"},\n",
    "        {\"output_answer\": \"배당소득은 국내외 법인으로부터 받는 배당금 및 배분금, 기타 법에서 정한 소득을 포함합니다.\"}\n",
    "    ],\n",
    "    metadata= [\n",
    "        {\"contexts\": \"제1조(목적) 이 법은 개인의 소득에 대하여 소득의 성격과 납세자의 부담능력 등에 따라 적정하게 과세함으로써 조세부담의 형평을 도모하고 재정수입의 원활한 조달에 이바지함을 목적으로 한다.\"},\n",
    "        {\"contexts\": \"제1조의2(정의) “거주자”란 국내에 주소를 두거나 183일 이상의 거소를 둔 개인을 말한다.\"},\n",
    "        {\"contexts\": \"제1조의2(정의) “비거주자”란 거주자가 아닌 개인을 말한다.\"},\n",
    "        {\"contexts\": \"제1조의2(정의) “내국법인”이란 「법인세법」 제2조제1호에 따른 내국법인을 말한다.\"},\n",
    "        {\"contexts\": \"제2조(납세의무) 거주자 및 국내원천소득이 있는 비거주자는 소득세를 납부할 의무가 있다.\"},\n",
    "        {\"contexts\": \"제3조(과세소득의 범위) 거주자는 법에서 규정한 모든 소득에 대해 과세되며, 비거주자는 국내원천소득에 대해서만 과세된다.\"},\n",
    "        {\"contexts\": \"제4조(소득의 구분) 소득은 종합소득, 퇴직소득, 양도소득으로 분류된다.\"},\n",
    "        {\"contexts\": \"제4조(소득의 구분) 종합소득은 이자소득, 배당소득, 사업소득, 근로소득, 연금소득 및 기타소득을 포함한다.\"},\n",
    "        {\"contexts\": \"제12조(비과세소득) 비과세 소득에는 공익신탁의 이익, 특정 사업소득 및 기타 법에서 정한 특정 소득이 포함된다.\"},\n",
    "        {\"contexts\": \"제5조(과세기간) 소득세의 과세기간은 매년 1월 1일부터 12월 31일까지이다.\"},\n",
    "        {\"contexts\": \"제6조(납세지) 거주자의 소득세 납세지는 주소지이며, 주소지가 없으면 거소지이다.\"},\n",
    "        {\"contexts\": \"제6조(납세지) 비거주자의 소득세 납세지는 국내사업장의 소재지이다. 국내사업장이 여러 곳인 경우 주된 사업장의 소재지이다.\"},\n",
    "        {\"contexts\": \"제6조(납세지) 납세지가 불분명한 경우에는 대통령령으로 정한다.\"},\n",
    "        {\"contexts\": \"제7조(원천징수 등의 경우의 납세지) 원천징수세액의 납세지는 원천징수자의 종류와 위치에 따라 결정된다.\"},\n",
    "        {\"contexts\": \"제8조(상속 등의 경우의 납세지) 납세자의 사망 시 상속인 또는 납세관리인의 주소지나 거소지가 납세지가 된다.\"},\n",
    "        {\"contexts\": \"제2조의3(신탁재산 귀속 소득에 대한 납세의무의 범위) 신탁 소득에 대한 납세의 범위는 신탁의 수익자가 해당 소득에 대해 납세의무를 진다.\"},\n",
    "        {\"contexts\": \"제14조(과세표준의 계산) 이자소득, 배당소득 및 기타 법에서 정한 소득은 원천징수 대상이다.\"},\n",
    "        {\"contexts\": \"제14조(과세표준의 계산) 공동 소유 자산의 양도소득은 각 거주자 소유 지분에 따라 과세된다.\"},\n",
    "        {\"contexts\": \"제16조(이자소득) 이자 소득의 출처는 정부 및 지방자치단체가 발행한 채권, 법인이 발행한 채권, 국내외 은행 예금 등이다.\"},\n",
    "        {\"contexts\": \"제17조(배당소득) 배당소득은 국내외 법인으로부터 받는 배당금 및 배분금, 기타 법에서 정한 소득을 포함한다.\"}\n",
    "    ],\n",
    "    dataset_id=dataset.id,\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retriever 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "embedding = OpenAIEmbeddings(model='text-embedding-3-large')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/pinecone/data/index.py:1: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from tqdm.autonotebook import tqdm\n"
     ]
    }
   ],
   "source": [
    "from langchain_pinecone import PineconeVectorStore\n",
    "\n",
    "index_name = 'tax-markdown-index'\n",
    "\n",
    "database = PineconeVectorStore.from_existing_index(index_name=index_name, embedding=embedding)\n",
    "retriever = database.as_retriever()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LLM 답변 생성을 위한 RAGBot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "from langsmith import traceable\n",
    "from langsmith.wrappers import wrap_openai\n",
    "\n",
    "class RagBot:\n",
    "\n",
    "    def __init__(self, retriever, model: str = \"gpt-4o\"):\n",
    "        # 위에서 선언한 retriever를 할용해서 Retrieval 실행\n",
    "        self._retriever = retriever\n",
    "        # Wrapping the client instruments the LLM\n",
    "        # LangSmith 문법\n",
    "        self._client = wrap_openai(openai.Client())\n",
    "        self._model = model\n",
    "\n",
    "    @traceable()\n",
    "    def retrieve_docs(self, question):\n",
    "        return self._retriever.invoke(question)\n",
    "\n",
    "    @traceable()\n",
    "    def invoke_llm(self, question, docs):\n",
    "        # `retrieve_docs()` 를 통해 가져온 문서들을 system prompt로 전달\n",
    "        # 3.3에서 했던 방식과 유사함\n",
    "        response = self._client.chat.completions.create(\n",
    "            model=self._model,\n",
    "            messages=[\n",
    "                {\n",
    "                    \"role\": \"system\",\n",
    "                    \"content\": \"당신은 한국의 소득세 전문가입니다.\"\n",
    "                    \"아래 소득세법을 참고해서 사용자의 질문에 답변해주세요.\\n\\n\"\n",
    "                    f\"## 소득세법\\n\\n{docs}\",\n",
    "                },\n",
    "                {\"role\": \"user\", \"content\": question},\n",
    "            ],\n",
    "        )\n",
    "\n",
    "        # Evaluators 를 활용해서 `answer`와 `context`를 평가할 예정\n",
    "        return {\n",
    "            \"answer\": response.choices[0].message.content,\n",
    "            \"contexts\": [str(doc) for doc in docs],\n",
    "        }\n",
    "\n",
    "    @traceable()\n",
    "    def get_answer(self, question: str):\n",
    "        docs = self.retrieve_docs(question)\n",
    "        return self.invoke_llm(question, docs)\n",
    "\n",
    "rag_bot = RagBot(retriever)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_rag_answer(example: dict):\n",
    "    \"\"\"답변만 평가할 때 사용\"\"\"\n",
    "    response = rag_bot.get_answer(example[\"input_question\"])\n",
    "    return {\"answer\": response[\"answer\"]}\n",
    "\n",
    "def predict_rag_answer_with_context(example: dict):\n",
    "    \"\"\"Context를 활용해서 hallucination을 평가할 때 사용\"\"\"\n",
    "    response = rag_bot.get_answer(example[\"input_question\"])\n",
    "    return {\"answer\": response[\"answer\"], \"contexts\": response[\"contexts\"]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import hub\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# Grade prompt\n",
    "# 답변의 정확도를 측정하기위해 사용되는 프롬프트\n",
    "grade_prompt_answer_accuracy = prompt = hub.pull(\"langchain-ai/rag-answer-vs-reference\")\n",
    "\n",
    "def answer_evaluator(run, example) -> dict:\n",
    "    \"\"\"\n",
    "    RAG 답변 성능을 측정하기 위한 evaluator\n",
    "    \"\"\"\n",
    "\n",
    "    # `example`이 데이터를 생성할 때 입력한 `Question-Answer` pair. `run`은 `RagBot`을 활용해서 생성한 LLM의 답변\n",
    "    input_question = example.inputs[\"input_question\"]\n",
    "    reference = example.outputs[\"output_answer\"]\n",
    "    prediction = run.outputs[\"answer\"]\n",
    "\n",
    "    # LLM Judge로 사용될 LLM\n",
    "    llm = ChatOpenAI(model=\"gpt-4o\", temperature=0)\n",
    "\n",
    "    # LLM 응답을 위한 LCEL 활용\n",
    "    # 3.6 `dictionary_chain`의 `prompt | llm | StrOutputParser()`` 의 구조와 유사함\n",
    "    answer_grader = grade_prompt_answer_accuracy | llm\n",
    "\n",
    "    # Evaluator 실행\n",
    "    score = answer_grader.invoke({\"question\": input_question,\n",
    "                                  \"correct_answer\": reference,\n",
    "                                  \"student_answer\": prediction})\n",
    "    score = score[\"Score\"]\n",
    "\n",
    "    return {\"key\": \"answer_v_reference_score\", \"score\": score}\n",
    "# Grade prompt\n",
    "# 답변이 사용자의 질문에 얼마나 도움되는지 판단하는 프롬프트\n",
    "grade_prompt_answer_helpfulness = prompt = hub.pull(\"langchain-ai/rag-answer-helpfulness\")\n",
    "\n",
    "def answer_helpfulness_evaluator(run, example) -> dict:\n",
    "    \"\"\"\n",
    "    답변이 사용자의 질문에 얼마나 도움되는지 판단하는 Evaluator\n",
    "    \"\"\"\n",
    "\n",
    "    # 데이터셋의 답변과 비교하지 않고, 데이터셋의 질문에 대한 LLM의 답변의 가치를 평가함\n",
    "    input_question = example.inputs[\"input_question\"]\n",
    "    prediction = run.outputs[\"answer\"]\n",
    "\n",
    "    # LLM Judge로 사용될 LLM\n",
    "    llm = ChatOpenAI(model=\"gpt-4o\", temperature=0)\n",
    "\n",
    "    # LLM 응답을 위한 LCEL 활용\n",
    "    # 3.6 `dictionary_chain`의 `prompt | llm | StrOutputParser()`` 의 구조와 유사함\n",
    "    answer_grader = grade_prompt_answer_helpfulness | llm\n",
    "\n",
    "    # Evaluator 실행\n",
    "    score = answer_grader.invoke({\"question\": input_question,\n",
    "                                  \"student_answer\": prediction})\n",
    "    score = score[\"Score\"]\n",
    "\n",
    "    return {\"key\": \"answer_helpfulness_score\", \"score\": score}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grade prompt\n",
    "# 답변이 사용자의 질문에 얼마나 도움되는지 판단하는 프롬프트\n",
    "grade_prompt_hallucinations = prompt = hub.pull(\"langchain-ai/rag-answer-hallucination\")\n",
    "\n",
    "def answer_hallucination_evaluator(run, example) -> dict:\n",
    "    \"\"\"\n",
    "    hallucination 판단을 위한 Evaluator\n",
    "    \"\"\"\n",
    "\n",
    "    # 데이터셋에 있는 질문과, LLM이 답변을 생성할 때 사용한 context를 활용\n",
    "    input_question = example.inputs[\"input_question\"]\n",
    "    contexts = run.outputs[\"contexts\"]\n",
    "\n",
    "    # LLM의 답변\n",
    "    prediction = run.outputs[\"answer\"]\n",
    "\n",
    "    # LLM Judge로 사용될 LLM\n",
    "    llm = ChatOpenAI(model=\"gpt-4o\", temperature=0)\n",
    "\n",
    "    # LLM 응답을 위한 LCEL 활용\n",
    "    # 3.6 `dictionary_chain`의 `prompt | llm | StrOutputParser()`` 의 구조와 유사함\n",
    "    answer_grader = grade_prompt_hallucinations | llm\n",
    "\n",
    "    # Evaluator 실행\n",
    "    score = answer_grader.invoke({\"documents\": contexts,\n",
    "                                  \"student_answer\": prediction})\n",
    "    score = score[\"Score\"]\n",
    "\n",
    "    return {\"key\": \"answer_hallucination\", \"score\": score}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "View the evaluation results for experiment: 'inflearn-evaluator-lecture-hallucination-f9f25f9e' at:\n",
      "https://smith.langchain.com/o/2f003b67-27f4-48d0-8856-e1db2397e3d4/datasets/edb864cd-0264-4267-8e7d-6947cf745ec2/compare?selectedSessions=3a697977-a5c3-42c3-ab22-237bc54a7274\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]Error running evaluator <DynamicRunEvaluator answer_evaluator> on run fc17a617-0f44-4ff7-93f1-2c5e97a35460: RateLimitError(\"Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o in organization org-CnOnLIaLFhfXUDRV6hWHsPkS on tokens per min (TPM): Limit 30000, Used 29954, Requested 407. Please try again in 722ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\")\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/evaluation/_runner.py\", line 1404, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/evaluation/evaluator.py\", line 331, in evaluate_run\n",
      "    result = self.func(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 617, in wrapper\n",
      "    raise e\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 614, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "  File \"/var/folders/1l/w3vzbf215cs4ll30rh71l7wr6ghggx/T/ipykernel_62466/2954685631.py\", line 26, in answer_evaluator\n",
      "    score = answer_grader.invoke({\"question\": input_question,\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langchain_core/runnables/base.py\", line 3024, in invoke\n",
      "    input = context.run(step.invoke, input, config)\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langchain_core/runnables/base.py\", line 5354, in invoke\n",
      "    return self.bound.invoke(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langchain_core/language_models/chat_models.py\", line 286, in invoke\n",
      "    self.generate_prompt(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langchain_core/language_models/chat_models.py\", line 786, in generate_prompt\n",
      "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langchain_core/language_models/chat_models.py\", line 643, in generate\n",
      "    raise e\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langchain_core/language_models/chat_models.py\", line 633, in generate\n",
      "    self._generate_with_cache(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langchain_core/language_models/chat_models.py\", line 851, in _generate_with_cache\n",
      "    result = self._generate(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langchain_openai/chat_models/base.py\", line 689, in _generate\n",
      "    response = self.client.create(**payload)\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 275, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/resources/chat/completions.py\", line 829, in create\n",
      "    return self._post(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/_base_client.py\", line 1280, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/_base_client.py\", line 957, in request\n",
      "    return self._request(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/_base_client.py\", line 1046, in _request\n",
      "    return self._retry_request(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/_base_client.py\", line 1095, in _retry_request\n",
      "    return self._request(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/_base_client.py\", line 1046, in _request\n",
      "    return self._retry_request(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/_base_client.py\", line 1095, in _retry_request\n",
      "    return self._request(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/_base_client.py\", line 1061, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o in organization org-CnOnLIaLFhfXUDRV6hWHsPkS on tokens per min (TPM): Limit 30000, Used 29954, Requested 407. Please try again in 722ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Error running evaluator <DynamicRunEvaluator answer_evaluator> on run d44a7cba-85d0-4618-9fb2-e09bf88551d5: RateLimitError(\"Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o in organization org-CnOnLIaLFhfXUDRV6hWHsPkS on tokens per min (TPM): Limit 30000, Used 29751, Requested 440. Please try again in 382ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\")\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/evaluation/_runner.py\", line 1404, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/evaluation/evaluator.py\", line 331, in evaluate_run\n",
      "    result = self.func(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 617, in wrapper\n",
      "    raise e\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 614, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "  File \"/var/folders/1l/w3vzbf215cs4ll30rh71l7wr6ghggx/T/ipykernel_62466/2954685631.py\", line 26, in answer_evaluator\n",
      "    score = answer_grader.invoke({\"question\": input_question,\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langchain_core/runnables/base.py\", line 3024, in invoke\n",
      "    input = context.run(step.invoke, input, config)\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langchain_core/runnables/base.py\", line 5354, in invoke\n",
      "    return self.bound.invoke(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langchain_core/language_models/chat_models.py\", line 286, in invoke\n",
      "    self.generate_prompt(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langchain_core/language_models/chat_models.py\", line 786, in generate_prompt\n",
      "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langchain_core/language_models/chat_models.py\", line 643, in generate\n",
      "    raise e\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langchain_core/language_models/chat_models.py\", line 633, in generate\n",
      "    self._generate_with_cache(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langchain_core/language_models/chat_models.py\", line 851, in _generate_with_cache\n",
      "    result = self._generate(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langchain_openai/chat_models/base.py\", line 689, in _generate\n",
      "    response = self.client.create(**payload)\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 275, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/resources/chat/completions.py\", line 829, in create\n",
      "    return self._post(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/_base_client.py\", line 1280, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/_base_client.py\", line 957, in request\n",
      "    return self._request(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/_base_client.py\", line 1046, in _request\n",
      "    return self._retry_request(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/_base_client.py\", line 1095, in _retry_request\n",
      "    return self._request(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/_base_client.py\", line 1046, in _request\n",
      "    return self._retry_request(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/_base_client.py\", line 1095, in _retry_request\n",
      "    return self._request(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/_base_client.py\", line 1061, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o in organization org-CnOnLIaLFhfXUDRV6hWHsPkS on tokens per min (TPM): Limit 30000, Used 29751, Requested 440. Please try again in 382ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Error running evaluator <DynamicRunEvaluator answer_evaluator> on run ae9d2f10-6661-48a4-9536-156f0e61180d: RateLimitError(\"Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o in organization org-CnOnLIaLFhfXUDRV6hWHsPkS on tokens per min (TPM): Limit 30000, Used 29677, Requested 520. Please try again in 394ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\")\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/evaluation/_runner.py\", line 1404, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/evaluation/evaluator.py\", line 331, in evaluate_run\n",
      "    result = self.func(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 617, in wrapper\n",
      "    raise e\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 614, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "  File \"/var/folders/1l/w3vzbf215cs4ll30rh71l7wr6ghggx/T/ipykernel_62466/2954685631.py\", line 26, in answer_evaluator\n",
      "    score = answer_grader.invoke({\"question\": input_question,\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langchain_core/runnables/base.py\", line 3024, in invoke\n",
      "    input = context.run(step.invoke, input, config)\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langchain_core/runnables/base.py\", line 5354, in invoke\n",
      "    return self.bound.invoke(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langchain_core/language_models/chat_models.py\", line 286, in invoke\n",
      "    self.generate_prompt(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langchain_core/language_models/chat_models.py\", line 786, in generate_prompt\n",
      "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langchain_core/language_models/chat_models.py\", line 643, in generate\n",
      "    raise e\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langchain_core/language_models/chat_models.py\", line 633, in generate\n",
      "    self._generate_with_cache(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langchain_core/language_models/chat_models.py\", line 851, in _generate_with_cache\n",
      "    result = self._generate(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langchain_openai/chat_models/base.py\", line 689, in _generate\n",
      "    response = self.client.create(**payload)\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 275, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/resources/chat/completions.py\", line 829, in create\n",
      "    return self._post(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/_base_client.py\", line 1280, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/_base_client.py\", line 957, in request\n",
      "    return self._request(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/_base_client.py\", line 1046, in _request\n",
      "    return self._retry_request(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/_base_client.py\", line 1095, in _retry_request\n",
      "    return self._request(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/_base_client.py\", line 1046, in _request\n",
      "    return self._retry_request(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/_base_client.py\", line 1095, in _retry_request\n",
      "    return self._request(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/_base_client.py\", line 1061, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o in organization org-CnOnLIaLFhfXUDRV6hWHsPkS on tokens per min (TPM): Limit 30000, Used 29677, Requested 520. Please try again in 394ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Error running evaluator <DynamicRunEvaluator answer_helpfulness_evaluator> on run fc17a617-0f44-4ff7-93f1-2c5e97a35460: RateLimitError(\"Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o in organization org-CnOnLIaLFhfXUDRV6hWHsPkS on tokens per min (TPM): Limit 30000, Used 29874, Requested 313. Please try again in 374ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\")\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/evaluation/_runner.py\", line 1404, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/evaluation/evaluator.py\", line 331, in evaluate_run\n",
      "    result = self.func(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 617, in wrapper\n",
      "    raise e\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 614, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "  File \"/var/folders/1l/w3vzbf215cs4ll30rh71l7wr6ghggx/T/ipykernel_62466/2954685631.py\", line 53, in answer_helpfulness_evaluator\n",
      "    score = answer_grader.invoke({\"question\": input_question,\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langchain_core/runnables/base.py\", line 3024, in invoke\n",
      "    input = context.run(step.invoke, input, config)\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langchain_core/runnables/base.py\", line 5354, in invoke\n",
      "    return self.bound.invoke(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langchain_core/language_models/chat_models.py\", line 286, in invoke\n",
      "    self.generate_prompt(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langchain_core/language_models/chat_models.py\", line 786, in generate_prompt\n",
      "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langchain_core/language_models/chat_models.py\", line 643, in generate\n",
      "    raise e\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langchain_core/language_models/chat_models.py\", line 633, in generate\n",
      "    self._generate_with_cache(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langchain_core/language_models/chat_models.py\", line 851, in _generate_with_cache\n",
      "    result = self._generate(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langchain_openai/chat_models/base.py\", line 689, in _generate\n",
      "    response = self.client.create(**payload)\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 275, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/resources/chat/completions.py\", line 829, in create\n",
      "    return self._post(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/_base_client.py\", line 1280, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/_base_client.py\", line 957, in request\n",
      "    return self._request(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/_base_client.py\", line 1046, in _request\n",
      "    return self._retry_request(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/_base_client.py\", line 1095, in _retry_request\n",
      "    return self._request(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/_base_client.py\", line 1046, in _request\n",
      "    return self._retry_request(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/_base_client.py\", line 1095, in _retry_request\n",
      "    return self._request(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/_base_client.py\", line 1061, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o in organization org-CnOnLIaLFhfXUDRV6hWHsPkS on tokens per min (TPM): Limit 30000, Used 29874, Requested 313. Please try again in 374ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Error running evaluator <DynamicRunEvaluator answer_helpfulness_evaluator> on run 5db7f2ff-c9cc-4772-bdd2-ac455af8736c: RateLimitError(\"Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o in organization org-CnOnLIaLFhfXUDRV6hWHsPkS on tokens per min (TPM): Limit 30000, Used 29866, Requested 319. Please try again in 370ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\")\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/evaluation/_runner.py\", line 1404, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/evaluation/evaluator.py\", line 331, in evaluate_run\n",
      "    result = self.func(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 617, in wrapper\n",
      "    raise e\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 614, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "  File \"/var/folders/1l/w3vzbf215cs4ll30rh71l7wr6ghggx/T/ipykernel_62466/2954685631.py\", line 53, in answer_helpfulness_evaluator\n",
      "    score = answer_grader.invoke({\"question\": input_question,\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langchain_core/runnables/base.py\", line 3024, in invoke\n",
      "    input = context.run(step.invoke, input, config)\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langchain_core/runnables/base.py\", line 5354, in invoke\n",
      "    return self.bound.invoke(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langchain_core/language_models/chat_models.py\", line 286, in invoke\n",
      "    self.generate_prompt(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langchain_core/language_models/chat_models.py\", line 786, in generate_prompt\n",
      "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langchain_core/language_models/chat_models.py\", line 643, in generate\n",
      "    raise e\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langchain_core/language_models/chat_models.py\", line 633, in generate\n",
      "    self._generate_with_cache(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langchain_core/language_models/chat_models.py\", line 851, in _generate_with_cache\n",
      "    result = self._generate(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langchain_openai/chat_models/base.py\", line 689, in _generate\n",
      "    response = self.client.create(**payload)\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 275, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/resources/chat/completions.py\", line 829, in create\n",
      "    return self._post(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/_base_client.py\", line 1280, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/_base_client.py\", line 957, in request\n",
      "    return self._request(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/_base_client.py\", line 1046, in _request\n",
      "    return self._retry_request(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/_base_client.py\", line 1095, in _retry_request\n",
      "    return self._request(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/_base_client.py\", line 1046, in _request\n",
      "    return self._retry_request(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/_base_client.py\", line 1095, in _retry_request\n",
      "    return self._request(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/_base_client.py\", line 1061, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o in organization org-CnOnLIaLFhfXUDRV6hWHsPkS on tokens per min (TPM): Limit 30000, Used 29866, Requested 319. Please try again in 370ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Error running evaluator <DynamicRunEvaluator answer_evaluator> on run fff1e71e-e2ca-4c6e-bda4-576e0acd0b9c: RateLimitError(\"Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o in organization org-CnOnLIaLFhfXUDRV6hWHsPkS on tokens per min (TPM): Limit 30000, Used 29694, Requested 597. Please try again in 582ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\")\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/evaluation/_runner.py\", line 1404, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/evaluation/evaluator.py\", line 331, in evaluate_run\n",
      "    result = self.func(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 617, in wrapper\n",
      "    raise e\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 614, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "  File \"/var/folders/1l/w3vzbf215cs4ll30rh71l7wr6ghggx/T/ipykernel_62466/2954685631.py\", line 26, in answer_evaluator\n",
      "    score = answer_grader.invoke({\"question\": input_question,\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langchain_core/runnables/base.py\", line 3024, in invoke\n",
      "    input = context.run(step.invoke, input, config)\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langchain_core/runnables/base.py\", line 5354, in invoke\n",
      "    return self.bound.invoke(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langchain_core/language_models/chat_models.py\", line 286, in invoke\n",
      "    self.generate_prompt(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langchain_core/language_models/chat_models.py\", line 786, in generate_prompt\n",
      "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langchain_core/language_models/chat_models.py\", line 643, in generate\n",
      "    raise e\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langchain_core/language_models/chat_models.py\", line 633, in generate\n",
      "    self._generate_with_cache(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langchain_core/language_models/chat_models.py\", line 851, in _generate_with_cache\n",
      "    result = self._generate(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langchain_openai/chat_models/base.py\", line 689, in _generate\n",
      "    response = self.client.create(**payload)\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 275, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/resources/chat/completions.py\", line 829, in create\n",
      "    return self._post(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/_base_client.py\", line 1280, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/_base_client.py\", line 957, in request\n",
      "    return self._request(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/_base_client.py\", line 1046, in _request\n",
      "    return self._retry_request(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/_base_client.py\", line 1095, in _retry_request\n",
      "    return self._request(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/_base_client.py\", line 1046, in _request\n",
      "    return self._retry_request(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/_base_client.py\", line 1095, in _retry_request\n",
      "    return self._request(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/_base_client.py\", line 1061, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o in organization org-CnOnLIaLFhfXUDRV6hWHsPkS on tokens per min (TPM): Limit 30000, Used 29694, Requested 597. Please try again in 582ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Error running evaluator <DynamicRunEvaluator answer_evaluator> on run 230e164f-b39d-4af6-bfd5-e0c0f249a71a: RateLimitError(\"Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o in organization org-CnOnLIaLFhfXUDRV6hWHsPkS on tokens per min (TPM): Limit 30000, Used 29562, Requested 574. Please try again in 272ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\")\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/evaluation/_runner.py\", line 1404, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/evaluation/evaluator.py\", line 331, in evaluate_run\n",
      "    result = self.func(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 617, in wrapper\n",
      "    raise e\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 614, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "  File \"/var/folders/1l/w3vzbf215cs4ll30rh71l7wr6ghggx/T/ipykernel_62466/2954685631.py\", line 26, in answer_evaluator\n",
      "    score = answer_grader.invoke({\"question\": input_question,\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langchain_core/runnables/base.py\", line 3024, in invoke\n",
      "    input = context.run(step.invoke, input, config)\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langchain_core/runnables/base.py\", line 5354, in invoke\n",
      "    return self.bound.invoke(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langchain_core/language_models/chat_models.py\", line 286, in invoke\n",
      "    self.generate_prompt(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langchain_core/language_models/chat_models.py\", line 786, in generate_prompt\n",
      "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langchain_core/language_models/chat_models.py\", line 643, in generate\n",
      "    raise e\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langchain_core/language_models/chat_models.py\", line 633, in generate\n",
      "    self._generate_with_cache(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langchain_core/language_models/chat_models.py\", line 851, in _generate_with_cache\n",
      "    result = self._generate(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langchain_openai/chat_models/base.py\", line 689, in _generate\n",
      "    response = self.client.create(**payload)\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 275, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/resources/chat/completions.py\", line 829, in create\n",
      "    return self._post(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/_base_client.py\", line 1280, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/_base_client.py\", line 957, in request\n",
      "    return self._request(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/_base_client.py\", line 1046, in _request\n",
      "    return self._retry_request(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/_base_client.py\", line 1095, in _retry_request\n",
      "    return self._request(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/_base_client.py\", line 1046, in _request\n",
      "    return self._retry_request(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/_base_client.py\", line 1095, in _retry_request\n",
      "    return self._request(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/_base_client.py\", line 1061, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o in organization org-CnOnLIaLFhfXUDRV6hWHsPkS on tokens per min (TPM): Limit 30000, Used 29562, Requested 574. Please try again in 272ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Error running target function: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o in organization org-CnOnLIaLFhfXUDRV6hWHsPkS on tokens per min (TPM): Limit 30000, Used 29556, Requested 3301. Please try again in 5.714s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/evaluation/_runner.py\", line 1675, in _forward\n",
      "    fn(example.inputs, langsmith_extra=langsmith_extra)\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 617, in wrapper\n",
      "    raise e\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 614, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "  File \"/var/folders/1l/w3vzbf215cs4ll30rh71l7wr6ghggx/T/ipykernel_62466/3191971669.py\", line 8, in predict_rag_answer_with_context\n",
      "    response = rag_bot.get_answer(example[\"input_question\"])\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 617, in wrapper\n",
      "    raise e\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 614, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "  File \"/var/folders/1l/w3vzbf215cs4ll30rh71l7wr6ghggx/T/ipykernel_62466/3657546987.py\", line 45, in get_answer\n",
      "    return self.invoke_llm(question, docs)\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 617, in wrapper\n",
      "    raise e\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 614, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "  File \"/var/folders/1l/w3vzbf215cs4ll30rh71l7wr6ghggx/T/ipykernel_62466/3657546987.py\", line 23, in invoke_llm\n",
      "    response = self._client.chat.completions.create(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/wrappers/_openai.py\", line 238, in create\n",
      "    return decorator(original_create)(*args, stream=stream, **kwargs)\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 617, in wrapper\n",
      "    raise e\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 614, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 275, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/resources/chat/completions.py\", line 829, in create\n",
      "    return self._post(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/_base_client.py\", line 1280, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/_base_client.py\", line 957, in request\n",
      "    return self._request(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/_base_client.py\", line 1046, in _request\n",
      "    return self._retry_request(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/_base_client.py\", line 1095, in _retry_request\n",
      "    return self._request(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/_base_client.py\", line 1046, in _request\n",
      "    return self._retry_request(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/_base_client.py\", line 1095, in _retry_request\n",
      "    return self._request(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/_base_client.py\", line 1061, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o in organization org-CnOnLIaLFhfXUDRV6hWHsPkS on tokens per min (TPM): Limit 30000, Used 29556, Requested 3301. Please try again in 5.714s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "1it [00:10, 10.16s/it]Error running evaluator <DynamicRunEvaluator answer_evaluator> on run 703c2c41-739d-47ae-aa94-74c51e095e9d: KeyError('answer')\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/evaluation/_runner.py\", line 1404, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/evaluation/evaluator.py\", line 331, in evaluate_run\n",
      "    result = self.func(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 617, in wrapper\n",
      "    raise e\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 614, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "  File \"/var/folders/1l/w3vzbf215cs4ll30rh71l7wr6ghggx/T/ipykernel_62466/2954685631.py\", line 16, in answer_evaluator\n",
      "    prediction = run.outputs[\"answer\"]\n",
      "KeyError: 'answer'\n",
      "Error running evaluator <DynamicRunEvaluator answer_helpfulness_evaluator> on run 703c2c41-739d-47ae-aa94-74c51e095e9d: KeyError('answer')\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/evaluation/_runner.py\", line 1404, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/evaluation/evaluator.py\", line 331, in evaluate_run\n",
      "    result = self.func(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 617, in wrapper\n",
      "    raise e\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 614, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "  File \"/var/folders/1l/w3vzbf215cs4ll30rh71l7wr6ghggx/T/ipykernel_62466/2954685631.py\", line 43, in answer_helpfulness_evaluator\n",
      "    prediction = run.outputs[\"answer\"]\n",
      "KeyError: 'answer'\n",
      "Error running target function: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o in organization org-CnOnLIaLFhfXUDRV6hWHsPkS on tokens per min (TPM): Limit 30000, Used 29553, Requested 3296. Please try again in 5.698s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/evaluation/_runner.py\", line 1675, in _forward\n",
      "    fn(example.inputs, langsmith_extra=langsmith_extra)\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 617, in wrapper\n",
      "    raise e\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 614, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "  File \"/var/folders/1l/w3vzbf215cs4ll30rh71l7wr6ghggx/T/ipykernel_62466/3191971669.py\", line 8, in predict_rag_answer_with_context\n",
      "    response = rag_bot.get_answer(example[\"input_question\"])\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 617, in wrapper\n",
      "    raise e\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 614, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "  File \"/var/folders/1l/w3vzbf215cs4ll30rh71l7wr6ghggx/T/ipykernel_62466/3657546987.py\", line 45, in get_answer\n",
      "    return self.invoke_llm(question, docs)\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 617, in wrapper\n",
      "    raise e\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 614, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "  File \"/var/folders/1l/w3vzbf215cs4ll30rh71l7wr6ghggx/T/ipykernel_62466/3657546987.py\", line 23, in invoke_llm\n",
      "    response = self._client.chat.completions.create(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/wrappers/_openai.py\", line 238, in create\n",
      "    return decorator(original_create)(*args, stream=stream, **kwargs)\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 617, in wrapper\n",
      "    raise e\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 614, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 275, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/resources/chat/completions.py\", line 829, in create\n",
      "    return self._post(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/_base_client.py\", line 1280, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/_base_client.py\", line 957, in request\n",
      "    return self._request(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/_base_client.py\", line 1046, in _request\n",
      "    return self._retry_request(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/_base_client.py\", line 1095, in _retry_request\n",
      "    return self._request(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/_base_client.py\", line 1046, in _request\n",
      "    return self._retry_request(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/_base_client.py\", line 1095, in _retry_request\n",
      "    return self._request(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/_base_client.py\", line 1061, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o in organization org-CnOnLIaLFhfXUDRV6hWHsPkS on tokens per min (TPM): Limit 30000, Used 29553, Requested 3296. Please try again in 5.698s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Error running evaluator <DynamicRunEvaluator answer_evaluator> on run 49938d62-a123-4e2a-8bbe-45c4668f19c0: KeyError('answer')\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/evaluation/_runner.py\", line 1404, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/evaluation/evaluator.py\", line 331, in evaluate_run\n",
      "    result = self.func(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 617, in wrapper\n",
      "    raise e\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 614, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "  File \"/var/folders/1l/w3vzbf215cs4ll30rh71l7wr6ghggx/T/ipykernel_62466/2954685631.py\", line 16, in answer_evaluator\n",
      "    prediction = run.outputs[\"answer\"]\n",
      "KeyError: 'answer'\n",
      "Error running evaluator <DynamicRunEvaluator answer_helpfulness_evaluator> on run 49938d62-a123-4e2a-8bbe-45c4668f19c0: KeyError('answer')\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/evaluation/_runner.py\", line 1404, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/evaluation/evaluator.py\", line 331, in evaluate_run\n",
      "    result = self.func(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 617, in wrapper\n",
      "    raise e\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 614, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "  File \"/var/folders/1l/w3vzbf215cs4ll30rh71l7wr6ghggx/T/ipykernel_62466/2954685631.py\", line 43, in answer_helpfulness_evaluator\n",
      "    prediction = run.outputs[\"answer\"]\n",
      "KeyError: 'answer'\n",
      "Error running target function: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o in organization org-CnOnLIaLFhfXUDRV6hWHsPkS on tokens per min (TPM): Limit 30000, Used 29569, Requested 3304. Please try again in 5.746s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/evaluation/_runner.py\", line 1675, in _forward\n",
      "    fn(example.inputs, langsmith_extra=langsmith_extra)\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 617, in wrapper\n",
      "    raise e\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 614, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "  File \"/var/folders/1l/w3vzbf215cs4ll30rh71l7wr6ghggx/T/ipykernel_62466/3191971669.py\", line 8, in predict_rag_answer_with_context\n",
      "    response = rag_bot.get_answer(example[\"input_question\"])\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 617, in wrapper\n",
      "    raise e\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 614, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "  File \"/var/folders/1l/w3vzbf215cs4ll30rh71l7wr6ghggx/T/ipykernel_62466/3657546987.py\", line 45, in get_answer\n",
      "    return self.invoke_llm(question, docs)\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 617, in wrapper\n",
      "    raise e\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 614, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "  File \"/var/folders/1l/w3vzbf215cs4ll30rh71l7wr6ghggx/T/ipykernel_62466/3657546987.py\", line 23, in invoke_llm\n",
      "    response = self._client.chat.completions.create(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/wrappers/_openai.py\", line 238, in create\n",
      "    return decorator(original_create)(*args, stream=stream, **kwargs)\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 617, in wrapper\n",
      "    raise e\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 614, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 275, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/resources/chat/completions.py\", line 829, in create\n",
      "    return self._post(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/_base_client.py\", line 1280, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/_base_client.py\", line 957, in request\n",
      "    return self._request(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/_base_client.py\", line 1046, in _request\n",
      "    return self._retry_request(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/_base_client.py\", line 1095, in _retry_request\n",
      "    return self._request(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/_base_client.py\", line 1046, in _request\n",
      "    return self._retry_request(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/_base_client.py\", line 1095, in _retry_request\n",
      "    return self._request(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/_base_client.py\", line 1061, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o in organization org-CnOnLIaLFhfXUDRV6hWHsPkS on tokens per min (TPM): Limit 30000, Used 29569, Requested 3304. Please try again in 5.746s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Error running evaluator <DynamicRunEvaluator answer_evaluator> on run 29686ee7-5fd7-4f5f-bd7b-c0af450879ea: KeyError('answer')\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/evaluation/_runner.py\", line 1404, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/evaluation/evaluator.py\", line 331, in evaluate_run\n",
      "    result = self.func(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 617, in wrapper\n",
      "    raise e\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 614, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "  File \"/var/folders/1l/w3vzbf215cs4ll30rh71l7wr6ghggx/T/ipykernel_62466/2954685631.py\", line 16, in answer_evaluator\n",
      "    prediction = run.outputs[\"answer\"]\n",
      "KeyError: 'answer'\n",
      "Error running evaluator <DynamicRunEvaluator answer_helpfulness_evaluator> on run 29686ee7-5fd7-4f5f-bd7b-c0af450879ea: KeyError('answer')\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/evaluation/_runner.py\", line 1404, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/evaluation/evaluator.py\", line 331, in evaluate_run\n",
      "    result = self.func(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 617, in wrapper\n",
      "    raise e\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 614, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "  File \"/var/folders/1l/w3vzbf215cs4ll30rh71l7wr6ghggx/T/ipykernel_62466/2954685631.py\", line 43, in answer_helpfulness_evaluator\n",
      "    prediction = run.outputs[\"answer\"]\n",
      "KeyError: 'answer'\n",
      "Error running target function: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o in organization org-CnOnLIaLFhfXUDRV6hWHsPkS on tokens per min (TPM): Limit 30000, Used 29478, Requested 3365. Please try again in 5.686s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/evaluation/_runner.py\", line 1675, in _forward\n",
      "    fn(example.inputs, langsmith_extra=langsmith_extra)\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 617, in wrapper\n",
      "    raise e\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 614, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "  File \"/var/folders/1l/w3vzbf215cs4ll30rh71l7wr6ghggx/T/ipykernel_62466/3191971669.py\", line 8, in predict_rag_answer_with_context\n",
      "    response = rag_bot.get_answer(example[\"input_question\"])\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 617, in wrapper\n",
      "    raise e\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 614, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "  File \"/var/folders/1l/w3vzbf215cs4ll30rh71l7wr6ghggx/T/ipykernel_62466/3657546987.py\", line 45, in get_answer\n",
      "    return self.invoke_llm(question, docs)\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 617, in wrapper\n",
      "    raise e\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 614, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "  File \"/var/folders/1l/w3vzbf215cs4ll30rh71l7wr6ghggx/T/ipykernel_62466/3657546987.py\", line 23, in invoke_llm\n",
      "    response = self._client.chat.completions.create(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/wrappers/_openai.py\", line 238, in create\n",
      "    return decorator(original_create)(*args, stream=stream, **kwargs)\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 617, in wrapper\n",
      "    raise e\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 614, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 275, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/resources/chat/completions.py\", line 829, in create\n",
      "    return self._post(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/_base_client.py\", line 1280, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/_base_client.py\", line 957, in request\n",
      "    return self._request(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/_base_client.py\", line 1046, in _request\n",
      "    return self._retry_request(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/_base_client.py\", line 1095, in _retry_request\n",
      "    return self._request(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/_base_client.py\", line 1046, in _request\n",
      "    return self._retry_request(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/_base_client.py\", line 1095, in _retry_request\n",
      "    return self._request(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/_base_client.py\", line 1061, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o in organization org-CnOnLIaLFhfXUDRV6hWHsPkS on tokens per min (TPM): Limit 30000, Used 29478, Requested 3365. Please try again in 5.686s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "7it [00:10,  1.09s/it]Error running evaluator <DynamicRunEvaluator answer_evaluator> on run 1dfabafb-af94-43c2-9a94-36d86a5f457b: KeyError('answer')\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/evaluation/_runner.py\", line 1404, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/evaluation/evaluator.py\", line 331, in evaluate_run\n",
      "    result = self.func(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 617, in wrapper\n",
      "    raise e\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 614, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "  File \"/var/folders/1l/w3vzbf215cs4ll30rh71l7wr6ghggx/T/ipykernel_62466/2954685631.py\", line 16, in answer_evaluator\n",
      "    prediction = run.outputs[\"answer\"]\n",
      "KeyError: 'answer'\n",
      "Error running evaluator <DynamicRunEvaluator answer_helpfulness_evaluator> on run 1dfabafb-af94-43c2-9a94-36d86a5f457b: KeyError('answer')\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/evaluation/_runner.py\", line 1404, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/evaluation/evaluator.py\", line 331, in evaluate_run\n",
      "    result = self.func(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 617, in wrapper\n",
      "    raise e\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 614, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "  File \"/var/folders/1l/w3vzbf215cs4ll30rh71l7wr6ghggx/T/ipykernel_62466/2954685631.py\", line 43, in answer_helpfulness_evaluator\n",
      "    prediction = run.outputs[\"answer\"]\n",
      "KeyError: 'answer'\n",
      "Error running target function: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o in organization org-CnOnLIaLFhfXUDRV6hWHsPkS on tokens per min (TPM): Limit 30000, Used 29432, Requested 3398. Please try again in 5.66s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/evaluation/_runner.py\", line 1675, in _forward\n",
      "    fn(example.inputs, langsmith_extra=langsmith_extra)\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 617, in wrapper\n",
      "    raise e\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 614, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "  File \"/var/folders/1l/w3vzbf215cs4ll30rh71l7wr6ghggx/T/ipykernel_62466/3191971669.py\", line 8, in predict_rag_answer_with_context\n",
      "    response = rag_bot.get_answer(example[\"input_question\"])\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 617, in wrapper\n",
      "    raise e\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 614, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "  File \"/var/folders/1l/w3vzbf215cs4ll30rh71l7wr6ghggx/T/ipykernel_62466/3657546987.py\", line 45, in get_answer\n",
      "    return self.invoke_llm(question, docs)\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 617, in wrapper\n",
      "    raise e\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 614, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "  File \"/var/folders/1l/w3vzbf215cs4ll30rh71l7wr6ghggx/T/ipykernel_62466/3657546987.py\", line 23, in invoke_llm\n",
      "    response = self._client.chat.completions.create(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/wrappers/_openai.py\", line 238, in create\n",
      "    return decorator(original_create)(*args, stream=stream, **kwargs)\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 617, in wrapper\n",
      "    raise e\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 614, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 275, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/resources/chat/completions.py\", line 829, in create\n",
      "    return self._post(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/_base_client.py\", line 1280, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/_base_client.py\", line 957, in request\n",
      "    return self._request(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/_base_client.py\", line 1046, in _request\n",
      "    return self._retry_request(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/_base_client.py\", line 1095, in _retry_request\n",
      "    return self._request(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/_base_client.py\", line 1046, in _request\n",
      "    return self._retry_request(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/_base_client.py\", line 1095, in _retry_request\n",
      "    return self._request(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/_base_client.py\", line 1061, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o in organization org-CnOnLIaLFhfXUDRV6hWHsPkS on tokens per min (TPM): Limit 30000, Used 29432, Requested 3398. Please try again in 5.66s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Error running evaluator <DynamicRunEvaluator answer_evaluator> on run a854bbdd-b349-44f7-ad06-9169f112337c: KeyError('answer')\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/evaluation/_runner.py\", line 1404, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/evaluation/evaluator.py\", line 331, in evaluate_run\n",
      "    result = self.func(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 617, in wrapper\n",
      "    raise e\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 614, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "  File \"/var/folders/1l/w3vzbf215cs4ll30rh71l7wr6ghggx/T/ipykernel_62466/2954685631.py\", line 16, in answer_evaluator\n",
      "    prediction = run.outputs[\"answer\"]\n",
      "KeyError: 'answer'\n",
      "Error running evaluator <DynamicRunEvaluator answer_helpfulness_evaluator> on run a854bbdd-b349-44f7-ad06-9169f112337c: KeyError('answer')\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/evaluation/_runner.py\", line 1404, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/evaluation/evaluator.py\", line 331, in evaluate_run\n",
      "    result = self.func(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 617, in wrapper\n",
      "    raise e\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 614, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "  File \"/var/folders/1l/w3vzbf215cs4ll30rh71l7wr6ghggx/T/ipykernel_62466/2954685631.py\", line 43, in answer_helpfulness_evaluator\n",
      "    prediction = run.outputs[\"answer\"]\n",
      "KeyError: 'answer'\n",
      "Error running evaluator <DynamicRunEvaluator answer_helpfulness_evaluator> on run fff1e71e-e2ca-4c6e-bda4-576e0acd0b9c: RateLimitError(\"Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o in organization org-CnOnLIaLFhfXUDRV6hWHsPkS on tokens per min (TPM): Limit 30000, Used 29812, Requested 491. Please try again in 606ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\")\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/evaluation/_runner.py\", line 1404, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/evaluation/evaluator.py\", line 331, in evaluate_run\n",
      "    result = self.func(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 617, in wrapper\n",
      "    raise e\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 614, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "  File \"/var/folders/1l/w3vzbf215cs4ll30rh71l7wr6ghggx/T/ipykernel_62466/2954685631.py\", line 53, in answer_helpfulness_evaluator\n",
      "    score = answer_grader.invoke({\"question\": input_question,\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langchain_core/runnables/base.py\", line 3024, in invoke\n",
      "    input = context.run(step.invoke, input, config)\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langchain_core/runnables/base.py\", line 5354, in invoke\n",
      "    return self.bound.invoke(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langchain_core/language_models/chat_models.py\", line 286, in invoke\n",
      "    self.generate_prompt(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langchain_core/language_models/chat_models.py\", line 786, in generate_prompt\n",
      "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langchain_core/language_models/chat_models.py\", line 643, in generate\n",
      "    raise e\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langchain_core/language_models/chat_models.py\", line 633, in generate\n",
      "    self._generate_with_cache(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langchain_core/language_models/chat_models.py\", line 851, in _generate_with_cache\n",
      "    result = self._generate(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langchain_openai/chat_models/base.py\", line 689, in _generate\n",
      "    response = self.client.create(**payload)\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 275, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/resources/chat/completions.py\", line 829, in create\n",
      "    return self._post(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/_base_client.py\", line 1280, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/_base_client.py\", line 957, in request\n",
      "    return self._request(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/_base_client.py\", line 1046, in _request\n",
      "    return self._retry_request(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/_base_client.py\", line 1095, in _retry_request\n",
      "    return self._request(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/_base_client.py\", line 1046, in _request\n",
      "    return self._retry_request(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/_base_client.py\", line 1095, in _retry_request\n",
      "    return self._request(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/_base_client.py\", line 1061, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o in organization org-CnOnLIaLFhfXUDRV6hWHsPkS on tokens per min (TPM): Limit 30000, Used 29812, Requested 491. Please try again in 606ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "11it [00:14,  1.03s/it]Error running target function: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o in organization org-CnOnLIaLFhfXUDRV6hWHsPkS on tokens per min (TPM): Limit 30000, Used 29512, Requested 3299. Please try again in 5.622s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/evaluation/_runner.py\", line 1675, in _forward\n",
      "    fn(example.inputs, langsmith_extra=langsmith_extra)\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 617, in wrapper\n",
      "    raise e\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 614, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "  File \"/var/folders/1l/w3vzbf215cs4ll30rh71l7wr6ghggx/T/ipykernel_62466/3191971669.py\", line 8, in predict_rag_answer_with_context\n",
      "    response = rag_bot.get_answer(example[\"input_question\"])\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 617, in wrapper\n",
      "    raise e\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 614, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "  File \"/var/folders/1l/w3vzbf215cs4ll30rh71l7wr6ghggx/T/ipykernel_62466/3657546987.py\", line 45, in get_answer\n",
      "    return self.invoke_llm(question, docs)\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 617, in wrapper\n",
      "    raise e\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 614, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "  File \"/var/folders/1l/w3vzbf215cs4ll30rh71l7wr6ghggx/T/ipykernel_62466/3657546987.py\", line 23, in invoke_llm\n",
      "    response = self._client.chat.completions.create(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/wrappers/_openai.py\", line 238, in create\n",
      "    return decorator(original_create)(*args, stream=stream, **kwargs)\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 617, in wrapper\n",
      "    raise e\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 614, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 275, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/resources/chat/completions.py\", line 829, in create\n",
      "    return self._post(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/_base_client.py\", line 1280, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/_base_client.py\", line 957, in request\n",
      "    return self._request(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/_base_client.py\", line 1046, in _request\n",
      "    return self._retry_request(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/_base_client.py\", line 1095, in _retry_request\n",
      "    return self._request(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/_base_client.py\", line 1046, in _request\n",
      "    return self._retry_request(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/_base_client.py\", line 1095, in _retry_request\n",
      "    return self._request(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/_base_client.py\", line 1061, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o in organization org-CnOnLIaLFhfXUDRV6hWHsPkS on tokens per min (TPM): Limit 30000, Used 29512, Requested 3299. Please try again in 5.622s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Error running evaluator <DynamicRunEvaluator answer_evaluator> on run 4b418a61-da31-4bc8-967a-7ad2a509665d: KeyError('answer')\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/evaluation/_runner.py\", line 1404, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/evaluation/evaluator.py\", line 331, in evaluate_run\n",
      "    result = self.func(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 617, in wrapper\n",
      "    raise e\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 614, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "  File \"/var/folders/1l/w3vzbf215cs4ll30rh71l7wr6ghggx/T/ipykernel_62466/2954685631.py\", line 16, in answer_evaluator\n",
      "    prediction = run.outputs[\"answer\"]\n",
      "KeyError: 'answer'\n",
      "Error running evaluator <DynamicRunEvaluator answer_helpfulness_evaluator> on run 4b418a61-da31-4bc8-967a-7ad2a509665d: KeyError('answer')\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/evaluation/_runner.py\", line 1404, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/evaluation/evaluator.py\", line 331, in evaluate_run\n",
      "    result = self.func(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 617, in wrapper\n",
      "    raise e\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 614, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "  File \"/var/folders/1l/w3vzbf215cs4ll30rh71l7wr6ghggx/T/ipykernel_62466/2954685631.py\", line 43, in answer_helpfulness_evaluator\n",
      "    prediction = run.outputs[\"answer\"]\n",
      "KeyError: 'answer'\n",
      "Error running target function: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o in organization org-CnOnLIaLFhfXUDRV6hWHsPkS on tokens per min (TPM): Limit 30000, Used 29501, Requested 3372. Please try again in 5.746s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/evaluation/_runner.py\", line 1675, in _forward\n",
      "    fn(example.inputs, langsmith_extra=langsmith_extra)\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 617, in wrapper\n",
      "    raise e\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 614, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "  File \"/var/folders/1l/w3vzbf215cs4ll30rh71l7wr6ghggx/T/ipykernel_62466/3191971669.py\", line 8, in predict_rag_answer_with_context\n",
      "    response = rag_bot.get_answer(example[\"input_question\"])\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 617, in wrapper\n",
      "    raise e\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 614, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "  File \"/var/folders/1l/w3vzbf215cs4ll30rh71l7wr6ghggx/T/ipykernel_62466/3657546987.py\", line 45, in get_answer\n",
      "    return self.invoke_llm(question, docs)\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 617, in wrapper\n",
      "    raise e\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 614, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "  File \"/var/folders/1l/w3vzbf215cs4ll30rh71l7wr6ghggx/T/ipykernel_62466/3657546987.py\", line 23, in invoke_llm\n",
      "    response = self._client.chat.completions.create(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/wrappers/_openai.py\", line 238, in create\n",
      "    return decorator(original_create)(*args, stream=stream, **kwargs)\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 617, in wrapper\n",
      "    raise e\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 614, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 275, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/resources/chat/completions.py\", line 829, in create\n",
      "    return self._post(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/_base_client.py\", line 1280, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/_base_client.py\", line 957, in request\n",
      "    return self._request(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/_base_client.py\", line 1046, in _request\n",
      "    return self._retry_request(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/_base_client.py\", line 1095, in _retry_request\n",
      "    return self._request(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/_base_client.py\", line 1046, in _request\n",
      "    return self._retry_request(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/_base_client.py\", line 1095, in _retry_request\n",
      "    return self._request(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/_base_client.py\", line 1061, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o in organization org-CnOnLIaLFhfXUDRV6hWHsPkS on tokens per min (TPM): Limit 30000, Used 29501, Requested 3372. Please try again in 5.746s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "14it [00:17,  1.07s/it]Error running evaluator <DynamicRunEvaluator answer_evaluator> on run 4a944464-38dc-4d3f-96d9-1c0b97badb7a: KeyError('answer')\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/evaluation/_runner.py\", line 1404, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/evaluation/evaluator.py\", line 331, in evaluate_run\n",
      "    result = self.func(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 617, in wrapper\n",
      "    raise e\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 614, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "  File \"/var/folders/1l/w3vzbf215cs4ll30rh71l7wr6ghggx/T/ipykernel_62466/2954685631.py\", line 16, in answer_evaluator\n",
      "    prediction = run.outputs[\"answer\"]\n",
      "KeyError: 'answer'\n",
      "Error running evaluator <DynamicRunEvaluator answer_helpfulness_evaluator> on run 4a944464-38dc-4d3f-96d9-1c0b97badb7a: KeyError('answer')\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/evaluation/_runner.py\", line 1404, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/evaluation/evaluator.py\", line 331, in evaluate_run\n",
      "    result = self.func(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 617, in wrapper\n",
      "    raise e\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 614, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "  File \"/var/folders/1l/w3vzbf215cs4ll30rh71l7wr6ghggx/T/ipykernel_62466/2954685631.py\", line 43, in answer_helpfulness_evaluator\n",
      "    prediction = run.outputs[\"answer\"]\n",
      "KeyError: 'answer'\n",
      "Error running target function: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o in organization org-CnOnLIaLFhfXUDRV6hWHsPkS on tokens per min (TPM): Limit 30000, Used 29138, Requested 3365. Please try again in 5.006s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/evaluation/_runner.py\", line 1675, in _forward\n",
      "    fn(example.inputs, langsmith_extra=langsmith_extra)\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 617, in wrapper\n",
      "    raise e\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 614, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "  File \"/var/folders/1l/w3vzbf215cs4ll30rh71l7wr6ghggx/T/ipykernel_62466/3191971669.py\", line 8, in predict_rag_answer_with_context\n",
      "    response = rag_bot.get_answer(example[\"input_question\"])\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 617, in wrapper\n",
      "    raise e\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 614, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "  File \"/var/folders/1l/w3vzbf215cs4ll30rh71l7wr6ghggx/T/ipykernel_62466/3657546987.py\", line 45, in get_answer\n",
      "    return self.invoke_llm(question, docs)\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 617, in wrapper\n",
      "    raise e\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 614, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "  File \"/var/folders/1l/w3vzbf215cs4ll30rh71l7wr6ghggx/T/ipykernel_62466/3657546987.py\", line 23, in invoke_llm\n",
      "    response = self._client.chat.completions.create(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/wrappers/_openai.py\", line 238, in create\n",
      "    return decorator(original_create)(*args, stream=stream, **kwargs)\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 617, in wrapper\n",
      "    raise e\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 614, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 275, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/resources/chat/completions.py\", line 829, in create\n",
      "    return self._post(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/_base_client.py\", line 1280, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/_base_client.py\", line 957, in request\n",
      "    return self._request(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/_base_client.py\", line 1046, in _request\n",
      "    return self._retry_request(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/_base_client.py\", line 1095, in _retry_request\n",
      "    return self._request(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/_base_client.py\", line 1046, in _request\n",
      "    return self._retry_request(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/_base_client.py\", line 1095, in _retry_request\n",
      "    return self._request(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/_base_client.py\", line 1061, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o in organization org-CnOnLIaLFhfXUDRV6hWHsPkS on tokens per min (TPM): Limit 30000, Used 29138, Requested 3365. Please try again in 5.006s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "15it [00:18,  1.02s/it]Error running evaluator <DynamicRunEvaluator answer_evaluator> on run a2c40c6d-9cb4-45e2-bff4-537c2893f618: KeyError('answer')\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/evaluation/_runner.py\", line 1404, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/evaluation/evaluator.py\", line 331, in evaluate_run\n",
      "    result = self.func(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 617, in wrapper\n",
      "    raise e\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 614, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "  File \"/var/folders/1l/w3vzbf215cs4ll30rh71l7wr6ghggx/T/ipykernel_62466/2954685631.py\", line 16, in answer_evaluator\n",
      "    prediction = run.outputs[\"answer\"]\n",
      "KeyError: 'answer'\n",
      "Error running evaluator <DynamicRunEvaluator answer_helpfulness_evaluator> on run a2c40c6d-9cb4-45e2-bff4-537c2893f618: KeyError('answer')\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/evaluation/_runner.py\", line 1404, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/evaluation/evaluator.py\", line 331, in evaluate_run\n",
      "    result = self.func(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 617, in wrapper\n",
      "    raise e\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 614, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "  File \"/var/folders/1l/w3vzbf215cs4ll30rh71l7wr6ghggx/T/ipykernel_62466/2954685631.py\", line 43, in answer_helpfulness_evaluator\n",
      "    prediction = run.outputs[\"answer\"]\n",
      "KeyError: 'answer'\n",
      "Error running target function: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o in organization org-CnOnLIaLFhfXUDRV6hWHsPkS on tokens per min (TPM): Limit 30000, Used 28986, Requested 3597. Please try again in 5.166s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/evaluation/_runner.py\", line 1675, in _forward\n",
      "    fn(example.inputs, langsmith_extra=langsmith_extra)\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 617, in wrapper\n",
      "    raise e\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 614, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "  File \"/var/folders/1l/w3vzbf215cs4ll30rh71l7wr6ghggx/T/ipykernel_62466/3191971669.py\", line 8, in predict_rag_answer_with_context\n",
      "    response = rag_bot.get_answer(example[\"input_question\"])\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 617, in wrapper\n",
      "    raise e\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 614, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "  File \"/var/folders/1l/w3vzbf215cs4ll30rh71l7wr6ghggx/T/ipykernel_62466/3657546987.py\", line 45, in get_answer\n",
      "    return self.invoke_llm(question, docs)\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 617, in wrapper\n",
      "    raise e\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 614, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "  File \"/var/folders/1l/w3vzbf215cs4ll30rh71l7wr6ghggx/T/ipykernel_62466/3657546987.py\", line 23, in invoke_llm\n",
      "    response = self._client.chat.completions.create(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/wrappers/_openai.py\", line 238, in create\n",
      "    return decorator(original_create)(*args, stream=stream, **kwargs)\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 617, in wrapper\n",
      "    raise e\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 614, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 275, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/resources/chat/completions.py\", line 829, in create\n",
      "    return self._post(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/_base_client.py\", line 1280, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/_base_client.py\", line 957, in request\n",
      "    return self._request(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/_base_client.py\", line 1046, in _request\n",
      "    return self._retry_request(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/_base_client.py\", line 1095, in _retry_request\n",
      "    return self._request(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/_base_client.py\", line 1046, in _request\n",
      "    return self._retry_request(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/_base_client.py\", line 1095, in _retry_request\n",
      "    return self._request(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/_base_client.py\", line 1061, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o in organization org-CnOnLIaLFhfXUDRV6hWHsPkS on tokens per min (TPM): Limit 30000, Used 28986, Requested 3597. Please try again in 5.166s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "16it [00:18,  1.11it/s]Error running evaluator <DynamicRunEvaluator answer_evaluator> on run fda6f5ec-6ed2-4c90-aef7-59e0732e2290: KeyError('answer')\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/evaluation/_runner.py\", line 1404, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/evaluation/evaluator.py\", line 331, in evaluate_run\n",
      "    result = self.func(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 617, in wrapper\n",
      "    raise e\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 614, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "  File \"/var/folders/1l/w3vzbf215cs4ll30rh71l7wr6ghggx/T/ipykernel_62466/2954685631.py\", line 16, in answer_evaluator\n",
      "    prediction = run.outputs[\"answer\"]\n",
      "KeyError: 'answer'\n",
      "Error running evaluator <DynamicRunEvaluator answer_helpfulness_evaluator> on run fda6f5ec-6ed2-4c90-aef7-59e0732e2290: KeyError('answer')\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/evaluation/_runner.py\", line 1404, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/evaluation/evaluator.py\", line 331, in evaluate_run\n",
      "    result = self.func(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 617, in wrapper\n",
      "    raise e\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 614, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "  File \"/var/folders/1l/w3vzbf215cs4ll30rh71l7wr6ghggx/T/ipykernel_62466/2954685631.py\", line 43, in answer_helpfulness_evaluator\n",
      "    prediction = run.outputs[\"answer\"]\n",
      "KeyError: 'answer'\n",
      "Error running target function: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o in organization org-CnOnLIaLFhfXUDRV6hWHsPkS on tokens per min (TPM): Limit 30000, Used 28131, Requested 3302. Please try again in 2.866s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/evaluation/_runner.py\", line 1675, in _forward\n",
      "    fn(example.inputs, langsmith_extra=langsmith_extra)\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 617, in wrapper\n",
      "    raise e\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 614, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "  File \"/var/folders/1l/w3vzbf215cs4ll30rh71l7wr6ghggx/T/ipykernel_62466/3191971669.py\", line 8, in predict_rag_answer_with_context\n",
      "    response = rag_bot.get_answer(example[\"input_question\"])\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 617, in wrapper\n",
      "    raise e\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 614, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "  File \"/var/folders/1l/w3vzbf215cs4ll30rh71l7wr6ghggx/T/ipykernel_62466/3657546987.py\", line 45, in get_answer\n",
      "    return self.invoke_llm(question, docs)\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 617, in wrapper\n",
      "    raise e\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 614, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "  File \"/var/folders/1l/w3vzbf215cs4ll30rh71l7wr6ghggx/T/ipykernel_62466/3657546987.py\", line 23, in invoke_llm\n",
      "    response = self._client.chat.completions.create(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/wrappers/_openai.py\", line 238, in create\n",
      "    return decorator(original_create)(*args, stream=stream, **kwargs)\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 617, in wrapper\n",
      "    raise e\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 614, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 275, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/resources/chat/completions.py\", line 829, in create\n",
      "    return self._post(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/_base_client.py\", line 1280, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/_base_client.py\", line 957, in request\n",
      "    return self._request(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/_base_client.py\", line 1046, in _request\n",
      "    return self._retry_request(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/_base_client.py\", line 1095, in _retry_request\n",
      "    return self._request(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/_base_client.py\", line 1046, in _request\n",
      "    return self._retry_request(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/_base_client.py\", line 1095, in _retry_request\n",
      "    return self._request(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/_base_client.py\", line 1061, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o in organization org-CnOnLIaLFhfXUDRV6hWHsPkS on tokens per min (TPM): Limit 30000, Used 28131, Requested 3302. Please try again in 2.866s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "17it [00:20,  1.06s/it]Error running evaluator <DynamicRunEvaluator answer_evaluator> on run 64d3f5bc-1699-4c98-a13d-ad0789dc1d11: KeyError('answer')\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/evaluation/_runner.py\", line 1404, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/evaluation/evaluator.py\", line 331, in evaluate_run\n",
      "    result = self.func(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 617, in wrapper\n",
      "    raise e\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 614, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "  File \"/var/folders/1l/w3vzbf215cs4ll30rh71l7wr6ghggx/T/ipykernel_62466/2954685631.py\", line 16, in answer_evaluator\n",
      "    prediction = run.outputs[\"answer\"]\n",
      "KeyError: 'answer'\n",
      "Error running evaluator <DynamicRunEvaluator answer_helpfulness_evaluator> on run 64d3f5bc-1699-4c98-a13d-ad0789dc1d11: KeyError('answer')\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/evaluation/_runner.py\", line 1404, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/evaluation/evaluator.py\", line 331, in evaluate_run\n",
      "    result = self.func(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 617, in wrapper\n",
      "    raise e\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 614, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "  File \"/var/folders/1l/w3vzbf215cs4ll30rh71l7wr6ghggx/T/ipykernel_62466/2954685631.py\", line 43, in answer_helpfulness_evaluator\n",
      "    prediction = run.outputs[\"answer\"]\n",
      "KeyError: 'answer'\n",
      "Error running target function: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o in organization org-CnOnLIaLFhfXUDRV6hWHsPkS on tokens per min (TPM): Limit 30000, Used 28115, Requested 3337. Please try again in 2.904s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/evaluation/_runner.py\", line 1675, in _forward\n",
      "    fn(example.inputs, langsmith_extra=langsmith_extra)\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 617, in wrapper\n",
      "    raise e\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 614, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "  File \"/var/folders/1l/w3vzbf215cs4ll30rh71l7wr6ghggx/T/ipykernel_62466/3191971669.py\", line 8, in predict_rag_answer_with_context\n",
      "    response = rag_bot.get_answer(example[\"input_question\"])\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 617, in wrapper\n",
      "    raise e\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 614, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "  File \"/var/folders/1l/w3vzbf215cs4ll30rh71l7wr6ghggx/T/ipykernel_62466/3657546987.py\", line 45, in get_answer\n",
      "    return self.invoke_llm(question, docs)\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 617, in wrapper\n",
      "    raise e\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 614, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "  File \"/var/folders/1l/w3vzbf215cs4ll30rh71l7wr6ghggx/T/ipykernel_62466/3657546987.py\", line 23, in invoke_llm\n",
      "    response = self._client.chat.completions.create(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/wrappers/_openai.py\", line 238, in create\n",
      "    return decorator(original_create)(*args, stream=stream, **kwargs)\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 617, in wrapper\n",
      "    raise e\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 614, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 275, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/resources/chat/completions.py\", line 829, in create\n",
      "    return self._post(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/_base_client.py\", line 1280, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/_base_client.py\", line 957, in request\n",
      "    return self._request(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/_base_client.py\", line 1046, in _request\n",
      "    return self._retry_request(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/_base_client.py\", line 1095, in _retry_request\n",
      "    return self._request(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/_base_client.py\", line 1046, in _request\n",
      "    return self._retry_request(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/_base_client.py\", line 1095, in _retry_request\n",
      "    return self._request(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/_base_client.py\", line 1061, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o in organization org-CnOnLIaLFhfXUDRV6hWHsPkS on tokens per min (TPM): Limit 30000, Used 28115, Requested 3337. Please try again in 2.904s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Error running evaluator <DynamicRunEvaluator answer_evaluator> on run c74648ce-766a-40db-8d9b-fe9f2d053eb9: KeyError('answer')\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/evaluation/_runner.py\", line 1404, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/evaluation/evaluator.py\", line 331, in evaluate_run\n",
      "    result = self.func(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 617, in wrapper\n",
      "    raise e\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 614, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "  File \"/var/folders/1l/w3vzbf215cs4ll30rh71l7wr6ghggx/T/ipykernel_62466/2954685631.py\", line 16, in answer_evaluator\n",
      "    prediction = run.outputs[\"answer\"]\n",
      "KeyError: 'answer'\n",
      "Error running evaluator <DynamicRunEvaluator answer_helpfulness_evaluator> on run c74648ce-766a-40db-8d9b-fe9f2d053eb9: KeyError('answer')\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/evaluation/_runner.py\", line 1404, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/evaluation/evaluator.py\", line 331, in evaluate_run\n",
      "    result = self.func(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 617, in wrapper\n",
      "    raise e\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 614, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "  File \"/var/folders/1l/w3vzbf215cs4ll30rh71l7wr6ghggx/T/ipykernel_62466/2954685631.py\", line 43, in answer_helpfulness_evaluator\n",
      "    prediction = run.outputs[\"answer\"]\n",
      "KeyError: 'answer'\n",
      "20it [00:22,  1.14s/it]\n"
     ]
    }
   ],
   "source": [
    "from langsmith.evaluation import evaluate\n",
    "\n",
    "dataset_name = \"income_tax_dataset\"\n",
    "experiment_results = evaluate(\n",
    "    predict_rag_answer_with_context, # 어떤 함수를 활용해서 LLM 답변을 확인할지 지정, hallucination 판단 여부에 따라 `with_context` 사용\n",
    "    data=dataset_name, # Evaluation에 사용될 dataset의 이름\n",
    "    evaluators=[answer_evaluator, answer_helpfulness_evaluator], # 실행할 Evaluator의 종류\n",
    "    experiment_prefix=\"inflearn-evaluator-lecture-hallucination\",\n",
    "    metadata={\"version\": \"income tax v1, gpt-4o\"}, \n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 점수의 판단\n",
    "* Chatgpt 가 작성한 답변 -> 도메인 전문가가 아니기 때문에 정답지가 틀렸을 가능성\n",
    "* Embedding 문제 -> embedding 효율이 떨어져서 retrieval 된 문서가 잘못 참조되어 잘못된 답변이 생성되는 경우"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "View the evaluation results for experiment: 'inflearn-evaluator-lecture-hallucination-329597eb' at:\n",
      "https://smith.langchain.com/o/2f003b67-27f4-48d0-8856-e1db2397e3d4/datasets/edb864cd-0264-4267-8e7d-6947cf745ec2/compare?selectedSessions=7f10270c-f71b-4551-9e03-b42ac74e767d\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]Error running target function: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o in organization org-CnOnLIaLFhfXUDRV6hWHsPkS on tokens per min (TPM): Limit 30000, Used 27304, Requested 3296. Please try again in 1.2s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/evaluation/_runner.py\", line 1675, in _forward\n",
      "    fn(example.inputs, langsmith_extra=langsmith_extra)\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 617, in wrapper\n",
      "    raise e\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 614, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "  File \"/var/folders/1l/w3vzbf215cs4ll30rh71l7wr6ghggx/T/ipykernel_62466/3191971669.py\", line 8, in predict_rag_answer_with_context\n",
      "    response = rag_bot.get_answer(example[\"input_question\"])\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 617, in wrapper\n",
      "    raise e\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 614, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "  File \"/var/folders/1l/w3vzbf215cs4ll30rh71l7wr6ghggx/T/ipykernel_62466/3657546987.py\", line 45, in get_answer\n",
      "    return self.invoke_llm(question, docs)\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 617, in wrapper\n",
      "    raise e\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 614, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "  File \"/var/folders/1l/w3vzbf215cs4ll30rh71l7wr6ghggx/T/ipykernel_62466/3657546987.py\", line 23, in invoke_llm\n",
      "    response = self._client.chat.completions.create(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/wrappers/_openai.py\", line 238, in create\n",
      "    return decorator(original_create)(*args, stream=stream, **kwargs)\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 617, in wrapper\n",
      "    raise e\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 614, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 275, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/resources/chat/completions.py\", line 829, in create\n",
      "    return self._post(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/_base_client.py\", line 1280, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/_base_client.py\", line 957, in request\n",
      "    return self._request(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/_base_client.py\", line 1046, in _request\n",
      "    return self._retry_request(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/_base_client.py\", line 1095, in _retry_request\n",
      "    return self._request(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/_base_client.py\", line 1046, in _request\n",
      "    return self._retry_request(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/_base_client.py\", line 1095, in _retry_request\n",
      "    return self._request(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/_base_client.py\", line 1061, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o in organization org-CnOnLIaLFhfXUDRV6hWHsPkS on tokens per min (TPM): Limit 30000, Used 27304, Requested 3296. Please try again in 1.2s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Error running evaluator <DynamicRunEvaluator answer_hallucination_evaluator> on run 9fc5ff6c-dc73-4a69-986c-ffe3bf06acb3: KeyError('contexts')\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/evaluation/_runner.py\", line 1404, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/evaluation/evaluator.py\", line 331, in evaluate_run\n",
      "    result = self.func(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 617, in wrapper\n",
      "    raise e\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 614, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "  File \"/var/folders/1l/w3vzbf215cs4ll30rh71l7wr6ghggx/T/ipykernel_62466/1562348432.py\", line 12, in answer_hallucination_evaluator\n",
      "    contexts = run.outputs[\"contexts\"]\n",
      "KeyError: 'contexts'\n",
      "Error running target function: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o in organization org-CnOnLIaLFhfXUDRV6hWHsPkS on tokens per min (TPM): Limit 30000, Used 27268, Requested 3304. Please try again in 1.144s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/evaluation/_runner.py\", line 1675, in _forward\n",
      "    fn(example.inputs, langsmith_extra=langsmith_extra)\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 617, in wrapper\n",
      "    raise e\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 614, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "  File \"/var/folders/1l/w3vzbf215cs4ll30rh71l7wr6ghggx/T/ipykernel_62466/3191971669.py\", line 8, in predict_rag_answer_with_context\n",
      "    response = rag_bot.get_answer(example[\"input_question\"])\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 617, in wrapper\n",
      "    raise e\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 614, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "  File \"/var/folders/1l/w3vzbf215cs4ll30rh71l7wr6ghggx/T/ipykernel_62466/3657546987.py\", line 45, in get_answer\n",
      "    return self.invoke_llm(question, docs)\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 617, in wrapper\n",
      "    raise e\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 614, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "  File \"/var/folders/1l/w3vzbf215cs4ll30rh71l7wr6ghggx/T/ipykernel_62466/3657546987.py\", line 23, in invoke_llm\n",
      "    response = self._client.chat.completions.create(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/wrappers/_openai.py\", line 238, in create\n",
      "    return decorator(original_create)(*args, stream=stream, **kwargs)\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 617, in wrapper\n",
      "    raise e\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 614, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 275, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/resources/chat/completions.py\", line 829, in create\n",
      "    return self._post(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/_base_client.py\", line 1280, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/_base_client.py\", line 957, in request\n",
      "    return self._request(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/_base_client.py\", line 1046, in _request\n",
      "    return self._retry_request(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/_base_client.py\", line 1095, in _retry_request\n",
      "    return self._request(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/_base_client.py\", line 1046, in _request\n",
      "    return self._retry_request(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/_base_client.py\", line 1095, in _retry_request\n",
      "    return self._request(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/_base_client.py\", line 1061, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o in organization org-CnOnLIaLFhfXUDRV6hWHsPkS on tokens per min (TPM): Limit 30000, Used 27268, Requested 3304. Please try again in 1.144s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "1it [00:08,  9.00s/it]Error running evaluator <DynamicRunEvaluator answer_hallucination_evaluator> on run b288c4fb-037a-4637-bcde-cd428ed3584e: KeyError('contexts')\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/evaluation/_runner.py\", line 1404, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/evaluation/evaluator.py\", line 331, in evaluate_run\n",
      "    result = self.func(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 617, in wrapper\n",
      "    raise e\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 614, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "  File \"/var/folders/1l/w3vzbf215cs4ll30rh71l7wr6ghggx/T/ipykernel_62466/1562348432.py\", line 12, in answer_hallucination_evaluator\n",
      "    contexts = run.outputs[\"contexts\"]\n",
      "KeyError: 'contexts'\n",
      "Error running target function: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o in organization org-CnOnLIaLFhfXUDRV6hWHsPkS on tokens per min (TPM): Limit 30000, Used 27262, Requested 3301. Please try again in 1.126s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/evaluation/_runner.py\", line 1675, in _forward\n",
      "    fn(example.inputs, langsmith_extra=langsmith_extra)\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 617, in wrapper\n",
      "    raise e\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 614, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "  File \"/var/folders/1l/w3vzbf215cs4ll30rh71l7wr6ghggx/T/ipykernel_62466/3191971669.py\", line 8, in predict_rag_answer_with_context\n",
      "    response = rag_bot.get_answer(example[\"input_question\"])\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 617, in wrapper\n",
      "    raise e\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 614, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "  File \"/var/folders/1l/w3vzbf215cs4ll30rh71l7wr6ghggx/T/ipykernel_62466/3657546987.py\", line 45, in get_answer\n",
      "    return self.invoke_llm(question, docs)\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 617, in wrapper\n",
      "    raise e\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 614, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "  File \"/var/folders/1l/w3vzbf215cs4ll30rh71l7wr6ghggx/T/ipykernel_62466/3657546987.py\", line 23, in invoke_llm\n",
      "    response = self._client.chat.completions.create(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/wrappers/_openai.py\", line 238, in create\n",
      "    return decorator(original_create)(*args, stream=stream, **kwargs)\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 617, in wrapper\n",
      "    raise e\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 614, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 275, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/resources/chat/completions.py\", line 829, in create\n",
      "    return self._post(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/_base_client.py\", line 1280, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/_base_client.py\", line 957, in request\n",
      "    return self._request(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/_base_client.py\", line 1046, in _request\n",
      "    return self._retry_request(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/_base_client.py\", line 1095, in _retry_request\n",
      "    return self._request(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/_base_client.py\", line 1046, in _request\n",
      "    return self._retry_request(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/_base_client.py\", line 1095, in _retry_request\n",
      "    return self._request(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/_base_client.py\", line 1061, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o in organization org-CnOnLIaLFhfXUDRV6hWHsPkS on tokens per min (TPM): Limit 30000, Used 27262, Requested 3301. Please try again in 1.126s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Error running evaluator <DynamicRunEvaluator answer_hallucination_evaluator> on run cfeafc83-467f-4565-986c-10c2a95a0514: KeyError('contexts')\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/evaluation/_runner.py\", line 1404, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/evaluation/evaluator.py\", line 331, in evaluate_run\n",
      "    result = self.func(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 617, in wrapper\n",
      "    raise e\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 614, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "  File \"/var/folders/1l/w3vzbf215cs4ll30rh71l7wr6ghggx/T/ipykernel_62466/1562348432.py\", line 12, in answer_hallucination_evaluator\n",
      "    contexts = run.outputs[\"contexts\"]\n",
      "KeyError: 'contexts'\n",
      "Error running target function: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o in organization org-CnOnLIaLFhfXUDRV6hWHsPkS on tokens per min (TPM): Limit 30000, Used 27252, Requested 3324. Please try again in 1.152s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/evaluation/_runner.py\", line 1675, in _forward\n",
      "    fn(example.inputs, langsmith_extra=langsmith_extra)\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 617, in wrapper\n",
      "    raise e\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 614, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "  File \"/var/folders/1l/w3vzbf215cs4ll30rh71l7wr6ghggx/T/ipykernel_62466/3191971669.py\", line 8, in predict_rag_answer_with_context\n",
      "    response = rag_bot.get_answer(example[\"input_question\"])\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 617, in wrapper\n",
      "    raise e\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 614, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "  File \"/var/folders/1l/w3vzbf215cs4ll30rh71l7wr6ghggx/T/ipykernel_62466/3657546987.py\", line 45, in get_answer\n",
      "    return self.invoke_llm(question, docs)\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 617, in wrapper\n",
      "    raise e\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 614, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "  File \"/var/folders/1l/w3vzbf215cs4ll30rh71l7wr6ghggx/T/ipykernel_62466/3657546987.py\", line 23, in invoke_llm\n",
      "    response = self._client.chat.completions.create(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/wrappers/_openai.py\", line 238, in create\n",
      "    return decorator(original_create)(*args, stream=stream, **kwargs)\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 617, in wrapper\n",
      "    raise e\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 614, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 275, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/resources/chat/completions.py\", line 829, in create\n",
      "    return self._post(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/_base_client.py\", line 1280, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/_base_client.py\", line 957, in request\n",
      "    return self._request(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/_base_client.py\", line 1046, in _request\n",
      "    return self._retry_request(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/_base_client.py\", line 1095, in _retry_request\n",
      "    return self._request(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/_base_client.py\", line 1046, in _request\n",
      "    return self._retry_request(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/_base_client.py\", line 1095, in _retry_request\n",
      "    return self._request(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/_base_client.py\", line 1061, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o in organization org-CnOnLIaLFhfXUDRV6hWHsPkS on tokens per min (TPM): Limit 30000, Used 27252, Requested 3324. Please try again in 1.152s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Error running evaluator <DynamicRunEvaluator answer_hallucination_evaluator> on run ee61c5e7-517b-4897-a6d0-e6b667a4ce9a: KeyError('contexts')\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/evaluation/_runner.py\", line 1404, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/evaluation/evaluator.py\", line 331, in evaluate_run\n",
      "    result = self.func(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 617, in wrapper\n",
      "    raise e\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 614, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "  File \"/var/folders/1l/w3vzbf215cs4ll30rh71l7wr6ghggx/T/ipykernel_62466/1562348432.py\", line 12, in answer_hallucination_evaluator\n",
      "    contexts = run.outputs[\"contexts\"]\n",
      "KeyError: 'contexts'\n",
      "Error running target function: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o in organization org-CnOnLIaLFhfXUDRV6hWHsPkS on tokens per min (TPM): Limit 30000, Used 27247, Requested 3307. Please try again in 1.108s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/evaluation/_runner.py\", line 1675, in _forward\n",
      "    fn(example.inputs, langsmith_extra=langsmith_extra)\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 617, in wrapper\n",
      "    raise e\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 614, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "  File \"/var/folders/1l/w3vzbf215cs4ll30rh71l7wr6ghggx/T/ipykernel_62466/3191971669.py\", line 8, in predict_rag_answer_with_context\n",
      "    response = rag_bot.get_answer(example[\"input_question\"])\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 617, in wrapper\n",
      "    raise e\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 614, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "  File \"/var/folders/1l/w3vzbf215cs4ll30rh71l7wr6ghggx/T/ipykernel_62466/3657546987.py\", line 45, in get_answer\n",
      "    return self.invoke_llm(question, docs)\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 617, in wrapper\n",
      "    raise e\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 614, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "  File \"/var/folders/1l/w3vzbf215cs4ll30rh71l7wr6ghggx/T/ipykernel_62466/3657546987.py\", line 23, in invoke_llm\n",
      "    response = self._client.chat.completions.create(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/wrappers/_openai.py\", line 238, in create\n",
      "    return decorator(original_create)(*args, stream=stream, **kwargs)\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 617, in wrapper\n",
      "    raise e\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 614, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 275, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/resources/chat/completions.py\", line 829, in create\n",
      "    return self._post(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/_base_client.py\", line 1280, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/_base_client.py\", line 957, in request\n",
      "    return self._request(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/_base_client.py\", line 1046, in _request\n",
      "    return self._retry_request(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/_base_client.py\", line 1095, in _retry_request\n",
      "    return self._request(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/_base_client.py\", line 1046, in _request\n",
      "    return self._retry_request(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/_base_client.py\", line 1095, in _retry_request\n",
      "    return self._request(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/_base_client.py\", line 1061, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o in organization org-CnOnLIaLFhfXUDRV6hWHsPkS on tokens per min (TPM): Limit 30000, Used 27247, Requested 3307. Please try again in 1.108s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Error running evaluator <DynamicRunEvaluator answer_hallucination_evaluator> on run 72e814c2-0304-41cb-8e94-d649001f8c9c: KeyError('contexts')\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/evaluation/_runner.py\", line 1404, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/evaluation/evaluator.py\", line 331, in evaluate_run\n",
      "    result = self.func(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 617, in wrapper\n",
      "    raise e\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 614, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "  File \"/var/folders/1l/w3vzbf215cs4ll30rh71l7wr6ghggx/T/ipykernel_62466/1562348432.py\", line 12, in answer_hallucination_evaluator\n",
      "    contexts = run.outputs[\"contexts\"]\n",
      "KeyError: 'contexts'\n",
      "Error running target function: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o in organization org-CnOnLIaLFhfXUDRV6hWHsPkS on tokens per min (TPM): Limit 30000, Used 27241, Requested 3328. Please try again in 1.138s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/evaluation/_runner.py\", line 1675, in _forward\n",
      "    fn(example.inputs, langsmith_extra=langsmith_extra)\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 617, in wrapper\n",
      "    raise e\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 614, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "  File \"/var/folders/1l/w3vzbf215cs4ll30rh71l7wr6ghggx/T/ipykernel_62466/3191971669.py\", line 8, in predict_rag_answer_with_context\n",
      "    response = rag_bot.get_answer(example[\"input_question\"])\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 617, in wrapper\n",
      "    raise e\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 614, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "  File \"/var/folders/1l/w3vzbf215cs4ll30rh71l7wr6ghggx/T/ipykernel_62466/3657546987.py\", line 45, in get_answer\n",
      "    return self.invoke_llm(question, docs)\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 617, in wrapper\n",
      "    raise e\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 614, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "  File \"/var/folders/1l/w3vzbf215cs4ll30rh71l7wr6ghggx/T/ipykernel_62466/3657546987.py\", line 23, in invoke_llm\n",
      "    response = self._client.chat.completions.create(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/wrappers/_openai.py\", line 238, in create\n",
      "    return decorator(original_create)(*args, stream=stream, **kwargs)\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 617, in wrapper\n",
      "    raise e\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 614, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 275, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/resources/chat/completions.py\", line 829, in create\n",
      "    return self._post(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/_base_client.py\", line 1280, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/_base_client.py\", line 957, in request\n",
      "    return self._request(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/_base_client.py\", line 1046, in _request\n",
      "    return self._retry_request(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/_base_client.py\", line 1095, in _retry_request\n",
      "    return self._request(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/_base_client.py\", line 1046, in _request\n",
      "    return self._retry_request(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/_base_client.py\", line 1095, in _retry_request\n",
      "    return self._request(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/_base_client.py\", line 1061, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o in organization org-CnOnLIaLFhfXUDRV6hWHsPkS on tokens per min (TPM): Limit 30000, Used 27241, Requested 3328. Please try again in 1.138s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Error running evaluator <DynamicRunEvaluator answer_hallucination_evaluator> on run 26ad0439-33a7-4c6c-a51b-4fbd5ef29c4b: KeyError('contexts')\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/evaluation/_runner.py\", line 1404, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/evaluation/evaluator.py\", line 331, in evaluate_run\n",
      "    result = self.func(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 617, in wrapper\n",
      "    raise e\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 614, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "  File \"/var/folders/1l/w3vzbf215cs4ll30rh71l7wr6ghggx/T/ipykernel_62466/1562348432.py\", line 12, in answer_hallucination_evaluator\n",
      "    contexts = run.outputs[\"contexts\"]\n",
      "KeyError: 'contexts'\n",
      "Error running target function: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o in organization org-CnOnLIaLFhfXUDRV6hWHsPkS on tokens per min (TPM): Limit 30000, Used 27228, Requested 3334. Please try again in 1.124s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/evaluation/_runner.py\", line 1675, in _forward\n",
      "    fn(example.inputs, langsmith_extra=langsmith_extra)\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 617, in wrapper\n",
      "    raise e\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 614, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "  File \"/var/folders/1l/w3vzbf215cs4ll30rh71l7wr6ghggx/T/ipykernel_62466/3191971669.py\", line 8, in predict_rag_answer_with_context\n",
      "    response = rag_bot.get_answer(example[\"input_question\"])\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 617, in wrapper\n",
      "    raise e\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 614, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "  File \"/var/folders/1l/w3vzbf215cs4ll30rh71l7wr6ghggx/T/ipykernel_62466/3657546987.py\", line 45, in get_answer\n",
      "    return self.invoke_llm(question, docs)\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 617, in wrapper\n",
      "    raise e\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 614, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "  File \"/var/folders/1l/w3vzbf215cs4ll30rh71l7wr6ghggx/T/ipykernel_62466/3657546987.py\", line 23, in invoke_llm\n",
      "    response = self._client.chat.completions.create(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/wrappers/_openai.py\", line 238, in create\n",
      "    return decorator(original_create)(*args, stream=stream, **kwargs)\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 617, in wrapper\n",
      "    raise e\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 614, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 275, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/resources/chat/completions.py\", line 829, in create\n",
      "    return self._post(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/_base_client.py\", line 1280, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/_base_client.py\", line 957, in request\n",
      "    return self._request(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/_base_client.py\", line 1046, in _request\n",
      "    return self._retry_request(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/_base_client.py\", line 1095, in _retry_request\n",
      "    return self._request(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/_base_client.py\", line 1046, in _request\n",
      "    return self._retry_request(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/_base_client.py\", line 1095, in _retry_request\n",
      "    return self._request(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/_base_client.py\", line 1061, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o in organization org-CnOnLIaLFhfXUDRV6hWHsPkS on tokens per min (TPM): Limit 30000, Used 27228, Requested 3334. Please try again in 1.124s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Error running evaluator <DynamicRunEvaluator answer_hallucination_evaluator> on run ad64c7b4-ddba-44e7-9096-af0448fb7296: KeyError('contexts')\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/evaluation/_runner.py\", line 1404, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/evaluation/evaluator.py\", line 331, in evaluate_run\n",
      "    result = self.func(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 617, in wrapper\n",
      "    raise e\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 614, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "  File \"/var/folders/1l/w3vzbf215cs4ll30rh71l7wr6ghggx/T/ipykernel_62466/1562348432.py\", line 12, in answer_hallucination_evaluator\n",
      "    contexts = run.outputs[\"contexts\"]\n",
      "KeyError: 'contexts'\n",
      "Error running target function: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o in organization org-CnOnLIaLFhfXUDRV6hWHsPkS on tokens per min (TPM): Limit 30000, Used 27204, Requested 3341. Please try again in 1.09s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/evaluation/_runner.py\", line 1675, in _forward\n",
      "    fn(example.inputs, langsmith_extra=langsmith_extra)\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 617, in wrapper\n",
      "    raise e\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 614, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "  File \"/var/folders/1l/w3vzbf215cs4ll30rh71l7wr6ghggx/T/ipykernel_62466/3191971669.py\", line 8, in predict_rag_answer_with_context\n",
      "    response = rag_bot.get_answer(example[\"input_question\"])\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 617, in wrapper\n",
      "    raise e\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 614, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "  File \"/var/folders/1l/w3vzbf215cs4ll30rh71l7wr6ghggx/T/ipykernel_62466/3657546987.py\", line 45, in get_answer\n",
      "    return self.invoke_llm(question, docs)\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 617, in wrapper\n",
      "    raise e\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 614, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "  File \"/var/folders/1l/w3vzbf215cs4ll30rh71l7wr6ghggx/T/ipykernel_62466/3657546987.py\", line 23, in invoke_llm\n",
      "    response = self._client.chat.completions.create(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/wrappers/_openai.py\", line 238, in create\n",
      "    return decorator(original_create)(*args, stream=stream, **kwargs)\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 617, in wrapper\n",
      "    raise e\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 614, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 275, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/resources/chat/completions.py\", line 829, in create\n",
      "    return self._post(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/_base_client.py\", line 1280, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/_base_client.py\", line 957, in request\n",
      "    return self._request(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/_base_client.py\", line 1046, in _request\n",
      "    return self._retry_request(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/_base_client.py\", line 1095, in _retry_request\n",
      "    return self._request(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/_base_client.py\", line 1046, in _request\n",
      "    return self._retry_request(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/_base_client.py\", line 1095, in _retry_request\n",
      "    return self._request(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/_base_client.py\", line 1061, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o in organization org-CnOnLIaLFhfXUDRV6hWHsPkS on tokens per min (TPM): Limit 30000, Used 27204, Requested 3341. Please try again in 1.09s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "7it [00:09,  1.04it/s]Error running evaluator <DynamicRunEvaluator answer_hallucination_evaluator> on run a5dd994a-2e40-4919-b510-7564c90d51d9: KeyError('contexts')\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/evaluation/_runner.py\", line 1404, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/evaluation/evaluator.py\", line 331, in evaluate_run\n",
      "    result = self.func(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 617, in wrapper\n",
      "    raise e\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 614, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "  File \"/var/folders/1l/w3vzbf215cs4ll30rh71l7wr6ghggx/T/ipykernel_62466/1562348432.py\", line 12, in answer_hallucination_evaluator\n",
      "    contexts = run.outputs[\"contexts\"]\n",
      "KeyError: 'contexts'\n",
      "Error running target function: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o in organization org-CnOnLIaLFhfXUDRV6hWHsPkS on tokens per min (TPM): Limit 30000, Used 27201, Requested 3352. Please try again in 1.106s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/evaluation/_runner.py\", line 1675, in _forward\n",
      "    fn(example.inputs, langsmith_extra=langsmith_extra)\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 617, in wrapper\n",
      "    raise e\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 614, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "  File \"/var/folders/1l/w3vzbf215cs4ll30rh71l7wr6ghggx/T/ipykernel_62466/3191971669.py\", line 8, in predict_rag_answer_with_context\n",
      "    response = rag_bot.get_answer(example[\"input_question\"])\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 617, in wrapper\n",
      "    raise e\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 614, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "  File \"/var/folders/1l/w3vzbf215cs4ll30rh71l7wr6ghggx/T/ipykernel_62466/3657546987.py\", line 45, in get_answer\n",
      "    return self.invoke_llm(question, docs)\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 617, in wrapper\n",
      "    raise e\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 614, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "  File \"/var/folders/1l/w3vzbf215cs4ll30rh71l7wr6ghggx/T/ipykernel_62466/3657546987.py\", line 23, in invoke_llm\n",
      "    response = self._client.chat.completions.create(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/wrappers/_openai.py\", line 238, in create\n",
      "    return decorator(original_create)(*args, stream=stream, **kwargs)\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 617, in wrapper\n",
      "    raise e\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 614, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 275, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/resources/chat/completions.py\", line 829, in create\n",
      "    return self._post(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/_base_client.py\", line 1280, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/_base_client.py\", line 957, in request\n",
      "    return self._request(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/_base_client.py\", line 1046, in _request\n",
      "    return self._retry_request(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/_base_client.py\", line 1095, in _retry_request\n",
      "    return self._request(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/_base_client.py\", line 1046, in _request\n",
      "    return self._retry_request(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/_base_client.py\", line 1095, in _retry_request\n",
      "    return self._request(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/_base_client.py\", line 1061, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o in organization org-CnOnLIaLFhfXUDRV6hWHsPkS on tokens per min (TPM): Limit 30000, Used 27201, Requested 3352. Please try again in 1.106s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Error running evaluator <DynamicRunEvaluator answer_hallucination_evaluator> on run 1366d93c-b1f9-4192-8588-1db3e9cd7ad9: KeyError('contexts')\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/evaluation/_runner.py\", line 1404, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/evaluation/evaluator.py\", line 331, in evaluate_run\n",
      "    result = self.func(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 617, in wrapper\n",
      "    raise e\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 614, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "  File \"/var/folders/1l/w3vzbf215cs4ll30rh71l7wr6ghggx/T/ipykernel_62466/1562348432.py\", line 12, in answer_hallucination_evaluator\n",
      "    contexts = run.outputs[\"contexts\"]\n",
      "KeyError: 'contexts'\n",
      "Error running target function: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o in organization org-CnOnLIaLFhfXUDRV6hWHsPkS on tokens per min (TPM): Limit 30000, Used 27194, Requested 3365. Please try again in 1.118s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/evaluation/_runner.py\", line 1675, in _forward\n",
      "    fn(example.inputs, langsmith_extra=langsmith_extra)\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 617, in wrapper\n",
      "    raise e\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 614, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "  File \"/var/folders/1l/w3vzbf215cs4ll30rh71l7wr6ghggx/T/ipykernel_62466/3191971669.py\", line 8, in predict_rag_answer_with_context\n",
      "    response = rag_bot.get_answer(example[\"input_question\"])\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 617, in wrapper\n",
      "    raise e\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 614, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "  File \"/var/folders/1l/w3vzbf215cs4ll30rh71l7wr6ghggx/T/ipykernel_62466/3657546987.py\", line 45, in get_answer\n",
      "    return self.invoke_llm(question, docs)\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 617, in wrapper\n",
      "    raise e\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 614, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "  File \"/var/folders/1l/w3vzbf215cs4ll30rh71l7wr6ghggx/T/ipykernel_62466/3657546987.py\", line 23, in invoke_llm\n",
      "    response = self._client.chat.completions.create(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/wrappers/_openai.py\", line 238, in create\n",
      "    return decorator(original_create)(*args, stream=stream, **kwargs)\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 617, in wrapper\n",
      "    raise e\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 614, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 275, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/resources/chat/completions.py\", line 829, in create\n",
      "    return self._post(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/_base_client.py\", line 1280, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/_base_client.py\", line 957, in request\n",
      "    return self._request(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/_base_client.py\", line 1046, in _request\n",
      "    return self._retry_request(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/_base_client.py\", line 1095, in _retry_request\n",
      "    return self._request(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/_base_client.py\", line 1046, in _request\n",
      "    return self._retry_request(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/_base_client.py\", line 1095, in _retry_request\n",
      "    return self._request(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/_base_client.py\", line 1061, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o in organization org-CnOnLIaLFhfXUDRV6hWHsPkS on tokens per min (TPM): Limit 30000, Used 27194, Requested 3365. Please try again in 1.118s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Error running evaluator <DynamicRunEvaluator answer_hallucination_evaluator> on run b4b18093-2d97-483b-b949-a46bdf8549ad: KeyError('contexts')\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/evaluation/_runner.py\", line 1404, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/evaluation/evaluator.py\", line 331, in evaluate_run\n",
      "    result = self.func(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 617, in wrapper\n",
      "    raise e\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 614, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "  File \"/var/folders/1l/w3vzbf215cs4ll30rh71l7wr6ghggx/T/ipykernel_62466/1562348432.py\", line 12, in answer_hallucination_evaluator\n",
      "    contexts = run.outputs[\"contexts\"]\n",
      "KeyError: 'contexts'\n",
      "Error running target function: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o in organization org-CnOnLIaLFhfXUDRV6hWHsPkS on tokens per min (TPM): Limit 30000, Used 27077, Requested 3485. Please try again in 1.124s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/evaluation/_runner.py\", line 1675, in _forward\n",
      "    fn(example.inputs, langsmith_extra=langsmith_extra)\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 617, in wrapper\n",
      "    raise e\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 614, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "  File \"/var/folders/1l/w3vzbf215cs4ll30rh71l7wr6ghggx/T/ipykernel_62466/3191971669.py\", line 8, in predict_rag_answer_with_context\n",
      "    response = rag_bot.get_answer(example[\"input_question\"])\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 617, in wrapper\n",
      "    raise e\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 614, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "  File \"/var/folders/1l/w3vzbf215cs4ll30rh71l7wr6ghggx/T/ipykernel_62466/3657546987.py\", line 45, in get_answer\n",
      "    return self.invoke_llm(question, docs)\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 617, in wrapper\n",
      "    raise e\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 614, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "  File \"/var/folders/1l/w3vzbf215cs4ll30rh71l7wr6ghggx/T/ipykernel_62466/3657546987.py\", line 23, in invoke_llm\n",
      "    response = self._client.chat.completions.create(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/wrappers/_openai.py\", line 238, in create\n",
      "    return decorator(original_create)(*args, stream=stream, **kwargs)\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 617, in wrapper\n",
      "    raise e\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 614, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 275, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/resources/chat/completions.py\", line 829, in create\n",
      "    return self._post(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/_base_client.py\", line 1280, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/_base_client.py\", line 957, in request\n",
      "    return self._request(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/_base_client.py\", line 1046, in _request\n",
      "    return self._retry_request(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/_base_client.py\", line 1095, in _retry_request\n",
      "    return self._request(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/_base_client.py\", line 1046, in _request\n",
      "    return self._retry_request(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/_base_client.py\", line 1095, in _retry_request\n",
      "    return self._request(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/_base_client.py\", line 1061, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o in organization org-CnOnLIaLFhfXUDRV6hWHsPkS on tokens per min (TPM): Limit 30000, Used 27077, Requested 3485. Please try again in 1.124s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "10it [00:09,  1.61it/s]Error running evaluator <DynamicRunEvaluator answer_hallucination_evaluator> on run 5be86e3b-38f6-49db-98b1-a3682f797992: KeyError('contexts')\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/evaluation/_runner.py\", line 1404, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/evaluation/evaluator.py\", line 331, in evaluate_run\n",
      "    result = self.func(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 617, in wrapper\n",
      "    raise e\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 614, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "  File \"/var/folders/1l/w3vzbf215cs4ll30rh71l7wr6ghggx/T/ipykernel_62466/1562348432.py\", line 12, in answer_hallucination_evaluator\n",
      "    contexts = run.outputs[\"contexts\"]\n",
      "KeyError: 'contexts'\n",
      "Error running target function: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o in organization org-CnOnLIaLFhfXUDRV6hWHsPkS on tokens per min (TPM): Limit 30000, Used 26895, Requested 3640. Please try again in 1.07s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/evaluation/_runner.py\", line 1675, in _forward\n",
      "    fn(example.inputs, langsmith_extra=langsmith_extra)\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 617, in wrapper\n",
      "    raise e\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 614, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "  File \"/var/folders/1l/w3vzbf215cs4ll30rh71l7wr6ghggx/T/ipykernel_62466/3191971669.py\", line 8, in predict_rag_answer_with_context\n",
      "    response = rag_bot.get_answer(example[\"input_question\"])\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 617, in wrapper\n",
      "    raise e\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 614, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "  File \"/var/folders/1l/w3vzbf215cs4ll30rh71l7wr6ghggx/T/ipykernel_62466/3657546987.py\", line 45, in get_answer\n",
      "    return self.invoke_llm(question, docs)\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 617, in wrapper\n",
      "    raise e\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 614, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "  File \"/var/folders/1l/w3vzbf215cs4ll30rh71l7wr6ghggx/T/ipykernel_62466/3657546987.py\", line 23, in invoke_llm\n",
      "    response = self._client.chat.completions.create(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/wrappers/_openai.py\", line 238, in create\n",
      "    return decorator(original_create)(*args, stream=stream, **kwargs)\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 617, in wrapper\n",
      "    raise e\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 614, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 275, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/resources/chat/completions.py\", line 829, in create\n",
      "    return self._post(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/_base_client.py\", line 1280, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/_base_client.py\", line 957, in request\n",
      "    return self._request(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/_base_client.py\", line 1046, in _request\n",
      "    return self._retry_request(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/_base_client.py\", line 1095, in _retry_request\n",
      "    return self._request(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/_base_client.py\", line 1046, in _request\n",
      "    return self._retry_request(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/_base_client.py\", line 1095, in _retry_request\n",
      "    return self._request(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/_base_client.py\", line 1061, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o in organization org-CnOnLIaLFhfXUDRV6hWHsPkS on tokens per min (TPM): Limit 30000, Used 26895, Requested 3640. Please try again in 1.07s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Error running evaluator <DynamicRunEvaluator answer_hallucination_evaluator> on run 48007394-0a2c-4b62-9543-fed55ad48b45: KeyError('contexts')\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/evaluation/_runner.py\", line 1404, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/evaluation/evaluator.py\", line 331, in evaluate_run\n",
      "    result = self.func(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 617, in wrapper\n",
      "    raise e\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 614, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "  File \"/var/folders/1l/w3vzbf215cs4ll30rh71l7wr6ghggx/T/ipykernel_62466/1562348432.py\", line 12, in answer_hallucination_evaluator\n",
      "    contexts = run.outputs[\"contexts\"]\n",
      "KeyError: 'contexts'\n",
      "Error running target function: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o in organization org-CnOnLIaLFhfXUDRV6hWHsPkS on tokens per min (TPM): Limit 30000, Used 29821, Requested 3299. Please try again in 6.24s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/evaluation/_runner.py\", line 1675, in _forward\n",
      "    fn(example.inputs, langsmith_extra=langsmith_extra)\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 617, in wrapper\n",
      "    raise e\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 614, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "  File \"/var/folders/1l/w3vzbf215cs4ll30rh71l7wr6ghggx/T/ipykernel_62466/3191971669.py\", line 8, in predict_rag_answer_with_context\n",
      "    response = rag_bot.get_answer(example[\"input_question\"])\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 617, in wrapper\n",
      "    raise e\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 614, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "  File \"/var/folders/1l/w3vzbf215cs4ll30rh71l7wr6ghggx/T/ipykernel_62466/3657546987.py\", line 45, in get_answer\n",
      "    return self.invoke_llm(question, docs)\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 617, in wrapper\n",
      "    raise e\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 614, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "  File \"/var/folders/1l/w3vzbf215cs4ll30rh71l7wr6ghggx/T/ipykernel_62466/3657546987.py\", line 23, in invoke_llm\n",
      "    response = self._client.chat.completions.create(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/wrappers/_openai.py\", line 238, in create\n",
      "    return decorator(original_create)(*args, stream=stream, **kwargs)\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 617, in wrapper\n",
      "    raise e\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 614, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 275, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/resources/chat/completions.py\", line 829, in create\n",
      "    return self._post(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/_base_client.py\", line 1280, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/_base_client.py\", line 957, in request\n",
      "    return self._request(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/_base_client.py\", line 1046, in _request\n",
      "    return self._retry_request(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/_base_client.py\", line 1095, in _retry_request\n",
      "    return self._request(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/_base_client.py\", line 1046, in _request\n",
      "    return self._retry_request(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/_base_client.py\", line 1095, in _retry_request\n",
      "    return self._request(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/_base_client.py\", line 1061, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o in organization org-CnOnLIaLFhfXUDRV6hWHsPkS on tokens per min (TPM): Limit 30000, Used 29821, Requested 3299. Please try again in 6.24s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "12it [00:10,  1.66it/s]Error running evaluator <DynamicRunEvaluator answer_hallucination_evaluator> on run c3e029be-0565-423a-9c25-bfa712d97549: KeyError('contexts')\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/evaluation/_runner.py\", line 1404, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/evaluation/evaluator.py\", line 331, in evaluate_run\n",
      "    result = self.func(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 617, in wrapper\n",
      "    raise e\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 614, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "  File \"/var/folders/1l/w3vzbf215cs4ll30rh71l7wr6ghggx/T/ipykernel_62466/1562348432.py\", line 12, in answer_hallucination_evaluator\n",
      "    contexts = run.outputs[\"contexts\"]\n",
      "KeyError: 'contexts'\n",
      "Error running evaluator <DynamicRunEvaluator answer_hallucination_evaluator> on run ad2ae8d2-3bc3-4ac8-b18f-c46e6b8ca99f: RateLimitError(\"Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o in organization org-CnOnLIaLFhfXUDRV6hWHsPkS on tokens per min (TPM): Limit 30000, Used 29679, Requested 3447. Please try again in 6.252s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\")\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/evaluation/_runner.py\", line 1404, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/evaluation/evaluator.py\", line 331, in evaluate_run\n",
      "    result = self.func(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 617, in wrapper\n",
      "    raise e\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 614, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "  File \"/var/folders/1l/w3vzbf215cs4ll30rh71l7wr6ghggx/T/ipykernel_62466/1562348432.py\", line 25, in answer_hallucination_evaluator\n",
      "    score = answer_grader.invoke({\"documents\": contexts,\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langchain_core/runnables/base.py\", line 3024, in invoke\n",
      "    input = context.run(step.invoke, input, config)\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langchain_core/runnables/base.py\", line 5354, in invoke\n",
      "    return self.bound.invoke(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langchain_core/language_models/chat_models.py\", line 286, in invoke\n",
      "    self.generate_prompt(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langchain_core/language_models/chat_models.py\", line 786, in generate_prompt\n",
      "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langchain_core/language_models/chat_models.py\", line 643, in generate\n",
      "    raise e\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langchain_core/language_models/chat_models.py\", line 633, in generate\n",
      "    self._generate_with_cache(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langchain_core/language_models/chat_models.py\", line 851, in _generate_with_cache\n",
      "    result = self._generate(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langchain_openai/chat_models/base.py\", line 689, in _generate\n",
      "    response = self.client.create(**payload)\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 275, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/resources/chat/completions.py\", line 829, in create\n",
      "    return self._post(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/_base_client.py\", line 1280, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/_base_client.py\", line 957, in request\n",
      "    return self._request(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/_base_client.py\", line 1046, in _request\n",
      "    return self._retry_request(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/_base_client.py\", line 1095, in _retry_request\n",
      "    return self._request(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/_base_client.py\", line 1046, in _request\n",
      "    return self._retry_request(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/_base_client.py\", line 1095, in _retry_request\n",
      "    return self._request(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/_base_client.py\", line 1061, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o in organization org-CnOnLIaLFhfXUDRV6hWHsPkS on tokens per min (TPM): Limit 30000, Used 29679, Requested 3447. Please try again in 6.252s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "14it [00:12,  1.48it/s]Error running target function: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o in organization org-CnOnLIaLFhfXUDRV6hWHsPkS on tokens per min (TPM): Limit 30000, Used 27408, Requested 3372. Please try again in 1.56s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/evaluation/_runner.py\", line 1675, in _forward\n",
      "    fn(example.inputs, langsmith_extra=langsmith_extra)\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 617, in wrapper\n",
      "    raise e\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 614, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "  File \"/var/folders/1l/w3vzbf215cs4ll30rh71l7wr6ghggx/T/ipykernel_62466/3191971669.py\", line 8, in predict_rag_answer_with_context\n",
      "    response = rag_bot.get_answer(example[\"input_question\"])\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 617, in wrapper\n",
      "    raise e\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 614, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "  File \"/var/folders/1l/w3vzbf215cs4ll30rh71l7wr6ghggx/T/ipykernel_62466/3657546987.py\", line 45, in get_answer\n",
      "    return self.invoke_llm(question, docs)\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 617, in wrapper\n",
      "    raise e\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 614, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "  File \"/var/folders/1l/w3vzbf215cs4ll30rh71l7wr6ghggx/T/ipykernel_62466/3657546987.py\", line 23, in invoke_llm\n",
      "    response = self._client.chat.completions.create(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/wrappers/_openai.py\", line 238, in create\n",
      "    return decorator(original_create)(*args, stream=stream, **kwargs)\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 617, in wrapper\n",
      "    raise e\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 614, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 275, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/resources/chat/completions.py\", line 829, in create\n",
      "    return self._post(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/_base_client.py\", line 1280, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/_base_client.py\", line 957, in request\n",
      "    return self._request(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/_base_client.py\", line 1046, in _request\n",
      "    return self._retry_request(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/_base_client.py\", line 1095, in _retry_request\n",
      "    return self._request(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/_base_client.py\", line 1046, in _request\n",
      "    return self._retry_request(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/_base_client.py\", line 1095, in _retry_request\n",
      "    return self._request(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/_base_client.py\", line 1061, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o in organization org-CnOnLIaLFhfXUDRV6hWHsPkS on tokens per min (TPM): Limit 30000, Used 27408, Requested 3372. Please try again in 1.56s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Error running evaluator <DynamicRunEvaluator answer_hallucination_evaluator> on run 36586cdf-2441-4117-a7a3-851916322510: KeyError('contexts')\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/evaluation/_runner.py\", line 1404, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/evaluation/evaluator.py\", line 331, in evaluate_run\n",
      "    result = self.func(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 617, in wrapper\n",
      "    raise e\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 614, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "  File \"/var/folders/1l/w3vzbf215cs4ll30rh71l7wr6ghggx/T/ipykernel_62466/1562348432.py\", line 12, in answer_hallucination_evaluator\n",
      "    contexts = run.outputs[\"contexts\"]\n",
      "KeyError: 'contexts'\n",
      "Error running target function: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o in organization org-CnOnLIaLFhfXUDRV6hWHsPkS on tokens per min (TPM): Limit 30000, Used 27208, Requested 3597. Please try again in 1.61s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/evaluation/_runner.py\", line 1675, in _forward\n",
      "    fn(example.inputs, langsmith_extra=langsmith_extra)\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 617, in wrapper\n",
      "    raise e\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 614, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "  File \"/var/folders/1l/w3vzbf215cs4ll30rh71l7wr6ghggx/T/ipykernel_62466/3191971669.py\", line 8, in predict_rag_answer_with_context\n",
      "    response = rag_bot.get_answer(example[\"input_question\"])\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 617, in wrapper\n",
      "    raise e\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 614, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "  File \"/var/folders/1l/w3vzbf215cs4ll30rh71l7wr6ghggx/T/ipykernel_62466/3657546987.py\", line 45, in get_answer\n",
      "    return self.invoke_llm(question, docs)\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 617, in wrapper\n",
      "    raise e\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 614, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "  File \"/var/folders/1l/w3vzbf215cs4ll30rh71l7wr6ghggx/T/ipykernel_62466/3657546987.py\", line 23, in invoke_llm\n",
      "    response = self._client.chat.completions.create(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/wrappers/_openai.py\", line 238, in create\n",
      "    return decorator(original_create)(*args, stream=stream, **kwargs)\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 617, in wrapper\n",
      "    raise e\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 614, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 275, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/resources/chat/completions.py\", line 829, in create\n",
      "    return self._post(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/_base_client.py\", line 1280, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/_base_client.py\", line 957, in request\n",
      "    return self._request(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/_base_client.py\", line 1046, in _request\n",
      "    return self._retry_request(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/_base_client.py\", line 1095, in _retry_request\n",
      "    return self._request(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/_base_client.py\", line 1046, in _request\n",
      "    return self._retry_request(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/_base_client.py\", line 1095, in _retry_request\n",
      "    return self._request(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/_base_client.py\", line 1061, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o in organization org-CnOnLIaLFhfXUDRV6hWHsPkS on tokens per min (TPM): Limit 30000, Used 27208, Requested 3597. Please try again in 1.61s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "15it [00:17,  1.47s/it]Error running evaluator <DynamicRunEvaluator answer_hallucination_evaluator> on run 7ccda52b-58f1-4221-9f08-7e29b9e2c77f: KeyError('contexts')\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/evaluation/_runner.py\", line 1404, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/evaluation/evaluator.py\", line 331, in evaluate_run\n",
      "    result = self.func(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 617, in wrapper\n",
      "    raise e\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 614, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "  File \"/var/folders/1l/w3vzbf215cs4ll30rh71l7wr6ghggx/T/ipykernel_62466/1562348432.py\", line 12, in answer_hallucination_evaluator\n",
      "    contexts = run.outputs[\"contexts\"]\n",
      "KeyError: 'contexts'\n",
      "Error running evaluator <DynamicRunEvaluator answer_hallucination_evaluator> on run e17c7991-8df8-43be-b1ec-2ef8be215675: RateLimitError(\"Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o in organization org-CnOnLIaLFhfXUDRV6hWHsPkS on tokens per min (TPM): Limit 30000, Used 27148, Requested 3632. Please try again in 1.56s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\")\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/evaluation/_runner.py\", line 1404, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/evaluation/evaluator.py\", line 331, in evaluate_run\n",
      "    result = self.func(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 617, in wrapper\n",
      "    raise e\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 614, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "  File \"/var/folders/1l/w3vzbf215cs4ll30rh71l7wr6ghggx/T/ipykernel_62466/1562348432.py\", line 25, in answer_hallucination_evaluator\n",
      "    score = answer_grader.invoke({\"documents\": contexts,\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langchain_core/runnables/base.py\", line 3024, in invoke\n",
      "    input = context.run(step.invoke, input, config)\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langchain_core/runnables/base.py\", line 5354, in invoke\n",
      "    return self.bound.invoke(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langchain_core/language_models/chat_models.py\", line 286, in invoke\n",
      "    self.generate_prompt(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langchain_core/language_models/chat_models.py\", line 786, in generate_prompt\n",
      "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langchain_core/language_models/chat_models.py\", line 643, in generate\n",
      "    raise e\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langchain_core/language_models/chat_models.py\", line 633, in generate\n",
      "    self._generate_with_cache(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langchain_core/language_models/chat_models.py\", line 851, in _generate_with_cache\n",
      "    result = self._generate(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langchain_openai/chat_models/base.py\", line 689, in _generate\n",
      "    response = self.client.create(**payload)\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 275, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/resources/chat/completions.py\", line 829, in create\n",
      "    return self._post(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/_base_client.py\", line 1280, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/_base_client.py\", line 957, in request\n",
      "    return self._request(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/_base_client.py\", line 1046, in _request\n",
      "    return self._retry_request(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/_base_client.py\", line 1095, in _retry_request\n",
      "    return self._request(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/_base_client.py\", line 1046, in _request\n",
      "    return self._retry_request(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/_base_client.py\", line 1095, in _retry_request\n",
      "    return self._request(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/_base_client.py\", line 1061, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o in organization org-CnOnLIaLFhfXUDRV6hWHsPkS on tokens per min (TPM): Limit 30000, Used 27148, Requested 3632. Please try again in 1.56s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Error running target function: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o in organization org-CnOnLIaLFhfXUDRV6hWHsPkS on tokens per min (TPM): Limit 30000, Used 29787, Requested 3365. Please try again in 6.304s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/evaluation/_runner.py\", line 1675, in _forward\n",
      "    fn(example.inputs, langsmith_extra=langsmith_extra)\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 617, in wrapper\n",
      "    raise e\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 614, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "  File \"/var/folders/1l/w3vzbf215cs4ll30rh71l7wr6ghggx/T/ipykernel_62466/3191971669.py\", line 8, in predict_rag_answer_with_context\n",
      "    response = rag_bot.get_answer(example[\"input_question\"])\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 617, in wrapper\n",
      "    raise e\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 614, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "  File \"/var/folders/1l/w3vzbf215cs4ll30rh71l7wr6ghggx/T/ipykernel_62466/3657546987.py\", line 45, in get_answer\n",
      "    return self.invoke_llm(question, docs)\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 617, in wrapper\n",
      "    raise e\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 614, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "  File \"/var/folders/1l/w3vzbf215cs4ll30rh71l7wr6ghggx/T/ipykernel_62466/3657546987.py\", line 23, in invoke_llm\n",
      "    response = self._client.chat.completions.create(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/wrappers/_openai.py\", line 238, in create\n",
      "    return decorator(original_create)(*args, stream=stream, **kwargs)\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 617, in wrapper\n",
      "    raise e\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 614, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 275, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/resources/chat/completions.py\", line 829, in create\n",
      "    return self._post(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/_base_client.py\", line 1280, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/_base_client.py\", line 957, in request\n",
      "    return self._request(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/_base_client.py\", line 1046, in _request\n",
      "    return self._retry_request(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/_base_client.py\", line 1095, in _retry_request\n",
      "    return self._request(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/_base_client.py\", line 1046, in _request\n",
      "    return self._retry_request(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/_base_client.py\", line 1095, in _retry_request\n",
      "    return self._request(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/_base_client.py\", line 1061, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o in organization org-CnOnLIaLFhfXUDRV6hWHsPkS on tokens per min (TPM): Limit 30000, Used 29787, Requested 3365. Please try again in 6.304s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "16it [00:19,  1.48s/it]Error running evaluator <DynamicRunEvaluator answer_hallucination_evaluator> on run dabfe4d2-c49a-4791-bb96-4e38025c2055: KeyError('contexts')\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/evaluation/_runner.py\", line 1404, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/evaluation/evaluator.py\", line 331, in evaluate_run\n",
      "    result = self.func(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 617, in wrapper\n",
      "    raise e\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 614, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "  File \"/var/folders/1l/w3vzbf215cs4ll30rh71l7wr6ghggx/T/ipykernel_62466/1562348432.py\", line 12, in answer_hallucination_evaluator\n",
      "    contexts = run.outputs[\"contexts\"]\n",
      "KeyError: 'contexts'\n",
      "18it [00:20,  1.27s/it]Error running evaluator <DynamicRunEvaluator answer_hallucination_evaluator> on run 02ad04d8-189e-4301-8d89-b099e1bc177d: RateLimitError(\"Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o in organization org-CnOnLIaLFhfXUDRV6hWHsPkS on tokens per min (TPM): Limit 30000, Used 27076, Requested 3545. Please try again in 1.242s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\")\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/evaluation/_runner.py\", line 1404, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/evaluation/evaluator.py\", line 331, in evaluate_run\n",
      "    result = self.func(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 617, in wrapper\n",
      "    raise e\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 614, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "  File \"/var/folders/1l/w3vzbf215cs4ll30rh71l7wr6ghggx/T/ipykernel_62466/1562348432.py\", line 25, in answer_hallucination_evaluator\n",
      "    score = answer_grader.invoke({\"documents\": contexts,\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langchain_core/runnables/base.py\", line 3024, in invoke\n",
      "    input = context.run(step.invoke, input, config)\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langchain_core/runnables/base.py\", line 5354, in invoke\n",
      "    return self.bound.invoke(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langchain_core/language_models/chat_models.py\", line 286, in invoke\n",
      "    self.generate_prompt(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langchain_core/language_models/chat_models.py\", line 786, in generate_prompt\n",
      "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langchain_core/language_models/chat_models.py\", line 643, in generate\n",
      "    raise e\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langchain_core/language_models/chat_models.py\", line 633, in generate\n",
      "    self._generate_with_cache(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langchain_core/language_models/chat_models.py\", line 851, in _generate_with_cache\n",
      "    result = self._generate(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langchain_openai/chat_models/base.py\", line 689, in _generate\n",
      "    response = self.client.create(**payload)\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 275, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/resources/chat/completions.py\", line 829, in create\n",
      "    return self._post(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/_base_client.py\", line 1280, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/_base_client.py\", line 957, in request\n",
      "    return self._request(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/_base_client.py\", line 1046, in _request\n",
      "    return self._retry_request(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/_base_client.py\", line 1095, in _retry_request\n",
      "    return self._request(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/_base_client.py\", line 1046, in _request\n",
      "    return self._retry_request(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/_base_client.py\", line 1095, in _retry_request\n",
      "    return self._request(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/_base_client.py\", line 1061, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o in organization org-CnOnLIaLFhfXUDRV6hWHsPkS on tokens per min (TPM): Limit 30000, Used 27076, Requested 3545. Please try again in 1.242s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "20it [00:29,  1.49s/it]\n"
     ]
    }
   ],
   "source": [
    "from langsmith.evaluation import evaluate\n",
    "\n",
    "dataset_name = \"income_tax_dataset\"\n",
    "experiment_results = evaluate(\n",
    "    predict_rag_answer_with_context, # 어떤 함수를 활용해서 LLM 답변을 확인할지 지정, hallucination 판단 여부에 따라 `with_context` 사용\n",
    "    data=dataset_name, # Evaluation에 사용될 dataset의 이름\n",
    "    evaluators=[answer_hallucination_evaluator], # 실행할 Evaluator의 종류\n",
    "    experiment_prefix=\"inflearn-evaluator-lecture-hallucination\",\n",
    "    metadata={\"version\": \"income tax v1, gpt-4o\"}, \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "inflearn-llm-application",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
