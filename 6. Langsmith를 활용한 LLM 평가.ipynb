{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LLM evaluation 의 중요성\n",
    "* 서비스를 안정적으로 운영하기 위해\n",
    "* 사용자가 정확한 정보를 받을 수 있는지 ? -> 환각 현상\n",
    "\n",
    "### Langsmith\n",
    "* 답변의 도움 정도, 실제 답변과 얼마나 유사한지 등의 llm 의 성능 평가 기능을 제공함\n",
    "\n",
    "* Dataset 구성\n",
    "    * 도메인 전문가가 작성한 정답지를 포함하는 데이터\n",
    "    * 특정 질문이 들어올 때 기대되는 답변을 포함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langsmith import Client\n",
    "\n",
    "client = Client()\n",
    "\n",
    "# Define dataset: these are your test cases\n",
    "dataset_name = \"income_tax_dataset\"\n",
    "dataset = client.create_dataset(dataset_name)\n",
    "client.create_examples(\n",
    "    inputs=[\n",
    "        {\"input_question\": \"제1조에 따른 소득세법의 목적은 무엇인가요?\"},\n",
    "        {\"input_question\": \"'거주자'는 소득세법에서 어떻게 정의되나요?\"},\n",
    "        {\"input_question\": \"'비거주자'는 소득세법에 따라 어떻게 정의되나요?\"},\n",
    "        {\"input_question\": \"소득세법에 따른 '내국법인'은 누구를 의미하나요?\"},\n",
    "        {\"input_question\": \"소득세법에 따라 소득세를 납부할 의무가 있는 사람은 누구인가요?\"},\n",
    "        {\"input_question\": \"거주자의 과세 범위는 무엇인가요?\"},\n",
    "        {\"input_question\": \"소득세법에 따라 소득은 어떻게 분류되나요?\"},\n",
    "        {\"input_question\": \"종합소득이란 무엇인가요?\"},\n",
    "        {\"input_question\": \"세금이 면제되는 소득의 종류는 무엇인가요?\"},\n",
    "        {\"input_question\": \"소득세의 과세기간은 어떻게 되나요?\"},\n",
    "        {\"input_question\": \"거주자의 소득세 납세지는 어디인가요?\"},\n",
    "        {\"input_question\": \"비거주자의 소득세 납세지는 어디인가요?\"},\n",
    "        {\"input_question\": \"납세지가 불분명한 경우 어떻게 되나요?\"},\n",
    "        {\"input_question\": \"원천징수세액의 납세지는 어떻게 결정되나요?\"},\n",
    "        {\"input_question\": \"납세자의 사망 시 납세지는 어떻게 되나요?\"},\n",
    "        {\"input_question\": \"신탁 소득에 대한 납세의 범위는 무엇인가요?\"},\n",
    "        {\"input_question\": \"원천징수 대상 소득은 무엇인가요?\"},\n",
    "        {\"input_question\": \"공동 소유 자산의 양도소득은 어떻게 과세되나요?\"},\n",
    "        {\"input_question\": \"이자 소득의 출처는 무엇인가요?\"},\n",
    "        {\"input_question\": \"소득세법에서 배당소득은 어떻게 정의되나요?\"}\n",
    "    ],\n",
    "    outputs=[\n",
    "        {\"output_answer\": \"소득세법의 목적은 소득의 성격과 납세자의 부담능력에 따라 적정하게 과세함으로써 조세부담의 형평을 도모하고 재정수입의 원활한 조달에 이바지하는 것입니다.\"},\n",
    "        {\"output_answer\": \"'거주자'는 한국에 주소를 두거나 183일 이상 거소를 둔 개인을 의미합니다.\"},\n",
    "        {\"output_answer\": \"'비거주자'는 거주자가 아닌 개인을 의미합니다.\"},\n",
    "        {\"output_answer\": \"'내국법인'은 법인세법 제2조 제1호에 따른 내국법인을 의미합니다.\"},\n",
    "        {\"output_answer\": \"거주자 및 국내원천소득이 있는 비거주자는 소득세를 납부할 의무가 있습니다.\"},\n",
    "        {\"output_answer\": \"거주자는 법에서 규정한 모든 소득에 대해 과세되며, 비거주자는 국내원천소득에 대해서만 과세됩니다.\"},\n",
    "        {\"output_answer\": \"소득은 종합소득, 퇴직소득, 양도소득으로 분류됩니다.\"},\n",
    "        {\"output_answer\": \"종합소득은 이자소득, 배당소득, 사업소득, 근로소득, 연금소득 및 기타소득을 포함합니다.\"},\n",
    "        {\"output_answer\": \"비과세 소득에는 공익신탁의 이익, 특정 사업소득 및 기타 법에서 정한 특정 소득이 포함됩니다.\"},\n",
    "        {\"output_answer\": \"소득세의 과세기간은 매년 1월 1일부터 12월 31일까지입니다.\"},\n",
    "        {\"output_answer\": \"거주자의 소득세 납세지는 주소지이며, 주소지가 없으면 거소지입니다.\"},\n",
    "        {\"output_answer\": \"비거주자의 소득세 납세지는 국내사업장의 소재지입니다. 국내사업장이 여러 곳인 경우 주된 사업장의 소재지가 납세지가 됩니다.\"},\n",
    "        {\"output_answer\": \"납세지가 불분명한 경우 대통령령으로 정합니다.\"},\n",
    "        {\"output_answer\": \"원천징수세액의 납세지는 원천징수자의 종류와 위치에 따라 결정됩니다.\"},\n",
    "        {\"output_answer\": \"납세자의 사망 시 상속인 또는 납세관리인의 주소지나 거소지가 납세지가 됩니다.\"},\n",
    "        {\"output_answer\": \"신탁 소득에 대한 납세의 범위는 신탁의 수익자가 해당 소득에 대해 납세의무를 집니다.\"},\n",
    "        {\"output_answer\": \"이자소득, 배당소득 및 기타 법에서 정한 소득은 원천징수 대상입니다.\"},\n",
    "        {\"output_answer\": \"공동 소유 자산의 양도소득은 각 거주자 소유 지분에 따라 과세됩니다.\"},\n",
    "        {\"output_answer\": \"이자 소득의 출처는 정부 및 지방자치단체가 발행한 채권, 법인이 발행한 채권, 국내외 은행 예금 등입니다.\"},\n",
    "        {\"output_answer\": \"배당소득은 국내외 법인으로부터 받는 배당금 및 배분금, 기타 법에서 정한 소득을 포함합니다.\"}\n",
    "    ],\n",
    "    metadata= [\n",
    "        {\"contexts\": \"제1조(목적) 이 법은 개인의 소득에 대하여 소득의 성격과 납세자의 부담능력 등에 따라 적정하게 과세함으로써 조세부담의 형평을 도모하고 재정수입의 원활한 조달에 이바지함을 목적으로 한다.\"},\n",
    "        {\"contexts\": \"제1조의2(정의) “거주자”란 국내에 주소를 두거나 183일 이상의 거소를 둔 개인을 말한다.\"},\n",
    "        {\"contexts\": \"제1조의2(정의) “비거주자”란 거주자가 아닌 개인을 말한다.\"},\n",
    "        {\"contexts\": \"제1조의2(정의) “내국법인”이란 「법인세법」 제2조제1호에 따른 내국법인을 말한다.\"},\n",
    "        {\"contexts\": \"제2조(납세의무) 거주자 및 국내원천소득이 있는 비거주자는 소득세를 납부할 의무가 있다.\"},\n",
    "        {\"contexts\": \"제3조(과세소득의 범위) 거주자는 법에서 규정한 모든 소득에 대해 과세되며, 비거주자는 국내원천소득에 대해서만 과세된다.\"},\n",
    "        {\"contexts\": \"제4조(소득의 구분) 소득은 종합소득, 퇴직소득, 양도소득으로 분류된다.\"},\n",
    "        {\"contexts\": \"제4조(소득의 구분) 종합소득은 이자소득, 배당소득, 사업소득, 근로소득, 연금소득 및 기타소득을 포함한다.\"},\n",
    "        {\"contexts\": \"제12조(비과세소득) 비과세 소득에는 공익신탁의 이익, 특정 사업소득 및 기타 법에서 정한 특정 소득이 포함된다.\"},\n",
    "        {\"contexts\": \"제5조(과세기간) 소득세의 과세기간은 매년 1월 1일부터 12월 31일까지이다.\"},\n",
    "        {\"contexts\": \"제6조(납세지) 거주자의 소득세 납세지는 주소지이며, 주소지가 없으면 거소지이다.\"},\n",
    "        {\"contexts\": \"제6조(납세지) 비거주자의 소득세 납세지는 국내사업장의 소재지이다. 국내사업장이 여러 곳인 경우 주된 사업장의 소재지이다.\"},\n",
    "        {\"contexts\": \"제6조(납세지) 납세지가 불분명한 경우에는 대통령령으로 정한다.\"},\n",
    "        {\"contexts\": \"제7조(원천징수 등의 경우의 납세지) 원천징수세액의 납세지는 원천징수자의 종류와 위치에 따라 결정된다.\"},\n",
    "        {\"contexts\": \"제8조(상속 등의 경우의 납세지) 납세자의 사망 시 상속인 또는 납세관리인의 주소지나 거소지가 납세지가 된다.\"},\n",
    "        {\"contexts\": \"제2조의3(신탁재산 귀속 소득에 대한 납세의무의 범위) 신탁 소득에 대한 납세의 범위는 신탁의 수익자가 해당 소득에 대해 납세의무를 진다.\"},\n",
    "        {\"contexts\": \"제14조(과세표준의 계산) 이자소득, 배당소득 및 기타 법에서 정한 소득은 원천징수 대상이다.\"},\n",
    "        {\"contexts\": \"제14조(과세표준의 계산) 공동 소유 자산의 양도소득은 각 거주자 소유 지분에 따라 과세된다.\"},\n",
    "        {\"contexts\": \"제16조(이자소득) 이자 소득의 출처는 정부 및 지방자치단체가 발행한 채권, 법인이 발행한 채권, 국내외 은행 예금 등이다.\"},\n",
    "        {\"contexts\": \"제17조(배당소득) 배당소득은 국내외 법인으로부터 받는 배당금 및 배분금, 기타 법에서 정한 소득을 포함한다.\"}\n",
    "    ],\n",
    "    dataset_id=dataset.id,\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retriever 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "embedding = OpenAIEmbeddings(model='text-embedding-3-large')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/pinecone/data/index.py:1: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from tqdm.autonotebook import tqdm\n"
     ]
    }
   ],
   "source": [
    "from langchain_pinecone import PineconeVectorStore\n",
    "\n",
    "index_name = 'tax-markdown-index'\n",
    "\n",
    "database = PineconeVectorStore.from_existing_index(index_name=index_name, embedding=embedding)\n",
    "retriever = database.as_retriever()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LLM 답변 생성을 위한 RAGBot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "from langsmith import traceable\n",
    "from langsmith.wrappers import wrap_openai\n",
    "\n",
    "class RagBot:\n",
    "\n",
    "    def __init__(self, retriever, model: str = \"gpt-4o\"):\n",
    "        # 위에서 선언한 retriever를 할용해서 Retrieval 실행\n",
    "        self._retriever = retriever\n",
    "        # Wrapping the client instruments the LLM\n",
    "        # LangSmith 문법\n",
    "        self._client = wrap_openai(openai.Client())\n",
    "        self._model = model\n",
    "\n",
    "    @traceable()\n",
    "    def retrieve_docs(self, question):\n",
    "        return self._retriever.invoke(question)\n",
    "\n",
    "    @traceable()\n",
    "    def invoke_llm(self, question, docs):\n",
    "        # `retrieve_docs()` 를 통해 가져온 문서들을 system prompt로 전달\n",
    "        # 3.3에서 했던 방식과 유사함\n",
    "        response = self._client.chat.completions.create(\n",
    "            model=self._model,\n",
    "            messages=[\n",
    "                {\n",
    "                    \"role\": \"system\",\n",
    "                    \"content\": \"당신은 한국의 소득세 전문가입니다.\"\n",
    "                    \"아래 소득세법을 참고해서 사용자의 질문에 답변해주세요.\\n\\n\"\n",
    "                    f\"## 소득세법\\n\\n{docs}\",\n",
    "                },\n",
    "                {\"role\": \"user\", \"content\": question},\n",
    "            ],\n",
    "        )\n",
    "\n",
    "        # Evaluators 를 활용해서 `answer`와 `context`를 평가할 예정\n",
    "        return {\n",
    "            \"answer\": response.choices[0].message.content,\n",
    "            \"contexts\": [str(doc) for doc in docs],\n",
    "        }\n",
    "\n",
    "    @traceable()\n",
    "    def get_answer(self, question: str):\n",
    "        docs = self.retrieve_docs(question)\n",
    "        return self.invoke_llm(question, docs)\n",
    "\n",
    "rag_bot = RagBot(retriever)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_rag_answer(example: dict):\n",
    "    \"\"\"답변만 평가할 때 사용\"\"\"\n",
    "    response = rag_bot.get_answer(example[\"input_question\"])\n",
    "    return {\"answer\": response[\"answer\"]}\n",
    "\n",
    "def predict_rag_answer_with_context(example: dict):\n",
    "    \"\"\"Context를 활용해서 hallucination을 평가할 때 사용\"\"\"\n",
    "    response = rag_bot.get_answer(example[\"input_question\"])\n",
    "    return {\"answer\": response[\"answer\"], \"contexts\": response[\"contexts\"]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import hub\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# Grade prompt\n",
    "# 답변의 정확도를 측정하기위해 사용되는 프롬프트\n",
    "grade_prompt_answer_accuracy = prompt = hub.pull(\"langchain-ai/rag-answer-vs-reference\")\n",
    "\n",
    "def answer_evaluator(run, example) -> dict:\n",
    "    \"\"\"\n",
    "    RAG 답변 성능을 측정하기 위한 evaluator\n",
    "    \"\"\"\n",
    "\n",
    "    # `example`이 데이터를 생성할 때 입력한 `Question-Answer` pair. `run`은 `RagBot`을 활용해서 생성한 LLM의 답변\n",
    "    input_question = example.inputs[\"input_question\"]\n",
    "    reference = example.outputs[\"output_answer\"]\n",
    "    prediction = run.outputs[\"answer\"]\n",
    "\n",
    "    # LLM Judge로 사용될 LLM\n",
    "    llm = ChatOpenAI(model=\"gpt-4o\", temperature=0)\n",
    "\n",
    "    # LLM 응답을 위한 LCEL 활용\n",
    "    # 3.6 `dictionary_chain`의 `prompt | llm | StrOutputParser()`` 의 구조와 유사함\n",
    "    answer_grader = grade_prompt_answer_accuracy | llm\n",
    "\n",
    "    # Evaluator 실행\n",
    "    score = answer_grader.invoke({\"question\": input_question,\n",
    "                                  \"correct_answer\": reference,\n",
    "                                  \"student_answer\": prediction})\n",
    "    score = score[\"Score\"]\n",
    "\n",
    "    return {\"key\": \"answer_v_reference_score\", \"score\": score}\n",
    "# Grade prompt\n",
    "# 답변이 사용자의 질문에 얼마나 도움되는지 판단하는 프롬프트\n",
    "grade_prompt_answer_helpfulness = prompt = hub.pull(\"langchain-ai/rag-answer-helpfulness\")\n",
    "\n",
    "def answer_helpfulness_evaluator(run, example) -> dict:\n",
    "    \"\"\"\n",
    "    답변이 사용자의 질문에 얼마나 도움되는지 판단하는 Evaluator\n",
    "    \"\"\"\n",
    "\n",
    "    # 데이터셋의 답변과 비교하지 않고, 데이터셋의 질문에 대한 LLM의 답변의 가치를 평가함\n",
    "    input_question = example.inputs[\"input_question\"]\n",
    "    prediction = run.outputs[\"answer\"]\n",
    "\n",
    "    # LLM Judge로 사용될 LLM\n",
    "    llm = ChatOpenAI(model=\"gpt-4o\", temperature=0)\n",
    "\n",
    "    # LLM 응답을 위한 LCEL 활용\n",
    "    # 3.6 `dictionary_chain`의 `prompt | llm | StrOutputParser()`` 의 구조와 유사함\n",
    "    answer_grader = grade_prompt_answer_helpfulness | llm\n",
    "\n",
    "    # Evaluator 실행\n",
    "    score = answer_grader.invoke({\"question\": input_question,\n",
    "                                  \"student_answer\": prediction})\n",
    "    score = score[\"Score\"]\n",
    "\n",
    "    return {\"key\": \"answer_helpfulness_score\", \"score\": score}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grade prompt\n",
    "# 답변이 사용자의 질문에 얼마나 도움되는지 판단하는 프롬프트\n",
    "grade_prompt_answer_helpfulness = prompt = hub.pull(\"langchain-ai/rag-answer-helpfulness\")\n",
    "\n",
    "def answer_hallucination_evaluator(run, example) -> dict:\n",
    "    \"\"\"\n",
    "    hallucination 판단을 위한 Evaluator\n",
    "    \"\"\"\n",
    "\n",
    "    # 데이터셋에 있는 질문과, LLM이 답변을 생성할 때 사용한 context를 활용\n",
    "    input_question = example.inputs[\"input_question\"]\n",
    "    contexts = run.outputs[\"contexts\"]\n",
    "\n",
    "    # LLM의 답변\n",
    "    prediction = run.outputs[\"answer\"]\n",
    "\n",
    "    # LLM Judge로 사용될 LLM\n",
    "    llm = ChatOpenAI(model=\"gpt-4o\", temperature=0)\n",
    "\n",
    "    # LLM 응답을 위한 LCEL 활용\n",
    "    # 3.6 `dictionary_chain`의 `prompt | llm | StrOutputParser()`` 의 구조와 유사함\n",
    "    answer_grader = grade_prompt_hallucinations | llm\n",
    "\n",
    "    # Evaluator 실행\n",
    "    score = answer_grader.invoke({\"documents\": contexts,\n",
    "                                  \"student_answer\": prediction})\n",
    "    score = score[\"Score\"]\n",
    "\n",
    "    return {\"key\": \"answer_hallucination\", \"score\": score}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "View the evaluation results for experiment: 'inflearn-evaluator-lecture-hallucination-cdcb91f8' at:\n",
      "https://smith.langchain.com/o/2f003b67-27f4-48d0-8856-e1db2397e3d4/datasets/292b8275-5cfc-4310-9d5f-d830adc71bad/compare?selectedSessions=c74b7441-88f7-4b8a-9a82-5d792be756fa\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]Error running evaluator <DynamicRunEvaluator answer_evaluator> on run d4af1ba0-81f9-4569-87cc-af340a3efb32: RateLimitError(\"Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o in organization org-CnOnLIaLFhfXUDRV6hWHsPkS on tokens per min (TPM): Limit 30000, Used 29793, Requested 427. Please try again in 440ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\")\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/evaluation/_runner.py\", line 1404, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/evaluation/evaluator.py\", line 331, in evaluate_run\n",
      "    result = self.func(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 617, in wrapper\n",
      "    raise e\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 614, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "  File \"/var/folders/1l/w3vzbf215cs4ll30rh71l7wr6ghggx/T/ipykernel_59744/2954685631.py\", line 26, in answer_evaluator\n",
      "    score = answer_grader.invoke({\"question\": input_question,\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langchain_core/runnables/base.py\", line 3024, in invoke\n",
      "    input = context.run(step.invoke, input, config)\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langchain_core/runnables/base.py\", line 5354, in invoke\n",
      "    return self.bound.invoke(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langchain_core/language_models/chat_models.py\", line 286, in invoke\n",
      "    self.generate_prompt(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langchain_core/language_models/chat_models.py\", line 786, in generate_prompt\n",
      "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langchain_core/language_models/chat_models.py\", line 643, in generate\n",
      "    raise e\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langchain_core/language_models/chat_models.py\", line 633, in generate\n",
      "    self._generate_with_cache(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langchain_core/language_models/chat_models.py\", line 851, in _generate_with_cache\n",
      "    result = self._generate(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langchain_openai/chat_models/base.py\", line 689, in _generate\n",
      "    response = self.client.create(**payload)\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 275, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/resources/chat/completions.py\", line 829, in create\n",
      "    return self._post(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/_base_client.py\", line 1280, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/_base_client.py\", line 957, in request\n",
      "    return self._request(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/_base_client.py\", line 1046, in _request\n",
      "    return self._retry_request(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/_base_client.py\", line 1095, in _retry_request\n",
      "    return self._request(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/_base_client.py\", line 1046, in _request\n",
      "    return self._retry_request(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/_base_client.py\", line 1095, in _retry_request\n",
      "    return self._request(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/_base_client.py\", line 1061, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o in organization org-CnOnLIaLFhfXUDRV6hWHsPkS on tokens per min (TPM): Limit 30000, Used 29793, Requested 427. Please try again in 440ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Error running evaluator <DynamicRunEvaluator answer_evaluator> on run 2581aa4f-276a-41b1-9d2b-81718aa82158: RateLimitError(\"Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o in organization org-CnOnLIaLFhfXUDRV6hWHsPkS on tokens per min (TPM): Limit 30000, Used 29753, Requested 460. Please try again in 426ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\")\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/evaluation/_runner.py\", line 1404, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/evaluation/evaluator.py\", line 331, in evaluate_run\n",
      "    result = self.func(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 617, in wrapper\n",
      "    raise e\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 614, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "  File \"/var/folders/1l/w3vzbf215cs4ll30rh71l7wr6ghggx/T/ipykernel_59744/2954685631.py\", line 26, in answer_evaluator\n",
      "    score = answer_grader.invoke({\"question\": input_question,\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langchain_core/runnables/base.py\", line 3024, in invoke\n",
      "    input = context.run(step.invoke, input, config)\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langchain_core/runnables/base.py\", line 5354, in invoke\n",
      "    return self.bound.invoke(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langchain_core/language_models/chat_models.py\", line 286, in invoke\n",
      "    self.generate_prompt(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langchain_core/language_models/chat_models.py\", line 786, in generate_prompt\n",
      "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langchain_core/language_models/chat_models.py\", line 643, in generate\n",
      "    raise e\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langchain_core/language_models/chat_models.py\", line 633, in generate\n",
      "    self._generate_with_cache(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langchain_core/language_models/chat_models.py\", line 851, in _generate_with_cache\n",
      "    result = self._generate(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langchain_openai/chat_models/base.py\", line 689, in _generate\n",
      "    response = self.client.create(**payload)\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 275, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/resources/chat/completions.py\", line 829, in create\n",
      "    return self._post(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/_base_client.py\", line 1280, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/_base_client.py\", line 957, in request\n",
      "    return self._request(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/_base_client.py\", line 1046, in _request\n",
      "    return self._retry_request(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/_base_client.py\", line 1095, in _retry_request\n",
      "    return self._request(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/_base_client.py\", line 1046, in _request\n",
      "    return self._retry_request(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/_base_client.py\", line 1095, in _retry_request\n",
      "    return self._request(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/_base_client.py\", line 1061, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o in organization org-CnOnLIaLFhfXUDRV6hWHsPkS on tokens per min (TPM): Limit 30000, Used 29753, Requested 460. Please try again in 426ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Error running evaluator <DynamicRunEvaluator answer_evaluator> on run 9e0ebcf9-f0d0-41bc-bf6c-99f37337991e: RateLimitError(\"Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o in organization org-CnOnLIaLFhfXUDRV6hWHsPkS on tokens per min (TPM): Limit 30000, Used 29948, Requested 471. Please try again in 838ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\")\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/evaluation/_runner.py\", line 1404, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/evaluation/evaluator.py\", line 331, in evaluate_run\n",
      "    result = self.func(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 617, in wrapper\n",
      "    raise e\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 614, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "  File \"/var/folders/1l/w3vzbf215cs4ll30rh71l7wr6ghggx/T/ipykernel_59744/2954685631.py\", line 26, in answer_evaluator\n",
      "    score = answer_grader.invoke({\"question\": input_question,\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langchain_core/runnables/base.py\", line 3024, in invoke\n",
      "    input = context.run(step.invoke, input, config)\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langchain_core/runnables/base.py\", line 5354, in invoke\n",
      "    return self.bound.invoke(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langchain_core/language_models/chat_models.py\", line 286, in invoke\n",
      "    self.generate_prompt(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langchain_core/language_models/chat_models.py\", line 786, in generate_prompt\n",
      "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langchain_core/language_models/chat_models.py\", line 643, in generate\n",
      "    raise e\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langchain_core/language_models/chat_models.py\", line 633, in generate\n",
      "    self._generate_with_cache(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langchain_core/language_models/chat_models.py\", line 851, in _generate_with_cache\n",
      "    result = self._generate(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langchain_openai/chat_models/base.py\", line 689, in _generate\n",
      "    response = self.client.create(**payload)\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 275, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/resources/chat/completions.py\", line 829, in create\n",
      "    return self._post(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/_base_client.py\", line 1280, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/_base_client.py\", line 957, in request\n",
      "    return self._request(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/_base_client.py\", line 1046, in _request\n",
      "    return self._retry_request(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/_base_client.py\", line 1095, in _retry_request\n",
      "    return self._request(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/_base_client.py\", line 1046, in _request\n",
      "    return self._retry_request(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/_base_client.py\", line 1095, in _retry_request\n",
      "    return self._request(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/_base_client.py\", line 1061, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o in organization org-CnOnLIaLFhfXUDRV6hWHsPkS on tokens per min (TPM): Limit 30000, Used 29948, Requested 471. Please try again in 838ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Error running evaluator <DynamicRunEvaluator answer_evaluator> on run 464fc3ca-4bd2-48a6-ba85-37d040fb02b4: RateLimitError(\"Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o in organization org-CnOnLIaLFhfXUDRV6hWHsPkS on tokens per min (TPM): Limit 30000, Used 29955, Requested 372. Please try again in 654ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\")\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/evaluation/_runner.py\", line 1404, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/evaluation/evaluator.py\", line 331, in evaluate_run\n",
      "    result = self.func(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 617, in wrapper\n",
      "    raise e\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 614, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "  File \"/var/folders/1l/w3vzbf215cs4ll30rh71l7wr6ghggx/T/ipykernel_59744/2954685631.py\", line 26, in answer_evaluator\n",
      "    score = answer_grader.invoke({\"question\": input_question,\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langchain_core/runnables/base.py\", line 3024, in invoke\n",
      "    input = context.run(step.invoke, input, config)\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langchain_core/runnables/base.py\", line 5354, in invoke\n",
      "    return self.bound.invoke(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langchain_core/language_models/chat_models.py\", line 286, in invoke\n",
      "    self.generate_prompt(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langchain_core/language_models/chat_models.py\", line 786, in generate_prompt\n",
      "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langchain_core/language_models/chat_models.py\", line 643, in generate\n",
      "    raise e\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langchain_core/language_models/chat_models.py\", line 633, in generate\n",
      "    self._generate_with_cache(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langchain_core/language_models/chat_models.py\", line 851, in _generate_with_cache\n",
      "    result = self._generate(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langchain_openai/chat_models/base.py\", line 689, in _generate\n",
      "    response = self.client.create(**payload)\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 275, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/resources/chat/completions.py\", line 829, in create\n",
      "    return self._post(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/_base_client.py\", line 1280, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/_base_client.py\", line 957, in request\n",
      "    return self._request(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/_base_client.py\", line 1046, in _request\n",
      "    return self._retry_request(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/_base_client.py\", line 1095, in _retry_request\n",
      "    return self._request(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/_base_client.py\", line 1046, in _request\n",
      "    return self._retry_request(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/_base_client.py\", line 1095, in _retry_request\n",
      "    return self._request(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/_base_client.py\", line 1061, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o in organization org-CnOnLIaLFhfXUDRV6hWHsPkS on tokens per min (TPM): Limit 30000, Used 29955, Requested 372. Please try again in 654ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Error running evaluator <DynamicRunEvaluator answer_helpfulness_evaluator> on run de93a2c1-53b7-40e1-9e93-92ce8c5c7156: RateLimitError(\"Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o in organization org-CnOnLIaLFhfXUDRV6hWHsPkS on tokens per min (TPM): Limit 30000, Used 29946, Requested 298. Please try again in 487ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\")\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/evaluation/_runner.py\", line 1404, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/evaluation/evaluator.py\", line 331, in evaluate_run\n",
      "    result = self.func(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 617, in wrapper\n",
      "    raise e\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 614, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "  File \"/var/folders/1l/w3vzbf215cs4ll30rh71l7wr6ghggx/T/ipykernel_59744/2954685631.py\", line 53, in answer_helpfulness_evaluator\n",
      "    score = answer_grader.invoke({\"question\": input_question,\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langchain_core/runnables/base.py\", line 3024, in invoke\n",
      "    input = context.run(step.invoke, input, config)\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langchain_core/runnables/base.py\", line 5354, in invoke\n",
      "    return self.bound.invoke(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langchain_core/language_models/chat_models.py\", line 286, in invoke\n",
      "    self.generate_prompt(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langchain_core/language_models/chat_models.py\", line 786, in generate_prompt\n",
      "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langchain_core/language_models/chat_models.py\", line 643, in generate\n",
      "    raise e\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langchain_core/language_models/chat_models.py\", line 633, in generate\n",
      "    self._generate_with_cache(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langchain_core/language_models/chat_models.py\", line 851, in _generate_with_cache\n",
      "    result = self._generate(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langchain_openai/chat_models/base.py\", line 689, in _generate\n",
      "    response = self.client.create(**payload)\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 275, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/resources/chat/completions.py\", line 829, in create\n",
      "    return self._post(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/_base_client.py\", line 1280, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/_base_client.py\", line 957, in request\n",
      "    return self._request(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/_base_client.py\", line 1046, in _request\n",
      "    return self._retry_request(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/_base_client.py\", line 1095, in _retry_request\n",
      "    return self._request(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/_base_client.py\", line 1046, in _request\n",
      "    return self._retry_request(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/_base_client.py\", line 1095, in _retry_request\n",
      "    return self._request(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/_base_client.py\", line 1061, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o in organization org-CnOnLIaLFhfXUDRV6hWHsPkS on tokens per min (TPM): Limit 30000, Used 29946, Requested 298. Please try again in 487ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Error running evaluator <DynamicRunEvaluator answer_helpfulness_evaluator> on run d4af1ba0-81f9-4569-87cc-af340a3efb32: RateLimitError(\"Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o in organization org-CnOnLIaLFhfXUDRV6hWHsPkS on tokens per min (TPM): Limit 30000, Used 29919, Requested 338. Please try again in 514ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\")\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/evaluation/_runner.py\", line 1404, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/evaluation/evaluator.py\", line 331, in evaluate_run\n",
      "    result = self.func(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 617, in wrapper\n",
      "    raise e\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 614, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "  File \"/var/folders/1l/w3vzbf215cs4ll30rh71l7wr6ghggx/T/ipykernel_59744/2954685631.py\", line 53, in answer_helpfulness_evaluator\n",
      "    score = answer_grader.invoke({\"question\": input_question,\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langchain_core/runnables/base.py\", line 3024, in invoke\n",
      "    input = context.run(step.invoke, input, config)\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langchain_core/runnables/base.py\", line 5354, in invoke\n",
      "    return self.bound.invoke(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langchain_core/language_models/chat_models.py\", line 286, in invoke\n",
      "    self.generate_prompt(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langchain_core/language_models/chat_models.py\", line 786, in generate_prompt\n",
      "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langchain_core/language_models/chat_models.py\", line 643, in generate\n",
      "    raise e\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langchain_core/language_models/chat_models.py\", line 633, in generate\n",
      "    self._generate_with_cache(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langchain_core/language_models/chat_models.py\", line 851, in _generate_with_cache\n",
      "    result = self._generate(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langchain_openai/chat_models/base.py\", line 689, in _generate\n",
      "    response = self.client.create(**payload)\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 275, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/resources/chat/completions.py\", line 829, in create\n",
      "    return self._post(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/_base_client.py\", line 1280, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/_base_client.py\", line 957, in request\n",
      "    return self._request(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/_base_client.py\", line 1046, in _request\n",
      "    return self._retry_request(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/_base_client.py\", line 1095, in _retry_request\n",
      "    return self._request(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/_base_client.py\", line 1046, in _request\n",
      "    return self._retry_request(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/_base_client.py\", line 1095, in _retry_request\n",
      "    return self._request(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/_base_client.py\", line 1061, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o in organization org-CnOnLIaLFhfXUDRV6hWHsPkS on tokens per min (TPM): Limit 30000, Used 29919, Requested 338. Please try again in 514ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Error running evaluator <DynamicRunEvaluator answer_helpfulness_evaluator> on run 9e0ebcf9-f0d0-41bc-bf6c-99f37337991e: RateLimitError(\"Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o in organization org-CnOnLIaLFhfXUDRV6hWHsPkS on tokens per min (TPM): Limit 30000, Used 29879, Requested 376. Please try again in 510ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\")\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/evaluation/_runner.py\", line 1404, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/evaluation/evaluator.py\", line 331, in evaluate_run\n",
      "    result = self.func(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 617, in wrapper\n",
      "    raise e\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 614, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "  File \"/var/folders/1l/w3vzbf215cs4ll30rh71l7wr6ghggx/T/ipykernel_59744/2954685631.py\", line 53, in answer_helpfulness_evaluator\n",
      "    score = answer_grader.invoke({\"question\": input_question,\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langchain_core/runnables/base.py\", line 3024, in invoke\n",
      "    input = context.run(step.invoke, input, config)\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langchain_core/runnables/base.py\", line 5354, in invoke\n",
      "    return self.bound.invoke(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langchain_core/language_models/chat_models.py\", line 286, in invoke\n",
      "    self.generate_prompt(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langchain_core/language_models/chat_models.py\", line 786, in generate_prompt\n",
      "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langchain_core/language_models/chat_models.py\", line 643, in generate\n",
      "    raise e\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langchain_core/language_models/chat_models.py\", line 633, in generate\n",
      "    self._generate_with_cache(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langchain_core/language_models/chat_models.py\", line 851, in _generate_with_cache\n",
      "    result = self._generate(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langchain_openai/chat_models/base.py\", line 689, in _generate\n",
      "    response = self.client.create(**payload)\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 275, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/resources/chat/completions.py\", line 829, in create\n",
      "    return self._post(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/_base_client.py\", line 1280, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/_base_client.py\", line 957, in request\n",
      "    return self._request(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/_base_client.py\", line 1046, in _request\n",
      "    return self._retry_request(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/_base_client.py\", line 1095, in _retry_request\n",
      "    return self._request(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/_base_client.py\", line 1046, in _request\n",
      "    return self._retry_request(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/_base_client.py\", line 1095, in _retry_request\n",
      "    return self._request(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/_base_client.py\", line 1061, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o in organization org-CnOnLIaLFhfXUDRV6hWHsPkS on tokens per min (TPM): Limit 30000, Used 29879, Requested 376. Please try again in 510ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Error running evaluator <DynamicRunEvaluator answer_helpfulness_evaluator> on run 2581aa4f-276a-41b1-9d2b-81718aa82158: RateLimitError(\"Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o in organization org-CnOnLIaLFhfXUDRV6hWHsPkS on tokens per min (TPM): Limit 30000, Used 29872, Requested 373. Please try again in 489ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\")\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/evaluation/_runner.py\", line 1404, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/evaluation/evaluator.py\", line 331, in evaluate_run\n",
      "    result = self.func(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 617, in wrapper\n",
      "    raise e\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 614, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "  File \"/var/folders/1l/w3vzbf215cs4ll30rh71l7wr6ghggx/T/ipykernel_59744/2954685631.py\", line 53, in answer_helpfulness_evaluator\n",
      "    score = answer_grader.invoke({\"question\": input_question,\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langchain_core/runnables/base.py\", line 3024, in invoke\n",
      "    input = context.run(step.invoke, input, config)\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langchain_core/runnables/base.py\", line 5354, in invoke\n",
      "    return self.bound.invoke(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langchain_core/language_models/chat_models.py\", line 286, in invoke\n",
      "    self.generate_prompt(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langchain_core/language_models/chat_models.py\", line 786, in generate_prompt\n",
      "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langchain_core/language_models/chat_models.py\", line 643, in generate\n",
      "    raise e\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langchain_core/language_models/chat_models.py\", line 633, in generate\n",
      "    self._generate_with_cache(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langchain_core/language_models/chat_models.py\", line 851, in _generate_with_cache\n",
      "    result = self._generate(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langchain_openai/chat_models/base.py\", line 689, in _generate\n",
      "    response = self.client.create(**payload)\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 275, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/resources/chat/completions.py\", line 829, in create\n",
      "    return self._post(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/_base_client.py\", line 1280, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/_base_client.py\", line 957, in request\n",
      "    return self._request(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/_base_client.py\", line 1046, in _request\n",
      "    return self._retry_request(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/_base_client.py\", line 1095, in _retry_request\n",
      "    return self._request(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/_base_client.py\", line 1046, in _request\n",
      "    return self._retry_request(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/_base_client.py\", line 1095, in _retry_request\n",
      "    return self._request(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/_base_client.py\", line 1061, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o in organization org-CnOnLIaLFhfXUDRV6hWHsPkS on tokens per min (TPM): Limit 30000, Used 29872, Requested 373. Please try again in 489ms. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "1it [00:13, 13.37s/it]Error running target function: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o in organization org-CnOnLIaLFhfXUDRV6hWHsPkS on tokens per min (TPM): Limit 30000, Used 28934, Requested 3307. Please try again in 4.482s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/evaluation/_runner.py\", line 1675, in _forward\n",
      "    fn(example.inputs, langsmith_extra=langsmith_extra)\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 617, in wrapper\n",
      "    raise e\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 614, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "  File \"/var/folders/1l/w3vzbf215cs4ll30rh71l7wr6ghggx/T/ipykernel_59744/3191971669.py\", line 8, in predict_rag_answer_with_context\n",
      "    response = rag_bot.get_answer(example[\"input_question\"])\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 617, in wrapper\n",
      "    raise e\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 614, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "  File \"/var/folders/1l/w3vzbf215cs4ll30rh71l7wr6ghggx/T/ipykernel_59744/3657546987.py\", line 45, in get_answer\n",
      "    return self.invoke_llm(question, docs)\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 617, in wrapper\n",
      "    raise e\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 614, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "  File \"/var/folders/1l/w3vzbf215cs4ll30rh71l7wr6ghggx/T/ipykernel_59744/3657546987.py\", line 23, in invoke_llm\n",
      "    response = self._client.chat.completions.create(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/wrappers/_openai.py\", line 238, in create\n",
      "    return decorator(original_create)(*args, stream=stream, **kwargs)\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 617, in wrapper\n",
      "    raise e\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 614, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 275, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/resources/chat/completions.py\", line 829, in create\n",
      "    return self._post(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/_base_client.py\", line 1280, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/_base_client.py\", line 957, in request\n",
      "    return self._request(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/_base_client.py\", line 1046, in _request\n",
      "    return self._retry_request(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/_base_client.py\", line 1095, in _retry_request\n",
      "    return self._request(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/_base_client.py\", line 1046, in _request\n",
      "    return self._retry_request(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/_base_client.py\", line 1095, in _retry_request\n",
      "    return self._request(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/_base_client.py\", line 1061, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o in organization org-CnOnLIaLFhfXUDRV6hWHsPkS on tokens per min (TPM): Limit 30000, Used 28934, Requested 3307. Please try again in 4.482s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Error running evaluator <DynamicRunEvaluator answer_evaluator> on run 7a6bd6d2-4ee2-4cf8-b4e4-4a064cb5d267: KeyError('answer')\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/evaluation/_runner.py\", line 1404, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/evaluation/evaluator.py\", line 331, in evaluate_run\n",
      "    result = self.func(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 617, in wrapper\n",
      "    raise e\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 614, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "  File \"/var/folders/1l/w3vzbf215cs4ll30rh71l7wr6ghggx/T/ipykernel_59744/2954685631.py\", line 16, in answer_evaluator\n",
      "    prediction = run.outputs[\"answer\"]\n",
      "KeyError: 'answer'\n",
      "Error running evaluator <DynamicRunEvaluator answer_helpfulness_evaluator> on run 7a6bd6d2-4ee2-4cf8-b4e4-4a064cb5d267: KeyError('answer')\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/evaluation/_runner.py\", line 1404, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/evaluation/evaluator.py\", line 331, in evaluate_run\n",
      "    result = self.func(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 617, in wrapper\n",
      "    raise e\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 614, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "  File \"/var/folders/1l/w3vzbf215cs4ll30rh71l7wr6ghggx/T/ipykernel_59744/2954685631.py\", line 43, in answer_helpfulness_evaluator\n",
      "    prediction = run.outputs[\"answer\"]\n",
      "KeyError: 'answer'\n",
      "Error running target function: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o in organization org-CnOnLIaLFhfXUDRV6hWHsPkS on tokens per min (TPM): Limit 30000, Used 28846, Requested 3352. Please try again in 4.396s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/evaluation/_runner.py\", line 1675, in _forward\n",
      "    fn(example.inputs, langsmith_extra=langsmith_extra)\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 617, in wrapper\n",
      "    raise e\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 614, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "  File \"/var/folders/1l/w3vzbf215cs4ll30rh71l7wr6ghggx/T/ipykernel_59744/3191971669.py\", line 8, in predict_rag_answer_with_context\n",
      "    response = rag_bot.get_answer(example[\"input_question\"])\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 617, in wrapper\n",
      "    raise e\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 614, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "  File \"/var/folders/1l/w3vzbf215cs4ll30rh71l7wr6ghggx/T/ipykernel_59744/3657546987.py\", line 45, in get_answer\n",
      "    return self.invoke_llm(question, docs)\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 617, in wrapper\n",
      "    raise e\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 614, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "  File \"/var/folders/1l/w3vzbf215cs4ll30rh71l7wr6ghggx/T/ipykernel_59744/3657546987.py\", line 23, in invoke_llm\n",
      "    response = self._client.chat.completions.create(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/wrappers/_openai.py\", line 238, in create\n",
      "    return decorator(original_create)(*args, stream=stream, **kwargs)\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 617, in wrapper\n",
      "    raise e\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 614, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 275, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/resources/chat/completions.py\", line 829, in create\n",
      "    return self._post(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/_base_client.py\", line 1280, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/_base_client.py\", line 957, in request\n",
      "    return self._request(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/_base_client.py\", line 1046, in _request\n",
      "    return self._retry_request(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/_base_client.py\", line 1095, in _retry_request\n",
      "    return self._request(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/_base_client.py\", line 1046, in _request\n",
      "    return self._retry_request(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/_base_client.py\", line 1095, in _retry_request\n",
      "    return self._request(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/_base_client.py\", line 1061, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o in organization org-CnOnLIaLFhfXUDRV6hWHsPkS on tokens per min (TPM): Limit 30000, Used 28846, Requested 3352. Please try again in 4.396s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "9it [00:16,  1.41s/it]Error running evaluator <DynamicRunEvaluator answer_evaluator> on run f720a006-00ed-476c-83be-e78e02ab2a0d: KeyError('answer')\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/evaluation/_runner.py\", line 1404, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/evaluation/evaluator.py\", line 331, in evaluate_run\n",
      "    result = self.func(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 617, in wrapper\n",
      "    raise e\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 614, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "  File \"/var/folders/1l/w3vzbf215cs4ll30rh71l7wr6ghggx/T/ipykernel_59744/2954685631.py\", line 16, in answer_evaluator\n",
      "    prediction = run.outputs[\"answer\"]\n",
      "KeyError: 'answer'\n",
      "Error running evaluator <DynamicRunEvaluator answer_helpfulness_evaluator> on run f720a006-00ed-476c-83be-e78e02ab2a0d: KeyError('answer')\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/evaluation/_runner.py\", line 1404, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/evaluation/evaluator.py\", line 331, in evaluate_run\n",
      "    result = self.func(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 617, in wrapper\n",
      "    raise e\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 614, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "  File \"/var/folders/1l/w3vzbf215cs4ll30rh71l7wr6ghggx/T/ipykernel_59744/2954685631.py\", line 43, in answer_helpfulness_evaluator\n",
      "    prediction = run.outputs[\"answer\"]\n",
      "KeyError: 'answer'\n",
      "Error running target function: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o in organization org-CnOnLIaLFhfXUDRV6hWHsPkS on tokens per min (TPM): Limit 30000, Used 29396, Requested 3324. Please try again in 5.44s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/evaluation/_runner.py\", line 1675, in _forward\n",
      "    fn(example.inputs, langsmith_extra=langsmith_extra)\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 617, in wrapper\n",
      "    raise e\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 614, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "  File \"/var/folders/1l/w3vzbf215cs4ll30rh71l7wr6ghggx/T/ipykernel_59744/3191971669.py\", line 8, in predict_rag_answer_with_context\n",
      "    response = rag_bot.get_answer(example[\"input_question\"])\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 617, in wrapper\n",
      "    raise e\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 614, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "  File \"/var/folders/1l/w3vzbf215cs4ll30rh71l7wr6ghggx/T/ipykernel_59744/3657546987.py\", line 45, in get_answer\n",
      "    return self.invoke_llm(question, docs)\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 617, in wrapper\n",
      "    raise e\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 614, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "  File \"/var/folders/1l/w3vzbf215cs4ll30rh71l7wr6ghggx/T/ipykernel_59744/3657546987.py\", line 23, in invoke_llm\n",
      "    response = self._client.chat.completions.create(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/wrappers/_openai.py\", line 238, in create\n",
      "    return decorator(original_create)(*args, stream=stream, **kwargs)\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 617, in wrapper\n",
      "    raise e\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 614, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 275, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/resources/chat/completions.py\", line 829, in create\n",
      "    return self._post(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/_base_client.py\", line 1280, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/_base_client.py\", line 957, in request\n",
      "    return self._request(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/_base_client.py\", line 1046, in _request\n",
      "    return self._retry_request(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/_base_client.py\", line 1095, in _retry_request\n",
      "    return self._request(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/_base_client.py\", line 1046, in _request\n",
      "    return self._retry_request(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/_base_client.py\", line 1095, in _retry_request\n",
      "    return self._request(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/_base_client.py\", line 1061, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o in organization org-CnOnLIaLFhfXUDRV6hWHsPkS on tokens per min (TPM): Limit 30000, Used 29396, Requested 3324. Please try again in 5.44s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "10it [00:16,  1.23s/it]Error running evaluator <DynamicRunEvaluator answer_evaluator> on run fb72aa6e-4fad-4cc0-a931-9c51a2fc9a4d: KeyError('answer')\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/evaluation/_runner.py\", line 1404, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/evaluation/evaluator.py\", line 331, in evaluate_run\n",
      "    result = self.func(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 617, in wrapper\n",
      "    raise e\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 614, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "  File \"/var/folders/1l/w3vzbf215cs4ll30rh71l7wr6ghggx/T/ipykernel_59744/2954685631.py\", line 16, in answer_evaluator\n",
      "    prediction = run.outputs[\"answer\"]\n",
      "KeyError: 'answer'\n",
      "Error running evaluator <DynamicRunEvaluator answer_helpfulness_evaluator> on run fb72aa6e-4fad-4cc0-a931-9c51a2fc9a4d: KeyError('answer')\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/evaluation/_runner.py\", line 1404, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/evaluation/evaluator.py\", line 331, in evaluate_run\n",
      "    result = self.func(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 617, in wrapper\n",
      "    raise e\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 614, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "  File \"/var/folders/1l/w3vzbf215cs4ll30rh71l7wr6ghggx/T/ipykernel_59744/2954685631.py\", line 43, in answer_helpfulness_evaluator\n",
      "    prediction = run.outputs[\"answer\"]\n",
      "KeyError: 'answer'\n",
      "Error running target function: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o in organization org-CnOnLIaLFhfXUDRV6hWHsPkS on tokens per min (TPM): Limit 30000, Used 29381, Requested 3485. Please try again in 5.732s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/evaluation/_runner.py\", line 1675, in _forward\n",
      "    fn(example.inputs, langsmith_extra=langsmith_extra)\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 617, in wrapper\n",
      "    raise e\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 614, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "  File \"/var/folders/1l/w3vzbf215cs4ll30rh71l7wr6ghggx/T/ipykernel_59744/3191971669.py\", line 8, in predict_rag_answer_with_context\n",
      "    response = rag_bot.get_answer(example[\"input_question\"])\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 617, in wrapper\n",
      "    raise e\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 614, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "  File \"/var/folders/1l/w3vzbf215cs4ll30rh71l7wr6ghggx/T/ipykernel_59744/3657546987.py\", line 45, in get_answer\n",
      "    return self.invoke_llm(question, docs)\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 617, in wrapper\n",
      "    raise e\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 614, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "  File \"/var/folders/1l/w3vzbf215cs4ll30rh71l7wr6ghggx/T/ipykernel_59744/3657546987.py\", line 23, in invoke_llm\n",
      "    response = self._client.chat.completions.create(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/wrappers/_openai.py\", line 238, in create\n",
      "    return decorator(original_create)(*args, stream=stream, **kwargs)\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 617, in wrapper\n",
      "    raise e\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 614, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 275, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/resources/chat/completions.py\", line 829, in create\n",
      "    return self._post(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/_base_client.py\", line 1280, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/_base_client.py\", line 957, in request\n",
      "    return self._request(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/_base_client.py\", line 1046, in _request\n",
      "    return self._retry_request(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/_base_client.py\", line 1095, in _retry_request\n",
      "    return self._request(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/_base_client.py\", line 1046, in _request\n",
      "    return self._retry_request(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/_base_client.py\", line 1095, in _retry_request\n",
      "    return self._request(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/_base_client.py\", line 1061, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o in organization org-CnOnLIaLFhfXUDRV6hWHsPkS on tokens per min (TPM): Limit 30000, Used 29381, Requested 3485. Please try again in 5.732s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Error running evaluator <DynamicRunEvaluator answer_evaluator> on run 780e324b-8f37-4fb5-b429-6798a5cc7e07: KeyError('answer')\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/evaluation/_runner.py\", line 1404, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/evaluation/evaluator.py\", line 331, in evaluate_run\n",
      "    result = self.func(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 617, in wrapper\n",
      "    raise e\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 614, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "  File \"/var/folders/1l/w3vzbf215cs4ll30rh71l7wr6ghggx/T/ipykernel_59744/2954685631.py\", line 16, in answer_evaluator\n",
      "    prediction = run.outputs[\"answer\"]\n",
      "KeyError: 'answer'\n",
      "Error running evaluator <DynamicRunEvaluator answer_helpfulness_evaluator> on run 780e324b-8f37-4fb5-b429-6798a5cc7e07: KeyError('answer')\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/evaluation/_runner.py\", line 1404, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/evaluation/evaluator.py\", line 331, in evaluate_run\n",
      "    result = self.func(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 617, in wrapper\n",
      "    raise e\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 614, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "  File \"/var/folders/1l/w3vzbf215cs4ll30rh71l7wr6ghggx/T/ipykernel_59744/2954685631.py\", line 43, in answer_helpfulness_evaluator\n",
      "    prediction = run.outputs[\"answer\"]\n",
      "KeyError: 'answer'\n",
      "Error running target function: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o in organization org-CnOnLIaLFhfXUDRV6hWHsPkS on tokens per min (TPM): Limit 30000, Used 29146, Requested 3299. Please try again in 4.89s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/evaluation/_runner.py\", line 1675, in _forward\n",
      "    fn(example.inputs, langsmith_extra=langsmith_extra)\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 617, in wrapper\n",
      "    raise e\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 614, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "  File \"/var/folders/1l/w3vzbf215cs4ll30rh71l7wr6ghggx/T/ipykernel_59744/3191971669.py\", line 8, in predict_rag_answer_with_context\n",
      "    response = rag_bot.get_answer(example[\"input_question\"])\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 617, in wrapper\n",
      "    raise e\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 614, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "  File \"/var/folders/1l/w3vzbf215cs4ll30rh71l7wr6ghggx/T/ipykernel_59744/3657546987.py\", line 45, in get_answer\n",
      "    return self.invoke_llm(question, docs)\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 617, in wrapper\n",
      "    raise e\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 614, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "  File \"/var/folders/1l/w3vzbf215cs4ll30rh71l7wr6ghggx/T/ipykernel_59744/3657546987.py\", line 23, in invoke_llm\n",
      "    response = self._client.chat.completions.create(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/wrappers/_openai.py\", line 238, in create\n",
      "    return decorator(original_create)(*args, stream=stream, **kwargs)\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 617, in wrapper\n",
      "    raise e\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 614, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 275, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/resources/chat/completions.py\", line 829, in create\n",
      "    return self._post(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/_base_client.py\", line 1280, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/_base_client.py\", line 957, in request\n",
      "    return self._request(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/_base_client.py\", line 1046, in _request\n",
      "    return self._retry_request(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/_base_client.py\", line 1095, in _retry_request\n",
      "    return self._request(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/_base_client.py\", line 1046, in _request\n",
      "    return self._retry_request(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/_base_client.py\", line 1095, in _retry_request\n",
      "    return self._request(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/_base_client.py\", line 1061, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o in organization org-CnOnLIaLFhfXUDRV6hWHsPkS on tokens per min (TPM): Limit 30000, Used 29146, Requested 3299. Please try again in 4.89s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "12it [00:16,  1.05it/s]Error running evaluator <DynamicRunEvaluator answer_evaluator> on run 70ee9821-21c9-4bb1-a250-f766f774d1ec: KeyError('answer')\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/evaluation/_runner.py\", line 1404, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/evaluation/evaluator.py\", line 331, in evaluate_run\n",
      "    result = self.func(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 617, in wrapper\n",
      "    raise e\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 614, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "  File \"/var/folders/1l/w3vzbf215cs4ll30rh71l7wr6ghggx/T/ipykernel_59744/2954685631.py\", line 16, in answer_evaluator\n",
      "    prediction = run.outputs[\"answer\"]\n",
      "KeyError: 'answer'\n",
      "Error running evaluator <DynamicRunEvaluator answer_helpfulness_evaluator> on run 70ee9821-21c9-4bb1-a250-f766f774d1ec: KeyError('answer')\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/evaluation/_runner.py\", line 1404, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/evaluation/evaluator.py\", line 331, in evaluate_run\n",
      "    result = self.func(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 617, in wrapper\n",
      "    raise e\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 614, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "  File \"/var/folders/1l/w3vzbf215cs4ll30rh71l7wr6ghggx/T/ipykernel_59744/2954685631.py\", line 43, in answer_helpfulness_evaluator\n",
      "    prediction = run.outputs[\"answer\"]\n",
      "KeyError: 'answer'\n",
      "Error running target function: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o in organization org-CnOnLIaLFhfXUDRV6hWHsPkS on tokens per min (TPM): Limit 30000, Used 29139, Requested 3302. Please try again in 4.882s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/evaluation/_runner.py\", line 1675, in _forward\n",
      "    fn(example.inputs, langsmith_extra=langsmith_extra)\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 617, in wrapper\n",
      "    raise e\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 614, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "  File \"/var/folders/1l/w3vzbf215cs4ll30rh71l7wr6ghggx/T/ipykernel_59744/3191971669.py\", line 8, in predict_rag_answer_with_context\n",
      "    response = rag_bot.get_answer(example[\"input_question\"])\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 617, in wrapper\n",
      "    raise e\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 614, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "  File \"/var/folders/1l/w3vzbf215cs4ll30rh71l7wr6ghggx/T/ipykernel_59744/3657546987.py\", line 45, in get_answer\n",
      "    return self.invoke_llm(question, docs)\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 617, in wrapper\n",
      "    raise e\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 614, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "  File \"/var/folders/1l/w3vzbf215cs4ll30rh71l7wr6ghggx/T/ipykernel_59744/3657546987.py\", line 23, in invoke_llm\n",
      "    response = self._client.chat.completions.create(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/wrappers/_openai.py\", line 238, in create\n",
      "    return decorator(original_create)(*args, stream=stream, **kwargs)\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 617, in wrapper\n",
      "    raise e\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 614, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 275, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/resources/chat/completions.py\", line 829, in create\n",
      "    return self._post(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/_base_client.py\", line 1280, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/_base_client.py\", line 957, in request\n",
      "    return self._request(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/_base_client.py\", line 1046, in _request\n",
      "    return self._retry_request(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/_base_client.py\", line 1095, in _retry_request\n",
      "    return self._request(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/_base_client.py\", line 1046, in _request\n",
      "    return self._retry_request(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/_base_client.py\", line 1095, in _retry_request\n",
      "    return self._request(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/_base_client.py\", line 1061, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o in organization org-CnOnLIaLFhfXUDRV6hWHsPkS on tokens per min (TPM): Limit 30000, Used 29139, Requested 3302. Please try again in 4.882s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Error running evaluator <DynamicRunEvaluator answer_evaluator> on run 41181193-f98f-4955-a533-25e91b4648eb: KeyError('answer')\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/evaluation/_runner.py\", line 1404, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/evaluation/evaluator.py\", line 331, in evaluate_run\n",
      "    result = self.func(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 617, in wrapper\n",
      "    raise e\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 614, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "  File \"/var/folders/1l/w3vzbf215cs4ll30rh71l7wr6ghggx/T/ipykernel_59744/2954685631.py\", line 16, in answer_evaluator\n",
      "    prediction = run.outputs[\"answer\"]\n",
      "KeyError: 'answer'\n",
      "Error running evaluator <DynamicRunEvaluator answer_helpfulness_evaluator> on run 41181193-f98f-4955-a533-25e91b4648eb: KeyError('answer')\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/evaluation/_runner.py\", line 1404, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/evaluation/evaluator.py\", line 331, in evaluate_run\n",
      "    result = self.func(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 617, in wrapper\n",
      "    raise e\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 614, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "  File \"/var/folders/1l/w3vzbf215cs4ll30rh71l7wr6ghggx/T/ipykernel_59744/2954685631.py\", line 43, in answer_helpfulness_evaluator\n",
      "    prediction = run.outputs[\"answer\"]\n",
      "KeyError: 'answer'\n",
      "Error running target function: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o in organization org-CnOnLIaLFhfXUDRV6hWHsPkS on tokens per min (TPM): Limit 30000, Used 29096, Requested 3640. Please try again in 5.472s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/evaluation/_runner.py\", line 1675, in _forward\n",
      "    fn(example.inputs, langsmith_extra=langsmith_extra)\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 617, in wrapper\n",
      "    raise e\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 614, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "  File \"/var/folders/1l/w3vzbf215cs4ll30rh71l7wr6ghggx/T/ipykernel_59744/3191971669.py\", line 8, in predict_rag_answer_with_context\n",
      "    response = rag_bot.get_answer(example[\"input_question\"])\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 617, in wrapper\n",
      "    raise e\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 614, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "  File \"/var/folders/1l/w3vzbf215cs4ll30rh71l7wr6ghggx/T/ipykernel_59744/3657546987.py\", line 45, in get_answer\n",
      "    return self.invoke_llm(question, docs)\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 617, in wrapper\n",
      "    raise e\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 614, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "  File \"/var/folders/1l/w3vzbf215cs4ll30rh71l7wr6ghggx/T/ipykernel_59744/3657546987.py\", line 23, in invoke_llm\n",
      "    response = self._client.chat.completions.create(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/wrappers/_openai.py\", line 238, in create\n",
      "    return decorator(original_create)(*args, stream=stream, **kwargs)\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 617, in wrapper\n",
      "    raise e\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 614, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 275, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/resources/chat/completions.py\", line 829, in create\n",
      "    return self._post(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/_base_client.py\", line 1280, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/_base_client.py\", line 957, in request\n",
      "    return self._request(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/_base_client.py\", line 1046, in _request\n",
      "    return self._retry_request(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/_base_client.py\", line 1095, in _retry_request\n",
      "    return self._request(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/_base_client.py\", line 1046, in _request\n",
      "    return self._retry_request(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/_base_client.py\", line 1095, in _retry_request\n",
      "    return self._request(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/_base_client.py\", line 1061, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o in organization org-CnOnLIaLFhfXUDRV6hWHsPkS on tokens per min (TPM): Limit 30000, Used 29096, Requested 3640. Please try again in 5.472s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Error running evaluator <DynamicRunEvaluator answer_evaluator> on run e16f11d3-8b55-442b-91c0-35df1a14978d: KeyError('answer')\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/evaluation/_runner.py\", line 1404, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/evaluation/evaluator.py\", line 331, in evaluate_run\n",
      "    result = self.func(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 617, in wrapper\n",
      "    raise e\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 614, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "  File \"/var/folders/1l/w3vzbf215cs4ll30rh71l7wr6ghggx/T/ipykernel_59744/2954685631.py\", line 16, in answer_evaluator\n",
      "    prediction = run.outputs[\"answer\"]\n",
      "KeyError: 'answer'\n",
      "Error running evaluator <DynamicRunEvaluator answer_helpfulness_evaluator> on run e16f11d3-8b55-442b-91c0-35df1a14978d: KeyError('answer')\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/evaluation/_runner.py\", line 1404, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/evaluation/evaluator.py\", line 331, in evaluate_run\n",
      "    result = self.func(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 617, in wrapper\n",
      "    raise e\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 614, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "  File \"/var/folders/1l/w3vzbf215cs4ll30rh71l7wr6ghggx/T/ipykernel_59744/2954685631.py\", line 43, in answer_helpfulness_evaluator\n",
      "    prediction = run.outputs[\"answer\"]\n",
      "KeyError: 'answer'\n",
      "Error running target function: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o in organization org-CnOnLIaLFhfXUDRV6hWHsPkS on tokens per min (TPM): Limit 30000, Used 29061, Requested 3337. Please try again in 4.796s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/evaluation/_runner.py\", line 1675, in _forward\n",
      "    fn(example.inputs, langsmith_extra=langsmith_extra)\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 617, in wrapper\n",
      "    raise e\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 614, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "  File \"/var/folders/1l/w3vzbf215cs4ll30rh71l7wr6ghggx/T/ipykernel_59744/3191971669.py\", line 8, in predict_rag_answer_with_context\n",
      "    response = rag_bot.get_answer(example[\"input_question\"])\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 617, in wrapper\n",
      "    raise e\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 614, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "  File \"/var/folders/1l/w3vzbf215cs4ll30rh71l7wr6ghggx/T/ipykernel_59744/3657546987.py\", line 45, in get_answer\n",
      "    return self.invoke_llm(question, docs)\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 617, in wrapper\n",
      "    raise e\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 614, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "  File \"/var/folders/1l/w3vzbf215cs4ll30rh71l7wr6ghggx/T/ipykernel_59744/3657546987.py\", line 23, in invoke_llm\n",
      "    response = self._client.chat.completions.create(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/wrappers/_openai.py\", line 238, in create\n",
      "    return decorator(original_create)(*args, stream=stream, **kwargs)\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 617, in wrapper\n",
      "    raise e\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 614, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 275, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/resources/chat/completions.py\", line 829, in create\n",
      "    return self._post(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/_base_client.py\", line 1280, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/_base_client.py\", line 957, in request\n",
      "    return self._request(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/_base_client.py\", line 1046, in _request\n",
      "    return self._retry_request(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/_base_client.py\", line 1095, in _retry_request\n",
      "    return self._request(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/_base_client.py\", line 1046, in _request\n",
      "    return self._retry_request(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/_base_client.py\", line 1095, in _retry_request\n",
      "    return self._request(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/_base_client.py\", line 1061, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o in organization org-CnOnLIaLFhfXUDRV6hWHsPkS on tokens per min (TPM): Limit 30000, Used 29061, Requested 3337. Please try again in 4.796s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "15it [00:17,  1.64it/s]Error running evaluator <DynamicRunEvaluator answer_evaluator> on run 945849e5-e1c2-4d76-8805-494ccabc5a01: KeyError('answer')\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/evaluation/_runner.py\", line 1404, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/evaluation/evaluator.py\", line 331, in evaluate_run\n",
      "    result = self.func(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 617, in wrapper\n",
      "    raise e\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 614, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "  File \"/var/folders/1l/w3vzbf215cs4ll30rh71l7wr6ghggx/T/ipykernel_59744/2954685631.py\", line 16, in answer_evaluator\n",
      "    prediction = run.outputs[\"answer\"]\n",
      "KeyError: 'answer'\n",
      "Error running evaluator <DynamicRunEvaluator answer_helpfulness_evaluator> on run 945849e5-e1c2-4d76-8805-494ccabc5a01: KeyError('answer')\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/evaluation/_runner.py\", line 1404, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/evaluation/evaluator.py\", line 331, in evaluate_run\n",
      "    result = self.func(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 617, in wrapper\n",
      "    raise e\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 614, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "  File \"/var/folders/1l/w3vzbf215cs4ll30rh71l7wr6ghggx/T/ipykernel_59744/2954685631.py\", line 43, in answer_helpfulness_evaluator\n",
      "    prediction = run.outputs[\"answer\"]\n",
      "KeyError: 'answer'\n",
      "Error running target function: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o in organization org-CnOnLIaLFhfXUDRV6hWHsPkS on tokens per min (TPM): Limit 30000, Used 29018, Requested 3372. Please try again in 4.78s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/evaluation/_runner.py\", line 1675, in _forward\n",
      "    fn(example.inputs, langsmith_extra=langsmith_extra)\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 617, in wrapper\n",
      "    raise e\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 614, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "  File \"/var/folders/1l/w3vzbf215cs4ll30rh71l7wr6ghggx/T/ipykernel_59744/3191971669.py\", line 8, in predict_rag_answer_with_context\n",
      "    response = rag_bot.get_answer(example[\"input_question\"])\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 617, in wrapper\n",
      "    raise e\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 614, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "  File \"/var/folders/1l/w3vzbf215cs4ll30rh71l7wr6ghggx/T/ipykernel_59744/3657546987.py\", line 45, in get_answer\n",
      "    return self.invoke_llm(question, docs)\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 617, in wrapper\n",
      "    raise e\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 614, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "  File \"/var/folders/1l/w3vzbf215cs4ll30rh71l7wr6ghggx/T/ipykernel_59744/3657546987.py\", line 23, in invoke_llm\n",
      "    response = self._client.chat.completions.create(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/wrappers/_openai.py\", line 238, in create\n",
      "    return decorator(original_create)(*args, stream=stream, **kwargs)\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 617, in wrapper\n",
      "    raise e\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 614, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 275, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/resources/chat/completions.py\", line 829, in create\n",
      "    return self._post(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/_base_client.py\", line 1280, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/_base_client.py\", line 957, in request\n",
      "    return self._request(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/_base_client.py\", line 1046, in _request\n",
      "    return self._retry_request(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/_base_client.py\", line 1095, in _retry_request\n",
      "    return self._request(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/_base_client.py\", line 1046, in _request\n",
      "    return self._retry_request(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/_base_client.py\", line 1095, in _retry_request\n",
      "    return self._request(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/_base_client.py\", line 1061, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o in organization org-CnOnLIaLFhfXUDRV6hWHsPkS on tokens per min (TPM): Limit 30000, Used 29018, Requested 3372. Please try again in 4.78s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Error running evaluator <DynamicRunEvaluator answer_evaluator> on run 552678b4-38c0-495e-bcd4-9abb2f40c575: KeyError('answer')\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/evaluation/_runner.py\", line 1404, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/evaluation/evaluator.py\", line 331, in evaluate_run\n",
      "    result = self.func(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 617, in wrapper\n",
      "    raise e\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 614, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "  File \"/var/folders/1l/w3vzbf215cs4ll30rh71l7wr6ghggx/T/ipykernel_59744/2954685631.py\", line 16, in answer_evaluator\n",
      "    prediction = run.outputs[\"answer\"]\n",
      "KeyError: 'answer'\n",
      "Error running evaluator <DynamicRunEvaluator answer_helpfulness_evaluator> on run 552678b4-38c0-495e-bcd4-9abb2f40c575: KeyError('answer')\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/evaluation/_runner.py\", line 1404, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/evaluation/evaluator.py\", line 331, in evaluate_run\n",
      "    result = self.func(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 617, in wrapper\n",
      "    raise e\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 614, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "  File \"/var/folders/1l/w3vzbf215cs4ll30rh71l7wr6ghggx/T/ipykernel_59744/2954685631.py\", line 43, in answer_helpfulness_evaluator\n",
      "    prediction = run.outputs[\"answer\"]\n",
      "KeyError: 'answer'\n",
      "Error running target function: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o in organization org-CnOnLIaLFhfXUDRV6hWHsPkS on tokens per min (TPM): Limit 30000, Used 28848, Requested 3597. Please try again in 4.89s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/evaluation/_runner.py\", line 1675, in _forward\n",
      "    fn(example.inputs, langsmith_extra=langsmith_extra)\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 617, in wrapper\n",
      "    raise e\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 614, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "  File \"/var/folders/1l/w3vzbf215cs4ll30rh71l7wr6ghggx/T/ipykernel_59744/3191971669.py\", line 8, in predict_rag_answer_with_context\n",
      "    response = rag_bot.get_answer(example[\"input_question\"])\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 617, in wrapper\n",
      "    raise e\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 614, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "  File \"/var/folders/1l/w3vzbf215cs4ll30rh71l7wr6ghggx/T/ipykernel_59744/3657546987.py\", line 45, in get_answer\n",
      "    return self.invoke_llm(question, docs)\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 617, in wrapper\n",
      "    raise e\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 614, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "  File \"/var/folders/1l/w3vzbf215cs4ll30rh71l7wr6ghggx/T/ipykernel_59744/3657546987.py\", line 23, in invoke_llm\n",
      "    response = self._client.chat.completions.create(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/wrappers/_openai.py\", line 238, in create\n",
      "    return decorator(original_create)(*args, stream=stream, **kwargs)\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 617, in wrapper\n",
      "    raise e\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 614, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 275, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/resources/chat/completions.py\", line 829, in create\n",
      "    return self._post(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/_base_client.py\", line 1280, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/_base_client.py\", line 957, in request\n",
      "    return self._request(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/_base_client.py\", line 1046, in _request\n",
      "    return self._retry_request(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/_base_client.py\", line 1095, in _retry_request\n",
      "    return self._request(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/_base_client.py\", line 1046, in _request\n",
      "    return self._retry_request(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/_base_client.py\", line 1095, in _retry_request\n",
      "    return self._request(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/_base_client.py\", line 1061, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o in organization org-CnOnLIaLFhfXUDRV6hWHsPkS on tokens per min (TPM): Limit 30000, Used 28848, Requested 3597. Please try again in 4.89s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "17it [00:17,  1.97it/s]Error running evaluator <DynamicRunEvaluator answer_evaluator> on run 939814e1-aac0-4547-9ef5-dcc4b9dec627: KeyError('answer')\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/evaluation/_runner.py\", line 1404, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/evaluation/evaluator.py\", line 331, in evaluate_run\n",
      "    result = self.func(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 617, in wrapper\n",
      "    raise e\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 614, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "  File \"/var/folders/1l/w3vzbf215cs4ll30rh71l7wr6ghggx/T/ipykernel_59744/2954685631.py\", line 16, in answer_evaluator\n",
      "    prediction = run.outputs[\"answer\"]\n",
      "KeyError: 'answer'\n",
      "Error running evaluator <DynamicRunEvaluator answer_helpfulness_evaluator> on run 939814e1-aac0-4547-9ef5-dcc4b9dec627: KeyError('answer')\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/evaluation/_runner.py\", line 1404, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/evaluation/evaluator.py\", line 331, in evaluate_run\n",
      "    result = self.func(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 617, in wrapper\n",
      "    raise e\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 614, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "  File \"/var/folders/1l/w3vzbf215cs4ll30rh71l7wr6ghggx/T/ipykernel_59744/2954685631.py\", line 43, in answer_helpfulness_evaluator\n",
      "    prediction = run.outputs[\"answer\"]\n",
      "KeyError: 'answer'\n",
      "Error running target function: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o in organization org-CnOnLIaLFhfXUDRV6hWHsPkS on tokens per min (TPM): Limit 30000, Used 28171, Requested 3365. Please try again in 3.072s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/evaluation/_runner.py\", line 1675, in _forward\n",
      "    fn(example.inputs, langsmith_extra=langsmith_extra)\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 617, in wrapper\n",
      "    raise e\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 614, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "  File \"/var/folders/1l/w3vzbf215cs4ll30rh71l7wr6ghggx/T/ipykernel_59744/3191971669.py\", line 8, in predict_rag_answer_with_context\n",
      "    response = rag_bot.get_answer(example[\"input_question\"])\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 617, in wrapper\n",
      "    raise e\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 614, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "  File \"/var/folders/1l/w3vzbf215cs4ll30rh71l7wr6ghggx/T/ipykernel_59744/3657546987.py\", line 45, in get_answer\n",
      "    return self.invoke_llm(question, docs)\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 617, in wrapper\n",
      "    raise e\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 614, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "  File \"/var/folders/1l/w3vzbf215cs4ll30rh71l7wr6ghggx/T/ipykernel_59744/3657546987.py\", line 23, in invoke_llm\n",
      "    response = self._client.chat.completions.create(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/wrappers/_openai.py\", line 238, in create\n",
      "    return decorator(original_create)(*args, stream=stream, **kwargs)\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 617, in wrapper\n",
      "    raise e\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 614, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 275, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/resources/chat/completions.py\", line 829, in create\n",
      "    return self._post(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/_base_client.py\", line 1280, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/_base_client.py\", line 957, in request\n",
      "    return self._request(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/_base_client.py\", line 1046, in _request\n",
      "    return self._retry_request(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/_base_client.py\", line 1095, in _retry_request\n",
      "    return self._request(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/_base_client.py\", line 1046, in _request\n",
      "    return self._retry_request(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/_base_client.py\", line 1095, in _retry_request\n",
      "    return self._request(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/_base_client.py\", line 1061, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o in organization org-CnOnLIaLFhfXUDRV6hWHsPkS on tokens per min (TPM): Limit 30000, Used 28171, Requested 3365. Please try again in 3.072s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "18it [00:19,  1.44it/s]Error running evaluator <DynamicRunEvaluator answer_evaluator> on run 0f80d82b-68bb-4834-8b10-f0c6d4970ff0: KeyError('answer')\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/evaluation/_runner.py\", line 1404, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/evaluation/evaluator.py\", line 331, in evaluate_run\n",
      "    result = self.func(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 617, in wrapper\n",
      "    raise e\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 614, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "  File \"/var/folders/1l/w3vzbf215cs4ll30rh71l7wr6ghggx/T/ipykernel_59744/2954685631.py\", line 16, in answer_evaluator\n",
      "    prediction = run.outputs[\"answer\"]\n",
      "KeyError: 'answer'\n",
      "Error running evaluator <DynamicRunEvaluator answer_helpfulness_evaluator> on run 0f80d82b-68bb-4834-8b10-f0c6d4970ff0: KeyError('answer')\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/evaluation/_runner.py\", line 1404, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/evaluation/evaluator.py\", line 331, in evaluate_run\n",
      "    result = self.func(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 617, in wrapper\n",
      "    raise e\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 614, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "  File \"/var/folders/1l/w3vzbf215cs4ll30rh71l7wr6ghggx/T/ipykernel_59744/2954685631.py\", line 43, in answer_helpfulness_evaluator\n",
      "    prediction = run.outputs[\"answer\"]\n",
      "KeyError: 'answer'\n",
      "20it [00:19,  1.00it/s]\n"
     ]
    }
   ],
   "source": [
    "from langsmith.evaluation import evaluate\n",
    "\n",
    "dataset_name = \"income_tax_dataset\"\n",
    "experiment_results = evaluate(\n",
    "    predict_rag_answer_with_context, # 어떤 함수를 활용해서 LLM 답변을 확인할지 지정, hallucination 판단 여부에 따라 `with_context` 사용\n",
    "    data=dataset_name, # Evaluation에 사용될 dataset의 이름\n",
    "    evaluators=[answer_evaluator, answer_helpfulness_evaluator], # 실행할 Evaluator의 종류\n",
    "    experiment_prefix=\"inflearn-evaluator-lecture-hallucination\",\n",
    "    metadata={\"version\": \"income tax v1, gpt-4o\"}, \n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 점수의 판단\n",
    "* Chatgpt 가 작성한 답변 -> 도메인 전문가가 아니기 때문에 정답지가 틀렸을 가능성\n",
    "* Embedding 문제 -> embedding 효율이 떨어져서 retrieval 된 문서가 잘못 참조되어 잘못된 답변이 생성되는 경우"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "View the evaluation results for experiment: 'inflearn-evaluator-lecture-hallucination-f8ac5188' at:\n",
      "https://smith.langchain.com/o/2f003b67-27f4-48d0-8856-e1db2397e3d4/datasets/292b8275-5cfc-4310-9d5f-d830adc71bad/compare?selectedSessions=711361d9-f030-4e78-903f-49a7b313631e\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]Error running evaluator <DynamicRunEvaluator answer_hallucination_evaluator> on run 1611f4bd-23a8-44d9-a8f2-7a43a4348be8: NameError(\"name 'grade_prompt_hallucinations' is not defined\")\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/evaluation/_runner.py\", line 1404, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/evaluation/evaluator.py\", line 331, in evaluate_run\n",
      "    result = self.func(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 617, in wrapper\n",
      "    raise e\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 614, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "  File \"/var/folders/1l/w3vzbf215cs4ll30rh71l7wr6ghggx/T/ipykernel_59744/1647625839.py\", line 22, in answer_hallucination_evaluator\n",
      "    answer_grader = grade_prompt_hallucinations | llm\n",
      "NameError: name 'grade_prompt_hallucinations' is not defined\n",
      "1it [00:03,  3.98s/it]Error running evaluator <DynamicRunEvaluator answer_hallucination_evaluator> on run 4b163f3e-4c54-4e0c-86ea-79309f7ab224: NameError(\"name 'grade_prompt_hallucinations' is not defined\")\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/evaluation/_runner.py\", line 1404, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/evaluation/evaluator.py\", line 331, in evaluate_run\n",
      "    result = self.func(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 617, in wrapper\n",
      "    raise e\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 614, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "  File \"/var/folders/1l/w3vzbf215cs4ll30rh71l7wr6ghggx/T/ipykernel_59744/1647625839.py\", line 22, in answer_hallucination_evaluator\n",
      "    answer_grader = grade_prompt_hallucinations | llm\n",
      "NameError: name 'grade_prompt_hallucinations' is not defined\n",
      "Error running evaluator <DynamicRunEvaluator answer_hallucination_evaluator> on run a8012c20-700e-4715-8da0-f8d61992a183: NameError(\"name 'grade_prompt_hallucinations' is not defined\")\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/evaluation/_runner.py\", line 1404, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/evaluation/evaluator.py\", line 331, in evaluate_run\n",
      "    result = self.func(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 617, in wrapper\n",
      "    raise e\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 614, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "  File \"/var/folders/1l/w3vzbf215cs4ll30rh71l7wr6ghggx/T/ipykernel_59744/1647625839.py\", line 22, in answer_hallucination_evaluator\n",
      "    answer_grader = grade_prompt_hallucinations | llm\n",
      "NameError: name 'grade_prompt_hallucinations' is not defined\n",
      "3it [00:04,  1.20s/it]Error running evaluator <DynamicRunEvaluator answer_hallucination_evaluator> on run b2a1c11b-ddf5-4e26-80ad-6faef6654e0b: NameError(\"name 'grade_prompt_hallucinations' is not defined\")\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/evaluation/_runner.py\", line 1404, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/evaluation/evaluator.py\", line 331, in evaluate_run\n",
      "    result = self.func(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 617, in wrapper\n",
      "    raise e\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 614, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "  File \"/var/folders/1l/w3vzbf215cs4ll30rh71l7wr6ghggx/T/ipykernel_59744/1647625839.py\", line 22, in answer_hallucination_evaluator\n",
      "    answer_grader = grade_prompt_hallucinations | llm\n",
      "NameError: name 'grade_prompt_hallucinations' is not defined\n",
      "4it [00:04,  1.22it/s]Error running evaluator <DynamicRunEvaluator answer_hallucination_evaluator> on run 9381166d-902d-4e01-89c1-1d73f558abe7: NameError(\"name 'grade_prompt_hallucinations' is not defined\")\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/evaluation/_runner.py\", line 1404, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/evaluation/evaluator.py\", line 331, in evaluate_run\n",
      "    result = self.func(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 617, in wrapper\n",
      "    raise e\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 614, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "  File \"/var/folders/1l/w3vzbf215cs4ll30rh71l7wr6ghggx/T/ipykernel_59744/1647625839.py\", line 22, in answer_hallucination_evaluator\n",
      "    answer_grader = grade_prompt_hallucinations | llm\n",
      "NameError: name 'grade_prompt_hallucinations' is not defined\n",
      "5it [00:04,  1.56it/s]Error running evaluator <DynamicRunEvaluator answer_hallucination_evaluator> on run 78a371a6-d709-4d73-8703-0924ff1a474c: NameError(\"name 'grade_prompt_hallucinations' is not defined\")\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/evaluation/_runner.py\", line 1404, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/evaluation/evaluator.py\", line 331, in evaluate_run\n",
      "    result = self.func(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 617, in wrapper\n",
      "    raise e\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 614, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "  File \"/var/folders/1l/w3vzbf215cs4ll30rh71l7wr6ghggx/T/ipykernel_59744/1647625839.py\", line 22, in answer_hallucination_evaluator\n",
      "    answer_grader = grade_prompt_hallucinations | llm\n",
      "NameError: name 'grade_prompt_hallucinations' is not defined\n",
      "6it [00:05,  2.02it/s]Error running evaluator <DynamicRunEvaluator answer_hallucination_evaluator> on run 62263438-86ca-4047-a1ee-b8c474d60139: NameError(\"name 'grade_prompt_hallucinations' is not defined\")\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/evaluation/_runner.py\", line 1404, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/evaluation/evaluator.py\", line 331, in evaluate_run\n",
      "    result = self.func(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 617, in wrapper\n",
      "    raise e\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 614, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "  File \"/var/folders/1l/w3vzbf215cs4ll30rh71l7wr6ghggx/T/ipykernel_59744/1647625839.py\", line 22, in answer_hallucination_evaluator\n",
      "    answer_grader = grade_prompt_hallucinations | llm\n",
      "NameError: name 'grade_prompt_hallucinations' is not defined\n",
      "7it [00:05,  1.63it/s]Error running evaluator <DynamicRunEvaluator answer_hallucination_evaluator> on run 3ff824c7-b804-4ad3-a28b-49c85ecd6fa1: NameError(\"name 'grade_prompt_hallucinations' is not defined\")\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/evaluation/_runner.py\", line 1404, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/evaluation/evaluator.py\", line 331, in evaluate_run\n",
      "    result = self.func(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 617, in wrapper\n",
      "    raise e\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 614, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "  File \"/var/folders/1l/w3vzbf215cs4ll30rh71l7wr6ghggx/T/ipykernel_59744/1647625839.py\", line 22, in answer_hallucination_evaluator\n",
      "    answer_grader = grade_prompt_hallucinations | llm\n",
      "NameError: name 'grade_prompt_hallucinations' is not defined\n",
      "Error running target function: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o in organization org-CnOnLIaLFhfXUDRV6hWHsPkS on tokens per min (TPM): Limit 30000, Used 26932, Requested 3640. Please try again in 1.144s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/evaluation/_runner.py\", line 1675, in _forward\n",
      "    fn(example.inputs, langsmith_extra=langsmith_extra)\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 617, in wrapper\n",
      "    raise e\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 614, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "  File \"/var/folders/1l/w3vzbf215cs4ll30rh71l7wr6ghggx/T/ipykernel_59744/3191971669.py\", line 8, in predict_rag_answer_with_context\n",
      "    response = rag_bot.get_answer(example[\"input_question\"])\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 617, in wrapper\n",
      "    raise e\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 614, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "  File \"/var/folders/1l/w3vzbf215cs4ll30rh71l7wr6ghggx/T/ipykernel_59744/3657546987.py\", line 45, in get_answer\n",
      "    return self.invoke_llm(question, docs)\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 617, in wrapper\n",
      "    raise e\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 614, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "  File \"/var/folders/1l/w3vzbf215cs4ll30rh71l7wr6ghggx/T/ipykernel_59744/3657546987.py\", line 23, in invoke_llm\n",
      "    response = self._client.chat.completions.create(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/wrappers/_openai.py\", line 238, in create\n",
      "    return decorator(original_create)(*args, stream=stream, **kwargs)\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 617, in wrapper\n",
      "    raise e\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 614, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 275, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/resources/chat/completions.py\", line 829, in create\n",
      "    return self._post(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/_base_client.py\", line 1280, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/_base_client.py\", line 957, in request\n",
      "    return self._request(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/_base_client.py\", line 1046, in _request\n",
      "    return self._retry_request(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/_base_client.py\", line 1095, in _retry_request\n",
      "    return self._request(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/_base_client.py\", line 1046, in _request\n",
      "    return self._retry_request(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/_base_client.py\", line 1095, in _retry_request\n",
      "    return self._request(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/_base_client.py\", line 1061, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o in organization org-CnOnLIaLFhfXUDRV6hWHsPkS on tokens per min (TPM): Limit 30000, Used 26932, Requested 3640. Please try again in 1.144s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "8it [00:10,  1.77s/it]Error running evaluator <DynamicRunEvaluator answer_hallucination_evaluator> on run aaaee342-3fe3-468c-b2b8-1c5c1a95dab5: KeyError('contexts')\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/evaluation/_runner.py\", line 1404, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/evaluation/evaluator.py\", line 331, in evaluate_run\n",
      "    result = self.func(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 617, in wrapper\n",
      "    raise e\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 614, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "  File \"/var/folders/1l/w3vzbf215cs4ll30rh71l7wr6ghggx/T/ipykernel_59744/1647625839.py\", line 12, in answer_hallucination_evaluator\n",
      "    contexts = run.outputs[\"contexts\"]\n",
      "KeyError: 'contexts'\n",
      "Error running target function: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o in organization org-CnOnLIaLFhfXUDRV6hWHsPkS on tokens per min (TPM): Limit 30000, Used 29804, Requested 3304. Please try again in 6.216s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/evaluation/_runner.py\", line 1675, in _forward\n",
      "    fn(example.inputs, langsmith_extra=langsmith_extra)\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 617, in wrapper\n",
      "    raise e\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 614, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "  File \"/var/folders/1l/w3vzbf215cs4ll30rh71l7wr6ghggx/T/ipykernel_59744/3191971669.py\", line 8, in predict_rag_answer_with_context\n",
      "    response = rag_bot.get_answer(example[\"input_question\"])\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 617, in wrapper\n",
      "    raise e\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 614, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "  File \"/var/folders/1l/w3vzbf215cs4ll30rh71l7wr6ghggx/T/ipykernel_59744/3657546987.py\", line 45, in get_answer\n",
      "    return self.invoke_llm(question, docs)\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 617, in wrapper\n",
      "    raise e\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 614, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "  File \"/var/folders/1l/w3vzbf215cs4ll30rh71l7wr6ghggx/T/ipykernel_59744/3657546987.py\", line 23, in invoke_llm\n",
      "    response = self._client.chat.completions.create(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/wrappers/_openai.py\", line 238, in create\n",
      "    return decorator(original_create)(*args, stream=stream, **kwargs)\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 617, in wrapper\n",
      "    raise e\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 614, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 275, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/resources/chat/completions.py\", line 829, in create\n",
      "    return self._post(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/_base_client.py\", line 1280, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/_base_client.py\", line 957, in request\n",
      "    return self._request(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/_base_client.py\", line 1046, in _request\n",
      "    return self._retry_request(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/_base_client.py\", line 1095, in _retry_request\n",
      "    return self._request(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/_base_client.py\", line 1046, in _request\n",
      "    return self._retry_request(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/_base_client.py\", line 1095, in _retry_request\n",
      "    return self._request(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/_base_client.py\", line 1061, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o in organization org-CnOnLIaLFhfXUDRV6hWHsPkS on tokens per min (TPM): Limit 30000, Used 29804, Requested 3304. Please try again in 6.216s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "9it [00:11,  1.49s/it]Error running evaluator <DynamicRunEvaluator answer_hallucination_evaluator> on run 8bc14058-5757-42b9-8994-2850665d886f: KeyError('contexts')\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/evaluation/_runner.py\", line 1404, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/evaluation/evaluator.py\", line 331, in evaluate_run\n",
      "    result = self.func(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 617, in wrapper\n",
      "    raise e\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 614, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "  File \"/var/folders/1l/w3vzbf215cs4ll30rh71l7wr6ghggx/T/ipykernel_59744/1647625839.py\", line 12, in answer_hallucination_evaluator\n",
      "    contexts = run.outputs[\"contexts\"]\n",
      "KeyError: 'contexts'\n",
      "Error running target function: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o in organization org-CnOnLIaLFhfXUDRV6hWHsPkS on tokens per min (TPM): Limit 30000, Used 29701, Requested 3365. Please try again in 6.132s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/evaluation/_runner.py\", line 1675, in _forward\n",
      "    fn(example.inputs, langsmith_extra=langsmith_extra)\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 617, in wrapper\n",
      "    raise e\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 614, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "  File \"/var/folders/1l/w3vzbf215cs4ll30rh71l7wr6ghggx/T/ipykernel_59744/3191971669.py\", line 8, in predict_rag_answer_with_context\n",
      "    response = rag_bot.get_answer(example[\"input_question\"])\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 617, in wrapper\n",
      "    raise e\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 614, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "  File \"/var/folders/1l/w3vzbf215cs4ll30rh71l7wr6ghggx/T/ipykernel_59744/3657546987.py\", line 45, in get_answer\n",
      "    return self.invoke_llm(question, docs)\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 617, in wrapper\n",
      "    raise e\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 614, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "  File \"/var/folders/1l/w3vzbf215cs4ll30rh71l7wr6ghggx/T/ipykernel_59744/3657546987.py\", line 23, in invoke_llm\n",
      "    response = self._client.chat.completions.create(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/wrappers/_openai.py\", line 238, in create\n",
      "    return decorator(original_create)(*args, stream=stream, **kwargs)\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 617, in wrapper\n",
      "    raise e\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 614, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 275, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/resources/chat/completions.py\", line 829, in create\n",
      "    return self._post(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/_base_client.py\", line 1280, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/_base_client.py\", line 957, in request\n",
      "    return self._request(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/_base_client.py\", line 1046, in _request\n",
      "    return self._retry_request(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/_base_client.py\", line 1095, in _retry_request\n",
      "    return self._request(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/_base_client.py\", line 1046, in _request\n",
      "    return self._retry_request(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/_base_client.py\", line 1095, in _retry_request\n",
      "    return self._request(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/_base_client.py\", line 1061, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o in organization org-CnOnLIaLFhfXUDRV6hWHsPkS on tokens per min (TPM): Limit 30000, Used 29701, Requested 3365. Please try again in 6.132s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "10it [00:11,  1.10s/it]Error running evaluator <DynamicRunEvaluator answer_hallucination_evaluator> on run 8ee5f502-4525-4716-b61d-a25282b9d789: KeyError('contexts')\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/evaluation/_runner.py\", line 1404, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/evaluation/evaluator.py\", line 331, in evaluate_run\n",
      "    result = self.func(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 617, in wrapper\n",
      "    raise e\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 614, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "  File \"/var/folders/1l/w3vzbf215cs4ll30rh71l7wr6ghggx/T/ipykernel_59744/1647625839.py\", line 12, in answer_hallucination_evaluator\n",
      "    contexts = run.outputs[\"contexts\"]\n",
      "KeyError: 'contexts'\n",
      "11it [00:11,  1.06it/s]Error running evaluator <DynamicRunEvaluator answer_hallucination_evaluator> on run 60fbd268-a1c0-45a0-ba5c-097a36641a03: NameError(\"name 'grade_prompt_hallucinations' is not defined\")\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/evaluation/_runner.py\", line 1404, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/evaluation/evaluator.py\", line 331, in evaluate_run\n",
      "    result = self.func(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 617, in wrapper\n",
      "    raise e\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 614, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "  File \"/var/folders/1l/w3vzbf215cs4ll30rh71l7wr6ghggx/T/ipykernel_59744/1647625839.py\", line 22, in answer_hallucination_evaluator\n",
      "    answer_grader = grade_prompt_hallucinations | llm\n",
      "NameError: name 'grade_prompt_hallucinations' is not defined\n",
      "12it [00:15,  1.74s/it]Error running evaluator <DynamicRunEvaluator answer_hallucination_evaluator> on run cda09ba8-e850-4fa3-a1cc-e8b46eb2aec1: NameError(\"name 'grade_prompt_hallucinations' is not defined\")\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/evaluation/_runner.py\", line 1404, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/evaluation/evaluator.py\", line 331, in evaluate_run\n",
      "    result = self.func(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 617, in wrapper\n",
      "    raise e\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 614, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "  File \"/var/folders/1l/w3vzbf215cs4ll30rh71l7wr6ghggx/T/ipykernel_59744/1647625839.py\", line 22, in answer_hallucination_evaluator\n",
      "    answer_grader = grade_prompt_hallucinations | llm\n",
      "NameError: name 'grade_prompt_hallucinations' is not defined\n",
      "Error running target function: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o in organization org-CnOnLIaLFhfXUDRV6hWHsPkS on tokens per min (TPM): Limit 30000, Used 27688, Requested 3299. Please try again in 1.974s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/evaluation/_runner.py\", line 1675, in _forward\n",
      "    fn(example.inputs, langsmith_extra=langsmith_extra)\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 617, in wrapper\n",
      "    raise e\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 614, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "  File \"/var/folders/1l/w3vzbf215cs4ll30rh71l7wr6ghggx/T/ipykernel_59744/3191971669.py\", line 8, in predict_rag_answer_with_context\n",
      "    response = rag_bot.get_answer(example[\"input_question\"])\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 617, in wrapper\n",
      "    raise e\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 614, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "  File \"/var/folders/1l/w3vzbf215cs4ll30rh71l7wr6ghggx/T/ipykernel_59744/3657546987.py\", line 45, in get_answer\n",
      "    return self.invoke_llm(question, docs)\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 617, in wrapper\n",
      "    raise e\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 614, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "  File \"/var/folders/1l/w3vzbf215cs4ll30rh71l7wr6ghggx/T/ipykernel_59744/3657546987.py\", line 23, in invoke_llm\n",
      "    response = self._client.chat.completions.create(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/wrappers/_openai.py\", line 238, in create\n",
      "    return decorator(original_create)(*args, stream=stream, **kwargs)\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 617, in wrapper\n",
      "    raise e\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 614, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 275, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/resources/chat/completions.py\", line 829, in create\n",
      "    return self._post(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/_base_client.py\", line 1280, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/_base_client.py\", line 957, in request\n",
      "    return self._request(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/_base_client.py\", line 1046, in _request\n",
      "    return self._retry_request(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/_base_client.py\", line 1095, in _retry_request\n",
      "    return self._request(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/_base_client.py\", line 1046, in _request\n",
      "    return self._retry_request(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/_base_client.py\", line 1095, in _retry_request\n",
      "    return self._request(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/_base_client.py\", line 1061, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o in organization org-CnOnLIaLFhfXUDRV6hWHsPkS on tokens per min (TPM): Limit 30000, Used 27688, Requested 3299. Please try again in 1.974s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "13it [00:17,  1.87s/it]Error running evaluator <DynamicRunEvaluator answer_hallucination_evaluator> on run 263d49fc-a896-40f2-ae1c-05b29c28ea77: KeyError('contexts')\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/evaluation/_runner.py\", line 1404, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/evaluation/evaluator.py\", line 331, in evaluate_run\n",
      "    result = self.func(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 617, in wrapper\n",
      "    raise e\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 614, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "  File \"/var/folders/1l/w3vzbf215cs4ll30rh71l7wr6ghggx/T/ipykernel_59744/1647625839.py\", line 12, in answer_hallucination_evaluator\n",
      "    contexts = run.outputs[\"contexts\"]\n",
      "KeyError: 'contexts'\n",
      "Error running target function: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o in organization org-CnOnLIaLFhfXUDRV6hWHsPkS on tokens per min (TPM): Limit 30000, Used 27656, Requested 3302. Please try again in 1.916s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/evaluation/_runner.py\", line 1675, in _forward\n",
      "    fn(example.inputs, langsmith_extra=langsmith_extra)\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 617, in wrapper\n",
      "    raise e\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 614, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "  File \"/var/folders/1l/w3vzbf215cs4ll30rh71l7wr6ghggx/T/ipykernel_59744/3191971669.py\", line 8, in predict_rag_answer_with_context\n",
      "    response = rag_bot.get_answer(example[\"input_question\"])\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 617, in wrapper\n",
      "    raise e\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 614, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "  File \"/var/folders/1l/w3vzbf215cs4ll30rh71l7wr6ghggx/T/ipykernel_59744/3657546987.py\", line 45, in get_answer\n",
      "    return self.invoke_llm(question, docs)\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 617, in wrapper\n",
      "    raise e\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 614, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "  File \"/var/folders/1l/w3vzbf215cs4ll30rh71l7wr6ghggx/T/ipykernel_59744/3657546987.py\", line 23, in invoke_llm\n",
      "    response = self._client.chat.completions.create(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/wrappers/_openai.py\", line 238, in create\n",
      "    return decorator(original_create)(*args, stream=stream, **kwargs)\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 617, in wrapper\n",
      "    raise e\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 614, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 275, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/resources/chat/completions.py\", line 829, in create\n",
      "    return self._post(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/_base_client.py\", line 1280, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/_base_client.py\", line 957, in request\n",
      "    return self._request(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/_base_client.py\", line 1046, in _request\n",
      "    return self._retry_request(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/_base_client.py\", line 1095, in _retry_request\n",
      "    return self._request(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/_base_client.py\", line 1046, in _request\n",
      "    return self._retry_request(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/_base_client.py\", line 1095, in _retry_request\n",
      "    return self._request(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/_base_client.py\", line 1061, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o in organization org-CnOnLIaLFhfXUDRV6hWHsPkS on tokens per min (TPM): Limit 30000, Used 27656, Requested 3302. Please try again in 1.916s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Error running evaluator <DynamicRunEvaluator answer_hallucination_evaluator> on run b3a8fa64-1bc7-4295-b3a0-8707a6a8aaa3: KeyError('contexts')\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/evaluation/_runner.py\", line 1404, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/evaluation/evaluator.py\", line 331, in evaluate_run\n",
      "    result = self.func(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 617, in wrapper\n",
      "    raise e\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 614, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "  File \"/var/folders/1l/w3vzbf215cs4ll30rh71l7wr6ghggx/T/ipykernel_59744/1647625839.py\", line 12, in answer_hallucination_evaluator\n",
      "    contexts = run.outputs[\"contexts\"]\n",
      "KeyError: 'contexts'\n",
      "Error running target function: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o in organization org-CnOnLIaLFhfXUDRV6hWHsPkS on tokens per min (TPM): Limit 30000, Used 27605, Requested 3337. Please try again in 1.883s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/evaluation/_runner.py\", line 1675, in _forward\n",
      "    fn(example.inputs, langsmith_extra=langsmith_extra)\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 617, in wrapper\n",
      "    raise e\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 614, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "  File \"/var/folders/1l/w3vzbf215cs4ll30rh71l7wr6ghggx/T/ipykernel_59744/3191971669.py\", line 8, in predict_rag_answer_with_context\n",
      "    response = rag_bot.get_answer(example[\"input_question\"])\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 617, in wrapper\n",
      "    raise e\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 614, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "  File \"/var/folders/1l/w3vzbf215cs4ll30rh71l7wr6ghggx/T/ipykernel_59744/3657546987.py\", line 45, in get_answer\n",
      "    return self.invoke_llm(question, docs)\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 617, in wrapper\n",
      "    raise e\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 614, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "  File \"/var/folders/1l/w3vzbf215cs4ll30rh71l7wr6ghggx/T/ipykernel_59744/3657546987.py\", line 23, in invoke_llm\n",
      "    response = self._client.chat.completions.create(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/wrappers/_openai.py\", line 238, in create\n",
      "    return decorator(original_create)(*args, stream=stream, **kwargs)\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 617, in wrapper\n",
      "    raise e\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 614, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 275, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/resources/chat/completions.py\", line 829, in create\n",
      "    return self._post(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/_base_client.py\", line 1280, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/_base_client.py\", line 957, in request\n",
      "    return self._request(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/_base_client.py\", line 1046, in _request\n",
      "    return self._retry_request(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/_base_client.py\", line 1095, in _retry_request\n",
      "    return self._request(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/_base_client.py\", line 1046, in _request\n",
      "    return self._retry_request(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/_base_client.py\", line 1095, in _retry_request\n",
      "    return self._request(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/_base_client.py\", line 1061, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o in organization org-CnOnLIaLFhfXUDRV6hWHsPkS on tokens per min (TPM): Limit 30000, Used 27605, Requested 3337. Please try again in 1.883s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "15it [00:17,  1.05s/it]Error running evaluator <DynamicRunEvaluator answer_hallucination_evaluator> on run e83669e7-1153-4a4d-a07b-1719925a93fd: KeyError('contexts')\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/evaluation/_runner.py\", line 1404, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/evaluation/evaluator.py\", line 331, in evaluate_run\n",
      "    result = self.func(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 617, in wrapper\n",
      "    raise e\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 614, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "  File \"/var/folders/1l/w3vzbf215cs4ll30rh71l7wr6ghggx/T/ipykernel_59744/1647625839.py\", line 12, in answer_hallucination_evaluator\n",
      "    contexts = run.outputs[\"contexts\"]\n",
      "KeyError: 'contexts'\n",
      "Error running target function: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o in organization org-CnOnLIaLFhfXUDRV6hWHsPkS on tokens per min (TPM): Limit 30000, Used 27585, Requested 3365. Please try again in 1.9s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/evaluation/_runner.py\", line 1675, in _forward\n",
      "    fn(example.inputs, langsmith_extra=langsmith_extra)\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 617, in wrapper\n",
      "    raise e\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 614, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "  File \"/var/folders/1l/w3vzbf215cs4ll30rh71l7wr6ghggx/T/ipykernel_59744/3191971669.py\", line 8, in predict_rag_answer_with_context\n",
      "    response = rag_bot.get_answer(example[\"input_question\"])\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 617, in wrapper\n",
      "    raise e\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 614, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "  File \"/var/folders/1l/w3vzbf215cs4ll30rh71l7wr6ghggx/T/ipykernel_59744/3657546987.py\", line 45, in get_answer\n",
      "    return self.invoke_llm(question, docs)\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 617, in wrapper\n",
      "    raise e\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 614, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "  File \"/var/folders/1l/w3vzbf215cs4ll30rh71l7wr6ghggx/T/ipykernel_59744/3657546987.py\", line 23, in invoke_llm\n",
      "    response = self._client.chat.completions.create(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/wrappers/_openai.py\", line 238, in create\n",
      "    return decorator(original_create)(*args, stream=stream, **kwargs)\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 617, in wrapper\n",
      "    raise e\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 614, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 275, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/resources/chat/completions.py\", line 829, in create\n",
      "    return self._post(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/_base_client.py\", line 1280, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/_base_client.py\", line 957, in request\n",
      "    return self._request(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/_base_client.py\", line 1046, in _request\n",
      "    return self._retry_request(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/_base_client.py\", line 1095, in _retry_request\n",
      "    return self._request(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/_base_client.py\", line 1046, in _request\n",
      "    return self._retry_request(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/_base_client.py\", line 1095, in _retry_request\n",
      "    return self._request(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/_base_client.py\", line 1061, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o in organization org-CnOnLIaLFhfXUDRV6hWHsPkS on tokens per min (TPM): Limit 30000, Used 27585, Requested 3365. Please try again in 1.9s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Error running evaluator <DynamicRunEvaluator answer_hallucination_evaluator> on run 1d18d9b9-ba9e-42cd-844d-e78241b83848: KeyError('contexts')\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/evaluation/_runner.py\", line 1404, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/evaluation/evaluator.py\", line 331, in evaluate_run\n",
      "    result = self.func(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 617, in wrapper\n",
      "    raise e\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 614, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "  File \"/var/folders/1l/w3vzbf215cs4ll30rh71l7wr6ghggx/T/ipykernel_59744/1647625839.py\", line 12, in answer_hallucination_evaluator\n",
      "    contexts = run.outputs[\"contexts\"]\n",
      "KeyError: 'contexts'\n",
      "Error running target function: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o in organization org-CnOnLIaLFhfXUDRV6hWHsPkS on tokens per min (TPM): Limit 30000, Used 27572, Requested 3372. Please try again in 1.887s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/evaluation/_runner.py\", line 1675, in _forward\n",
      "    fn(example.inputs, langsmith_extra=langsmith_extra)\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 617, in wrapper\n",
      "    raise e\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 614, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "  File \"/var/folders/1l/w3vzbf215cs4ll30rh71l7wr6ghggx/T/ipykernel_59744/3191971669.py\", line 8, in predict_rag_answer_with_context\n",
      "    response = rag_bot.get_answer(example[\"input_question\"])\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 617, in wrapper\n",
      "    raise e\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 614, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "  File \"/var/folders/1l/w3vzbf215cs4ll30rh71l7wr6ghggx/T/ipykernel_59744/3657546987.py\", line 45, in get_answer\n",
      "    return self.invoke_llm(question, docs)\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 617, in wrapper\n",
      "    raise e\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 614, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "  File \"/var/folders/1l/w3vzbf215cs4ll30rh71l7wr6ghggx/T/ipykernel_59744/3657546987.py\", line 23, in invoke_llm\n",
      "    response = self._client.chat.completions.create(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/wrappers/_openai.py\", line 238, in create\n",
      "    return decorator(original_create)(*args, stream=stream, **kwargs)\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 617, in wrapper\n",
      "    raise e\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 614, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 275, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/resources/chat/completions.py\", line 829, in create\n",
      "    return self._post(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/_base_client.py\", line 1280, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/_base_client.py\", line 957, in request\n",
      "    return self._request(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/_base_client.py\", line 1046, in _request\n",
      "    return self._retry_request(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/_base_client.py\", line 1095, in _retry_request\n",
      "    return self._request(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/_base_client.py\", line 1046, in _request\n",
      "    return self._retry_request(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/_base_client.py\", line 1095, in _retry_request\n",
      "    return self._request(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/_base_client.py\", line 1061, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o in organization org-CnOnLIaLFhfXUDRV6hWHsPkS on tokens per min (TPM): Limit 30000, Used 27572, Requested 3372. Please try again in 1.887s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Error running evaluator <DynamicRunEvaluator answer_hallucination_evaluator> on run 27c5d681-080f-4d8d-90fe-d228be85c997: KeyError('contexts')\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/evaluation/_runner.py\", line 1404, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/evaluation/evaluator.py\", line 331, in evaluate_run\n",
      "    result = self.func(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 617, in wrapper\n",
      "    raise e\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 614, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "  File \"/var/folders/1l/w3vzbf215cs4ll30rh71l7wr6ghggx/T/ipykernel_59744/1647625839.py\", line 12, in answer_hallucination_evaluator\n",
      "    contexts = run.outputs[\"contexts\"]\n",
      "KeyError: 'contexts'\n",
      "Error running target function: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o in organization org-CnOnLIaLFhfXUDRV6hWHsPkS on tokens per min (TPM): Limit 30000, Used 27559, Requested 3398. Please try again in 1.913s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/evaluation/_runner.py\", line 1675, in _forward\n",
      "    fn(example.inputs, langsmith_extra=langsmith_extra)\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 617, in wrapper\n",
      "    raise e\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 614, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "  File \"/var/folders/1l/w3vzbf215cs4ll30rh71l7wr6ghggx/T/ipykernel_59744/3191971669.py\", line 8, in predict_rag_answer_with_context\n",
      "    response = rag_bot.get_answer(example[\"input_question\"])\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 617, in wrapper\n",
      "    raise e\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 614, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "  File \"/var/folders/1l/w3vzbf215cs4ll30rh71l7wr6ghggx/T/ipykernel_59744/3657546987.py\", line 45, in get_answer\n",
      "    return self.invoke_llm(question, docs)\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 617, in wrapper\n",
      "    raise e\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 614, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "  File \"/var/folders/1l/w3vzbf215cs4ll30rh71l7wr6ghggx/T/ipykernel_59744/3657546987.py\", line 23, in invoke_llm\n",
      "    response = self._client.chat.completions.create(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/wrappers/_openai.py\", line 238, in create\n",
      "    return decorator(original_create)(*args, stream=stream, **kwargs)\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 617, in wrapper\n",
      "    raise e\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 614, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 275, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/resources/chat/completions.py\", line 829, in create\n",
      "    return self._post(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/_base_client.py\", line 1280, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/_base_client.py\", line 957, in request\n",
      "    return self._request(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/_base_client.py\", line 1046, in _request\n",
      "    return self._retry_request(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/_base_client.py\", line 1095, in _retry_request\n",
      "    return self._request(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/_base_client.py\", line 1046, in _request\n",
      "    return self._retry_request(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/_base_client.py\", line 1095, in _retry_request\n",
      "    return self._request(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/_base_client.py\", line 1061, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o in organization org-CnOnLIaLFhfXUDRV6hWHsPkS on tokens per min (TPM): Limit 30000, Used 27559, Requested 3398. Please try again in 1.913s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Error running evaluator <DynamicRunEvaluator answer_hallucination_evaluator> on run 0753650a-3210-4cb6-aaad-10d7c32f2cdb: KeyError('contexts')\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/evaluation/_runner.py\", line 1404, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/evaluation/evaluator.py\", line 331, in evaluate_run\n",
      "    result = self.func(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 617, in wrapper\n",
      "    raise e\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 614, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "  File \"/var/folders/1l/w3vzbf215cs4ll30rh71l7wr6ghggx/T/ipykernel_59744/1647625839.py\", line 12, in answer_hallucination_evaluator\n",
      "    contexts = run.outputs[\"contexts\"]\n",
      "KeyError: 'contexts'\n",
      "Error running target function: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o in organization org-CnOnLIaLFhfXUDRV6hWHsPkS on tokens per min (TPM): Limit 30000, Used 27386, Requested 3597. Please try again in 1.966s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/evaluation/_runner.py\", line 1675, in _forward\n",
      "    fn(example.inputs, langsmith_extra=langsmith_extra)\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 617, in wrapper\n",
      "    raise e\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 614, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "  File \"/var/folders/1l/w3vzbf215cs4ll30rh71l7wr6ghggx/T/ipykernel_59744/3191971669.py\", line 8, in predict_rag_answer_with_context\n",
      "    response = rag_bot.get_answer(example[\"input_question\"])\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 617, in wrapper\n",
      "    raise e\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 614, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "  File \"/var/folders/1l/w3vzbf215cs4ll30rh71l7wr6ghggx/T/ipykernel_59744/3657546987.py\", line 45, in get_answer\n",
      "    return self.invoke_llm(question, docs)\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 617, in wrapper\n",
      "    raise e\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 614, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "  File \"/var/folders/1l/w3vzbf215cs4ll30rh71l7wr6ghggx/T/ipykernel_59744/3657546987.py\", line 23, in invoke_llm\n",
      "    response = self._client.chat.completions.create(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/wrappers/_openai.py\", line 238, in create\n",
      "    return decorator(original_create)(*args, stream=stream, **kwargs)\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 617, in wrapper\n",
      "    raise e\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 614, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/_utils/_utils.py\", line 275, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/resources/chat/completions.py\", line 829, in create\n",
      "    return self._post(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/_base_client.py\", line 1280, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/_base_client.py\", line 957, in request\n",
      "    return self._request(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/_base_client.py\", line 1046, in _request\n",
      "    return self._retry_request(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/_base_client.py\", line 1095, in _retry_request\n",
      "    return self._request(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/_base_client.py\", line 1046, in _request\n",
      "    return self._retry_request(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/_base_client.py\", line 1095, in _retry_request\n",
      "    return self._request(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/openai/_base_client.py\", line 1061, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o in organization org-CnOnLIaLFhfXUDRV6hWHsPkS on tokens per min (TPM): Limit 30000, Used 27386, Requested 3597. Please try again in 1.966s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n",
      "19it [00:18,  1.95it/s]Error running evaluator <DynamicRunEvaluator answer_hallucination_evaluator> on run f2c1bd43-afbd-4bdf-8974-865935889b40: KeyError('contexts')\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/evaluation/_runner.py\", line 1404, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/evaluation/evaluator.py\", line 331, in evaluate_run\n",
      "    result = self.func(\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 617, in wrapper\n",
      "    raise e\n",
      "  File \"/Users/a202304035/.pyenv/versions/3.10.0/envs/inflearn-llm-application/lib/python3.10/site-packages/langsmith/run_helpers.py\", line 614, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "  File \"/var/folders/1l/w3vzbf215cs4ll30rh71l7wr6ghggx/T/ipykernel_59744/1647625839.py\", line 12, in answer_hallucination_evaluator\n",
      "    contexts = run.outputs[\"contexts\"]\n",
      "KeyError: 'contexts'\n",
      "20it [00:18,  1.08it/s]\n"
     ]
    }
   ],
   "source": [
    "from langsmith.evaluation import evaluate\n",
    "\n",
    "dataset_name = \"income_tax_dataset\"\n",
    "experiment_results = evaluate(\n",
    "    predict_rag_answer_with_context, # 어떤 함수를 활용해서 LLM 답변을 확인할지 지정, hallucination 판단 여부에 따라 `with_context` 사용\n",
    "    data=dataset_name, # Evaluation에 사용될 dataset의 이름\n",
    "    evaluators=[answer_hallucination_evaluator], # 실행할 Evaluator의 종류\n",
    "    experiment_prefix=\"inflearn-evaluator-lecture-hallucination\",\n",
    "    metadata={\"version\": \"income tax v1, gpt-4o\"}, \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "inflearn-llm-application",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
